{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYInpuS4ldsMnNCIpVCOIA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal7379/Colab/blob/main/NL_2_SQL_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYxlhmF5Uz8S",
        "outputId": "bd35910a-ce9a-4931-fada-6413ad961dc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Spider_kaggle.zip\n",
            "  inflating: spider/README.txt       \n",
            "  inflating: spider/database/academic/academic.sqlite  \n",
            "  inflating: spider/database/academic/schema.sql  \n",
            "  inflating: spider/database/activity_1/activity_1.sqlite  \n",
            "  inflating: spider/database/activity_1/schema.sql  \n",
            "  inflating: spider/database/aircraft/aircraft.sqlite  \n",
            "  inflating: spider/database/aircraft/schema.sql  \n",
            "  inflating: spider/database/allergy_1/allergy_1.sqlite  \n",
            "  inflating: spider/database/allergy_1/schema.sql  \n",
            "  inflating: spider/database/apartment_rentals/apartment_rentals.sqlite  \n",
            "  inflating: spider/database/apartment_rentals/schema.sql  \n",
            "  inflating: spider/database/architecture/architecture.sqlite  \n",
            "  inflating: spider/database/architecture/schema.sql  \n",
            "  inflating: spider/database/assets_maintenance/assets_maintenance.sqlite  \n",
            "  inflating: spider/database/assets_maintenance/schema.sql  \n",
            "  inflating: spider/database/baseball_1/baseball_1.sqlite  \n",
            "  inflating: spider/database/baseball_1/schema.sql  \n",
            "  inflating: spider/database/battle_death/battle_death.sqlite  \n",
            "  inflating: spider/database/battle_death/schema.sql  \n",
            "  inflating: spider/database/behavior_monitoring/behavior_monitoring.sqlite  \n",
            "  inflating: spider/database/behavior_monitoring/schema.sql  \n",
            "  inflating: spider/database/bike_1/bike_1.sqlite  \n",
            "  inflating: spider/database/bike_1/schema.sql  \n",
            "  inflating: spider/database/body_builder/body_builder.sqlite  \n",
            "  inflating: spider/database/body_builder/schema.sql  \n",
            "  inflating: spider/database/book_2/book_2.sqlite  \n",
            "  inflating: spider/database/book_2/schema.sql  \n",
            "  inflating: spider/database/browser_web/browser_web.sqlite  \n",
            "  inflating: spider/database/browser_web/schema.sql  \n",
            "  inflating: spider/database/candidate_poll/candidate_poll.sqlite  \n",
            "  inflating: spider/database/candidate_poll/schema.sql  \n",
            "  inflating: spider/database/car_1/annotation.json  \n",
            "  inflating: spider/database/car_1/car_1.json  \n",
            "  inflating: spider/database/car_1/car_1.sql  \n",
            "  inflating: spider/database/car_1/car_1.sqlite  \n",
            "  inflating: spider/database/car_1/data_csv/README.CARS.TXT  \n",
            "  inflating: spider/database/car_1/data_csv/car-makers.csv  \n",
            "  inflating: spider/database/car_1/data_csv/car-names.csv  \n",
            "  inflating: spider/database/car_1/data_csv/cars-data.csv  \n",
            "  inflating: spider/database/car_1/data_csv/cars.desc  \n",
            "  inflating: spider/database/car_1/data_csv/continents.csv  \n",
            "  inflating: spider/database/car_1/data_csv/countries.csv  \n",
            "  inflating: spider/database/car_1/data_csv/model-list.csv  \n",
            "  inflating: spider/database/car_1/link.txt  \n",
            "  inflating: spider/database/car_1/q.txt  \n",
            "  inflating: spider/database/chinook_1/annotation.json  \n",
            "  inflating: spider/database/chinook_1/chinook_1.sqlite  \n",
            "  inflating: spider/database/cinema/cinema.sqlite  \n",
            "  inflating: spider/database/cinema/schema.sql  \n",
            "  inflating: spider/database/city_record/city_record.sqlite  \n",
            "  inflating: spider/database/city_record/schema.sql  \n",
            "  inflating: spider/database/climbing/climbing.sqlite  \n",
            "  inflating: spider/database/climbing/schema.sql  \n",
            "  inflating: spider/database/club_1/club_1.sqlite  \n",
            "  inflating: spider/database/club_1/schema.sql  \n",
            "  inflating: spider/database/coffee_shop/coffee_shop.sqlite  \n",
            "  inflating: spider/database/coffee_shop/schema.sql  \n",
            "  inflating: spider/database/college_1/TinyCollege.sql  \n",
            "  inflating: spider/database/college_1/college_1.sqlite  \n",
            "  inflating: spider/database/college_1/link.txt  \n",
            "  inflating: spider/database/college_2/TextBookExampleSchema.sql  \n",
            "  inflating: spider/database/college_2/college_2.sqlite  \n",
            "  inflating: spider/database/college_2/link.txt  \n",
            "  inflating: spider/database/college_3/college_3.sqlite  \n",
            "  inflating: spider/database/college_3/schema.sql  \n",
            "  inflating: spider/database/company_1/company_1.sqlite  \n",
            "  inflating: spider/database/company_1/link.txt  \n",
            "  inflating: spider/database/company_employee/company_employee.sqlite  \n",
            "  inflating: spider/database/company_employee/schema.sql  \n",
            "  inflating: spider/database/company_office/company_office.sqlite  \n",
            "  inflating: spider/database/company_office/schema.sql  \n",
            "  inflating: spider/database/concert_singer/concert_singer.sqlite  \n",
            "  inflating: spider/database/concert_singer/schema.sql  \n",
            "  inflating: spider/database/county_public_safety/county_public_safety.sqlite  \n",
            "  inflating: spider/database/county_public_safety/schema.sql  \n",
            "  inflating: spider/database/course_teach/course_teach.sqlite  \n",
            "  inflating: spider/database/course_teach/schema.sql  \n",
            "  inflating: spider/database/cre_Doc_Control_Systems/cre_Doc_Control_Systems.sqlite  \n",
            "  inflating: spider/database/cre_Doc_Control_Systems/schema.sql  \n",
            "  inflating: spider/database/cre_Doc_Template_Mgt/cre_Doc_Template_Mgt.sqlite  \n",
            "  inflating: spider/database/cre_Doc_Template_Mgt/schema.sql  \n",
            "  inflating: spider/database/cre_Doc_Tracking_DB/cre_Doc_Tracking_DB.sqlite  \n",
            "  inflating: spider/database/cre_Doc_Tracking_DB/schema.sql  \n",
            "  inflating: spider/database/cre_Docs_and_Epenses/cre_Docs_and_Epenses.sqlite  \n",
            "  inflating: spider/database/cre_Docs_and_Epenses/schema.sql  \n",
            "  inflating: spider/database/cre_Drama_Workshop_Groups/cre_Drama_Workshop_Groups.sqlite  \n",
            "  inflating: spider/database/cre_Drama_Workshop_Groups/schema.sql  \n",
            "  inflating: spider/database/cre_Theme_park/cre_Theme_park.sqlite  \n",
            "  inflating: spider/database/cre_Theme_park/schema.sql  \n",
            "  inflating: spider/database/csu_1/csu_1.sqlite  \n",
            "  inflating: spider/database/csu_1/schema.sql  \n",
            "  inflating: spider/database/culture_company/culture_company.sqlite  \n",
            "  inflating: spider/database/culture_company/schema.sql  \n",
            "  inflating: spider/database/customer_complaints/customer_complaints.sqlite  \n",
            "  inflating: spider/database/customer_complaints/schema.sql  \n",
            "  inflating: spider/database/customer_deliveries/customer_deliveries.sqlite  \n",
            "  inflating: spider/database/customer_deliveries/schema.sql  \n",
            "  inflating: spider/database/customers_and_addresses/customers_and_addresses.sqlite  \n",
            "  inflating: spider/database/customers_and_addresses/schema.sql  \n",
            "  inflating: spider/database/customers_and_invoices/customers_and_invoices.sqlite  \n",
            "  inflating: spider/database/customers_and_invoices/schema.sql  \n",
            "  inflating: spider/database/customers_and_products_contacts/customers_and_products_contacts.sqlite  \n",
            "  inflating: spider/database/customers_and_products_contacts/schema.sql  \n",
            "  inflating: spider/database/customers_campaigns_ecommerce/customers_campaigns_ecommerce.sqlite  \n",
            "  inflating: spider/database/customers_campaigns_ecommerce/schema.sql  \n",
            "  inflating: spider/database/customers_card_transactions/customers_card_transactions.sqlite  \n",
            "  inflating: spider/database/customers_card_transactions/schema.sql  \n",
            "  inflating: spider/database/debate/debate.sqlite  \n",
            "  inflating: spider/database/debate/schema.sql  \n",
            "  inflating: spider/database/decoration_competition/decoration_competition.sqlite  \n",
            "  inflating: spider/database/decoration_competition/schema.sql  \n",
            "  inflating: spider/database/department_management/department_management.sqlite  \n",
            "  inflating: spider/database/department_management/schema.sql  \n",
            "  inflating: spider/database/department_store/department_store.sqlite  \n",
            "  inflating: spider/database/department_store/schema.sql  \n",
            "  inflating: spider/database/device/device.sqlite  \n",
            "  inflating: spider/database/device/schema.sql  \n",
            "  inflating: spider/database/document_management/document_management.sqlite  \n",
            "  inflating: spider/database/document_management/schema.sql  \n",
            "  inflating: spider/database/dog_kennels/dog_kennels.sqlite  \n",
            "  inflating: spider/database/dog_kennels/schema.sql  \n",
            "  inflating: spider/database/dorm_1/dorm_1.sqlite  \n",
            "  inflating: spider/database/dorm_1/schema.sql  \n",
            "  inflating: spider/database/driving_school/driving_school.sqlite  \n",
            "  inflating: spider/database/driving_school/schema.sql  \n",
            "  inflating: spider/database/e_government/e_government.sqlite  \n",
            "  inflating: spider/database/e_government/schema.sql  \n",
            "  inflating: spider/database/e_learning/e_learning.sqlite  \n",
            "  inflating: spider/database/e_learning/schema.sql  \n",
            "  inflating: spider/database/election/election.sqlite  \n",
            "  inflating: spider/database/election/schema.sql  \n",
            "  inflating: spider/database/election_representative/election_representative.sqlite  \n",
            "  inflating: spider/database/election_representative/schema.sql  \n",
            "  inflating: spider/database/employee_hire_evaluation/employee_hire_evaluation.sqlite  \n",
            "  inflating: spider/database/employee_hire_evaluation/schema.sql  \n",
            "  inflating: spider/database/entertainment_awards/entertainment_awards.sqlite  \n",
            "  inflating: spider/database/entertainment_awards/schema.sql  \n",
            "  inflating: spider/database/entrepreneur/entrepreneur.sqlite  \n",
            "  inflating: spider/database/entrepreneur/schema.sql  \n",
            "  inflating: spider/database/epinions_1/epinions_1.sqlite  \n",
            "  inflating: spider/database/farm/farm.sqlite  \n",
            "  inflating: spider/database/farm/schema.sql  \n",
            "  inflating: spider/database/film_rank/film_rank.sqlite  \n",
            "  inflating: spider/database/film_rank/schema.sql  \n",
            "  inflating: spider/database/flight_1/flight_1.sqlite  \n",
            "  inflating: spider/database/flight_1/schema.sql  \n",
            "  inflating: spider/database/flight_2/annotation.json  \n",
            "  inflating: spider/database/flight_2/data_csv/README.AIRLINES.txt  \n",
            "  inflating: spider/database/flight_2/data_csv/airlines.csv  \n",
            "  inflating: spider/database/flight_2/data_csv/airports100.csv  \n",
            "  inflating: spider/database/flight_2/data_csv/flights.csv  \n",
            "  inflating: spider/database/flight_2/flight_2.json  \n",
            "  inflating: spider/database/flight_2/flight_2.sql  \n",
            "  inflating: spider/database/flight_2/flight_2.sqlite  \n",
            "  inflating: spider/database/flight_2/link.txt  \n",
            "  inflating: spider/database/flight_2/q.txt  \n",
            "  inflating: spider/database/flight_4/flight_4.sqlite  \n",
            "  inflating: spider/database/flight_4/link.txt  \n",
            "  inflating: spider/database/flight_4/sql.txt  \n",
            "  inflating: spider/database/flight_company/flight_company.sqlite  \n",
            "  inflating: spider/database/flight_company/schema.sql  \n",
            "  inflating: spider/database/formula_1/annotation.json  \n",
            "  inflating: spider/database/formula_1/data_csv/circuits.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/constructorResults.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/constructorStandings.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/constructors.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/driverStandings.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/drivers.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/lapTimes.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/pitStops.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/qualifying.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/races.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/results.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/seasons.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/status.csv  \n",
            "  inflating: spider/database/formula_1/formula_1.splite  \n",
            "  inflating: spider/database/formula_1/formula_1.sql  \n",
            "  inflating: spider/database/formula_1/formula_1.sqlite  \n",
            "  inflating: spider/database/game_1/game_1.sqlite  \n",
            "  inflating: spider/database/game_1/schema.sql  \n",
            "  inflating: spider/database/game_injury/game_injury.sqlite  \n",
            "  inflating: spider/database/game_injury/schema.sql  \n",
            "  inflating: spider/database/gas_company/gas_company.sqlite  \n",
            "  inflating: spider/database/gas_company/schema.sql  \n",
            "  inflating: spider/database/geo/geo.sqlite  \n",
            "  inflating: spider/database/geo/schema.sql  \n",
            "  inflating: spider/database/gymnast/gymnast.sqlite  \n",
            "  inflating: spider/database/gymnast/schema.sql  \n",
            "  inflating: spider/database/hospital_1/hospital_1.sqlite  \n",
            "  inflating: spider/database/hospital_1/schema.sql  \n",
            "  inflating: spider/database/hr_1/hr_1.sqlite  \n",
            "  inflating: spider/database/hr_1/schema.sql  \n",
            "  inflating: spider/database/icfp_1/icfp_1.sqlite  \n",
            "  inflating: spider/database/icfp_1/link.txt  \n",
            "  inflating: spider/database/icfp_1/q.txt  \n",
            "  inflating: spider/database/imdb/imdb.sqlite  \n",
            "  inflating: spider/database/imdb/schema.sql  \n",
            "  inflating: spider/database/inn_1/annotation.json  \n",
            "  inflating: spider/database/inn_1/change_date.py  \n",
            "  inflating: spider/database/inn_1/data_csv/README.INN.TXT  \n",
            "  inflating: spider/database/inn_1/data_csv/Reservations.csv  \n",
            "  inflating: spider/database/inn_1/data_csv/Reservations_t.csv  \n",
            "  inflating: spider/database/inn_1/data_csv/Rooms.csv  \n",
            "  inflating: spider/database/inn_1/inn_1.sql  \n",
            "  inflating: spider/database/inn_1/inn_1.sqlite  \n",
            "  inflating: spider/database/inn_1/link.txt  \n",
            "  inflating: spider/database/inn_1/q.txt  \n",
            "  inflating: spider/database/insurance_and_eClaims/insurance_and_eClaims.sqlite  \n",
            "  inflating: spider/database/insurance_and_eClaims/schema.sql  \n",
            "  inflating: spider/database/insurance_fnol/insurance_fnol.sqlite  \n",
            "  inflating: spider/database/insurance_fnol/schema.sql  \n",
            "  inflating: spider/database/insurance_policies/insurance_policies.sqlite  \n",
            "  inflating: spider/database/insurance_policies/schema.sql  \n",
            "  inflating: spider/database/journal_committee/journal_committee.sqlite  \n",
            "  inflating: spider/database/journal_committee/schema.sql  \n",
            "  inflating: spider/database/loan_1/loan_1.sqlite  \n",
            "  inflating: spider/database/loan_1/schema.sql  \n",
            "  inflating: spider/database/local_govt_and_lot/local_govt_and_lot.sqlite  \n",
            "  inflating: spider/database/local_govt_and_lot/schema.sql  \n",
            "  inflating: spider/database/local_govt_in_alabama/local_govt_in_alabama.sqlite  \n",
            "  inflating: spider/database/local_govt_in_alabama/schema.sql  \n",
            "  inflating: spider/database/local_govt_mdm/local_govt_mdm.sqlite  \n",
            "  inflating: spider/database/local_govt_mdm/schema.sql  \n",
            "  inflating: spider/database/machine_repair/machine_repair.sqlite  \n",
            "  inflating: spider/database/machine_repair/schema.sql  \n",
            "  inflating: spider/database/manufactory_1/manufactory_1.sqlite  \n",
            "  inflating: spider/database/manufactory_1/schema.sql  \n",
            "  inflating: spider/database/manufacturer/manufacturer.sqlite  \n",
            "  inflating: spider/database/manufacturer/schema.sql  \n",
            "  inflating: spider/database/match_season/match_season.sqlite  \n",
            "  inflating: spider/database/match_season/schema.sql  \n",
            "  inflating: spider/database/medicine_enzyme_interaction/medicine_enzyme_interaction.sqlite  \n",
            "  inflating: spider/database/medicine_enzyme_interaction/schema.sql  \n",
            "  inflating: spider/database/mountain_photos/mountain_photos.sqlite  \n",
            "  inflating: spider/database/mountain_photos/schema.sql  \n",
            "  inflating: spider/database/movie_1/movie_1.sqlite  \n",
            "  inflating: spider/database/movie_1/schema.sql  \n",
            "  inflating: spider/database/museum_visit/museum_visit.sqlite  \n",
            "  inflating: spider/database/museum_visit/schema.sql  \n",
            "  inflating: spider/database/music_1/music_1.sqlite  \n",
            "  inflating: spider/database/music_1/schema.sql  \n",
            "  inflating: spider/database/music_2/music_2.sqlite  \n",
            "  inflating: spider/database/music_2/schema.sql  \n",
            "  inflating: spider/database/music_4/music_4.sqlite  \n",
            "  inflating: spider/database/music_4/schema.sql  \n",
            "  inflating: spider/database/musical/musical.sqlite  \n",
            "  inflating: spider/database/musical/schema.sql  \n",
            "  inflating: spider/database/network_1/network_1.sqlite  \n",
            "  inflating: spider/database/network_1/schema.sql  \n",
            "  inflating: spider/database/network_2/network_2.sqlite  \n",
            "  inflating: spider/database/network_2/schema.sql  \n",
            "  inflating: spider/database/news_report/news_report.sqlite  \n",
            "  inflating: spider/database/news_report/schema.sql  \n",
            "  inflating: spider/database/orchestra/orchestra.sqlite  \n",
            "  inflating: spider/database/orchestra/schema.sql  \n",
            "  inflating: spider/database/party_host/party_host.sqlite  \n",
            "  inflating: spider/database/party_host/schema.sql  \n",
            "  inflating: spider/database/party_people/party_people.sqlite  \n",
            "  inflating: spider/database/party_people/schema.sql  \n",
            "  inflating: spider/database/performance_attendance/performance_attendance.sqlite  \n",
            "  inflating: spider/database/performance_attendance/schema.sql  \n",
            "  inflating: spider/database/perpetrator/perpetrator.sqlite  \n",
            "  inflating: spider/database/perpetrator/schema.sql  \n",
            "  inflating: spider/database/pets_1/pets_1.sqlite  \n",
            "  inflating: spider/database/pets_1/schema.sql  \n",
            "  inflating: spider/database/phone_1/phone_1.sqlite  \n",
            "  inflating: spider/database/phone_1/schema.sql  \n",
            "  inflating: spider/database/phone_market/phone_market.sqlite  \n",
            "  inflating: spider/database/phone_market/schema.sql  \n",
            "  inflating: spider/database/pilot_record/pilot_record.sqlite  \n",
            "  inflating: spider/database/pilot_record/schema.sql  \n",
            "  inflating: spider/database/poker_player/poker_player.sqlite  \n",
            "  inflating: spider/database/poker_player/schema.sql  \n",
            "  inflating: spider/database/product_catalog/product_catalog.sqlite  \n",
            "  inflating: spider/database/product_catalog/schema.sql  \n",
            "  inflating: spider/database/products_for_hire/products_for_hire.sqlite  \n",
            "  inflating: spider/database/products_for_hire/schema.sql  \n",
            "  inflating: spider/database/products_gen_characteristics/products_gen_characteristics.sqlite  \n",
            "  inflating: spider/database/products_gen_characteristics/schema.sql  \n",
            "  inflating: spider/database/program_share/program_share.sqlite  \n",
            "  inflating: spider/database/program_share/schema.sql  \n",
            "  inflating: spider/database/protein_institute/protein_institute.sqlite  \n",
            "  inflating: spider/database/protein_institute/schema.sql  \n",
            "  inflating: spider/database/race_track/race_track.sqlite  \n",
            "  inflating: spider/database/race_track/schema.sql  \n",
            "  inflating: spider/database/railway/railway.sqlite  \n",
            "  inflating: spider/database/railway/schema.sql  \n",
            "  inflating: spider/database/real_estate_properties/real_estate_properties.sqlite  \n",
            "  inflating: spider/database/real_estate_properties/schema.sql  \n",
            "  inflating: spider/database/restaurant_1/restaurant_1.sqlite  \n",
            "  inflating: spider/database/restaurant_1/schema.sql  \n",
            "  inflating: spider/database/restaurants/restaurants.sqlite  \n",
            "  inflating: spider/database/restaurants/schema.sql  \n",
            "  inflating: spider/database/riding_club/riding_club.sqlite  \n",
            "  inflating: spider/database/riding_club/schema.sql  \n",
            "  inflating: spider/database/roller_coaster/roller_coaster.sqlite  \n",
            "  inflating: spider/database/roller_coaster/schema.sql  \n",
            "  inflating: spider/database/sakila_1/sakila_1.sqlite  \n",
            "  inflating: spider/database/sakila_1/schema.sql  \n",
            "  inflating: spider/database/scholar/schema.sql  \n",
            "  inflating: spider/database/scholar/scholar.sqlite  \n",
            "  inflating: spider/database/school_bus/schema.sql  \n",
            "  inflating: spider/database/school_bus/school_bus.sqlite  \n",
            "  inflating: spider/database/school_finance/schema.sql  \n",
            "  inflating: spider/database/school_finance/school_finance.sqlite  \n",
            "  inflating: spider/database/school_player/schema.sql  \n",
            "  inflating: spider/database/school_player/school_player.sqlite  \n",
            "  inflating: spider/database/scientist_1/schema.sql  \n",
            "  inflating: spider/database/scientist_1/scientist_1.sqlite  \n",
            "  inflating: spider/database/ship_1/schema.sql  \n",
            "  inflating: spider/database/ship_1/ship_1.sqlite  \n",
            "  inflating: spider/database/ship_mission/schema.sql  \n",
            "  inflating: spider/database/ship_mission/ship_mission.sqlite  \n",
            "  inflating: spider/database/shop_membership/schema.sql  \n",
            "  inflating: spider/database/shop_membership/shop_membership.sqlite  \n",
            "  inflating: spider/database/singer/schema.sql  \n",
            "  inflating: spider/database/singer/singer.sqlite  \n",
            "  inflating: spider/database/small_bank_1/small_bank_1.sqlite  \n",
            "  inflating: spider/database/soccer_1/schema.sql  \n",
            "  inflating: spider/database/soccer_1/soccer_1.sqlite  \n",
            "  inflating: spider/database/soccer_2/schema.sql  \n",
            "  inflating: spider/database/soccer_2/soccer_2.sqlite  \n",
            "  inflating: spider/database/solvency_ii/schema.sql  \n",
            "  inflating: spider/database/solvency_ii/solvency_ii.sqlite  \n",
            "  inflating: spider/database/sports_competition/schema.sql  \n",
            "  inflating: spider/database/sports_competition/sports_competition.sqlite  \n",
            "  inflating: spider/database/station_weather/schema.sql  \n",
            "  inflating: spider/database/station_weather/station_weather.sqlite  \n",
            "  inflating: spider/database/store_1/schema.sql  \n",
            "  inflating: spider/database/store_1/store_1.sqlite  \n",
            "  inflating: spider/database/store_product/schema.sql  \n",
            "  inflating: spider/database/store_product/store_product.sqlite  \n",
            "  inflating: spider/database/storm_record/schema.sql  \n",
            "  inflating: spider/database/storm_record/storm_record.sqlite  \n",
            "  inflating: spider/database/student_1/annotation.json  \n",
            "  inflating: spider/database/student_1/data_csv/README.STUDENTS.TXT  \n",
            "  inflating: spider/database/student_1/data_csv/list.csv  \n",
            "  inflating: spider/database/student_1/data_csv/teachers.csv  \n",
            "  inflating: spider/database/student_1/link.txt  \n",
            "  inflating: spider/database/student_1/q.txt  \n",
            "  inflating: spider/database/student_1/student_1.sql  \n",
            "  inflating: spider/database/student_1/student_1.sqlite  \n",
            "  inflating: spider/database/student_assessment/schema.sql  \n",
            "  inflating: spider/database/student_assessment/student_assessment.sqlite  \n",
            "  inflating: spider/database/student_transcripts_tracking/schema.sql  \n",
            "  inflating: spider/database/student_transcripts_tracking/student_transcripts_tracking.sqlite  \n",
            "  inflating: spider/database/swimming/schema.sql  \n",
            "  inflating: spider/database/swimming/swimming.sqlite  \n",
            "  inflating: spider/database/theme_gallery/schema.sql  \n",
            "  inflating: spider/database/theme_gallery/theme_gallery.sqlite  \n",
            "  inflating: spider/database/tracking_grants_for_research/schema.sql  \n",
            "  inflating: spider/database/tracking_grants_for_research/tracking_grants_for_research.sqlite  \n",
            "  inflating: spider/database/tracking_orders/schema.sql  \n",
            "  inflating: spider/database/tracking_orders/tracking_orders.sqlite  \n",
            "  inflating: spider/database/tracking_share_transactions/schema.sql  \n",
            "  inflating: spider/database/tracking_share_transactions/tracking_share_transactions.sqlite  \n",
            "  inflating: spider/database/tracking_software_problems/schema.sql  \n",
            "  inflating: spider/database/tracking_software_problems/tracking_software_problems.sqlite  \n",
            "  inflating: spider/database/train_station/schema.sql  \n",
            "  inflating: spider/database/train_station/train_station.sqlite  \n",
            "  inflating: spider/database/tvshow/schema.sql  \n",
            "  inflating: spider/database/tvshow/tvshow.sqlite  \n",
            "  inflating: spider/database/twitter_1/queries/oracle-dialects.xml  \n",
            "  inflating: spider/database/twitter_1/queries/postgres-dialects.xml  \n",
            "  inflating: spider/database/twitter_1/queries/sqlserver-dialects.xml  \n",
            "  inflating: spider/database/twitter_1/twitter_1.sqlite  \n",
            "  inflating: spider/database/university_basketball/schema.sql  \n",
            "  inflating: spider/database/university_basketball/university_basketball.sqlite  \n",
            "  inflating: spider/database/voter_1/voter_1.sqlite  \n",
            "  inflating: spider/database/voter_2/schema.sql  \n",
            "  inflating: spider/database/voter_2/voter_2.sqlite  \n",
            "  inflating: spider/database/wedding/schema.sql  \n",
            "  inflating: spider/database/wedding/wedding.sqlite  \n",
            "  inflating: spider/database/wine_1/annotation.json  \n",
            "  inflating: spider/database/wine_1/data_csv/README.WINE.txt  \n",
            "  inflating: spider/database/wine_1/data_csv/appellations.csv  \n",
            "  inflating: spider/database/wine_1/data_csv/grapes.csv  \n",
            "  inflating: spider/database/wine_1/data_csv/wine.csv  \n",
            "  inflating: spider/database/wine_1/link.txt  \n",
            "  inflating: spider/database/wine_1/q.txt  \n",
            "  inflating: spider/database/wine_1/wine_1.sql  \n",
            "  inflating: spider/database/wine_1/wine_1.sqlite  \n",
            "  inflating: spider/database/workshop_paper/schema.sql  \n",
            "  inflating: spider/database/workshop_paper/workshop_paper.sqlite  \n",
            "  inflating: spider/database/world_1/world_1.json  \n",
            "  inflating: spider/database/world_1/world_1.sqlite  \n",
            "  inflating: spider/database/wrestler/schema.sql  \n",
            "  inflating: spider/database/wrestler/wrestler.sqlite  \n",
            "  inflating: spider/database/wta_1/wta_1.sql  \n",
            "  inflating: spider/database/wta_1/wta_1.sqlite  \n",
            "  inflating: spider/database/yelp/schema.sql  \n",
            "  inflating: spider/database/yelp/yelp.sqlite  \n",
            "  inflating: spider/dev.json         \n",
            "  inflating: spider/dev_gold.sql     \n",
            "  inflating: spider/tables.json      \n",
            "  inflating: spider/train_gold.sql   \n",
            "  inflating: spider/train_others.json  \n",
            "  inflating: spider/train_spider.json  \n"
          ]
        }
      ],
      "source": [
        "!unzip Spider_kaggle.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data\n",
        "!cd data\n",
        "\n",
        "!wget https://github.com/salesforce/WikiSQL/raw/master/data.tar.bz2\n",
        "\n",
        "!tar -xvf data.tar.bz2\n",
        "\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4MPbBHjWddu",
        "outputId": "a80cf0c8-ef12-412a-a021-30391cc140df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-26 15:49:38--  https://github.com/salesforce/WikiSQL/raw/master/data.tar.bz2\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/salesforce/WikiSQL/master/data.tar.bz2 [following]\n",
            "--2026-01-26 15:49:39--  https://raw.githubusercontent.com/salesforce/WikiSQL/master/data.tar.bz2\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26164664 (25M) [application/octet-stream]\n",
            "Saving to: ‘data.tar.bz2’\n",
            "\n",
            "data.tar.bz2        100%[===================>]  24.95M  52.7MB/s    in 0.5s    \n",
            "\n",
            "2026-01-26 15:49:41 (52.7 MB/s) - ‘data.tar.bz2’ saved [26164664/26164664]\n",
            "\n",
            "data/\n",
            "data/train.jsonl\n",
            "data/test.tables.jsonl\n",
            "data/test.db\n",
            "data/dev.tables.jsonl\n",
            "data/dev.db\n",
            "data/test.jsonl\n",
            "data/train.tables.jsonl\n",
            "data/train.db\n",
            "data/dev.jsonl\n",
            "data  data.tar.bz2  sample_data  spider  Spider_kaggle.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers networkx tqdm sqlparse\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHud665XWdgq",
        "outputId": "d3301df4-7a3a-45cc-cd38-f2fcc01b9491"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.12/dist-packages (0.5.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import json, random, math, os\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "lbzDYQqzWdit"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHLwx0TKAO2R",
        "outputId": "36737ac0-92cc-41c2-c6bc-99d6bee23f78"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spider\n",
        "with open(\"spider/train_spider.json\") as f:\n",
        "    spider_train = json.load(f)\n",
        "\n",
        "with open(\"spider/dev.json\") as f:\n",
        "    spider_dev = json.load(f)\n",
        "\n",
        "with open(\"spider/tables.json\") as f:\n",
        "    spider_tables = json.load(f)\n",
        "\n",
        "print(\"Loaded spider schemas:\", len(spider_tables))\n",
        "\n",
        "# WikiSQL\n",
        "with open(\"data/train.jsonl\") as f:\n",
        "    wikisql_train = [json.loads(x) for x in f]\n",
        "\n",
        "with open(\"data/dev.jsonl\") as f:\n",
        "    wikisql_dev = [json.loads(x) for x in f]\n",
        "\n",
        "print(\"Spider:\", len(spider_train), len(spider_dev))\n",
        "print(\"WikiSQL:\", len(wikisql_train), len(wikisql_dev))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F470oFVaAO4s",
        "outputId": "2bd68b00-e763-448b-f544-edc072b22e77"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded spider schemas: 166\n",
            "Spider: 7000 1034\n",
            "WikiSQL: 56355 8421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlparse\n",
        "def sql_tokenize(sql):\n",
        "    sql = sql.lower()\n",
        "    tokens = [t.value for t in sqlparse.parse(sql)[0].flatten()]\n",
        "    tokens = [t for t in tokens if not t.isspace()]\n",
        "    return tokens\n",
        "print(sql_tokenize(\"SELECT name FROM student WHERE age > 18\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDuONuBiAO7F",
        "outputId": "05a11437-d4c0-46db-8d13-a5bcb49e33a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['select', 'name', 'from', 'student', 'where', 'age', '>', '18']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_VOCAB = {\"<PAD>\":0,\"<UNK>\":1}\n",
        "TGT_VOCAB = {\"<PAD>\":0,\"<BOS>\":1,\"<EOS>\":2,\"<UNK>\":3}\n"
      ],
      "metadata": {
        "id": "_o7m9dGDAO-k"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_src(tok):\n",
        "    if tok not in SRC_VOCAB:\n",
        "        SRC_VOCAB[tok] = len(SRC_VOCAB)\n",
        "\n",
        "def add_tgt(tok):\n",
        "    if tok not in TGT_VOCAB:\n",
        "        TGT_VOCAB[tok] = len(TGT_VOCAB)\n"
      ],
      "metadata": {
        "id": "g-08H7IvAqoT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wikisql_to_sql(ex):\n",
        "    \"\"\"\n",
        "    Convert WikiSQL structured SQL into SQL string\n",
        "    \"\"\"\n",
        "    sql = ex[\"sql\"]\n",
        "    table = ex[\"table_id\"]\n",
        "\n",
        "    col = sql[\"sel\"]\n",
        "    agg = sql[\"agg\"]\n",
        "\n",
        "    agg_ops = [\"\", \"MAX\", \"MIN\", \"COUNT\", \"SUM\", \"AVG\"]\n",
        "\n",
        "    select = f\"{agg_ops[agg]}(col{col})\" if agg != 0 else f\"col{col}\"\n",
        "\n",
        "    where = \"\"\n",
        "    if len(sql[\"conds\"]) > 0:\n",
        "        conds = []\n",
        "        for c in sql[\"conds\"]:\n",
        "            conds.append(f\"col{c[0]} {['=','>','<','!='][c[1]]} '{c[2]}'\")\n",
        "        where = \" WHERE \" + \" AND \".join(conds)\n",
        "\n",
        "    return f\"SELECT {select} FROM {table}{where}\"\n"
      ],
      "metadata": {
        "id": "I4gXnySWCjAQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spider_sql_to_string(sql, schema):\n",
        "    try:\n",
        "        select_clause = []\n",
        "        for item in sql[\"select\"][1]:\n",
        "            agg, col = item\n",
        "            if col[1][1] == 0:\n",
        "                col_name = \"*\"\n",
        "            else:\n",
        "                t = schema[\"table_names_original\"][\n",
        "                    schema[\"column_names_original\"][col[1][1]][0]\n",
        "                ]\n",
        "                c = schema[\"column_names_original\"][col[1][1]][1]\n",
        "                col_name = f\"{t}.{c}\"\n",
        "\n",
        "            agg_ops = [\"\", \"MAX\", \"MIN\", \"COUNT\", \"SUM\", \"AVG\"]\n",
        "            if agg > 0:\n",
        "                select_clause.append(f\"{agg_ops[agg]}({col_name})\")\n",
        "            else:\n",
        "                select_clause.append(col_name)\n",
        "\n",
        "        select_sql = \"SELECT \" + \", \".join(select_clause)\n",
        "\n",
        "        from_sql = \" FROM \" + schema[\"table_names_original\"][\n",
        "            sql[\"from\"][\"table_units\"][0][1]\n",
        "        ]\n",
        "\n",
        "        where_sql = \"\"\n",
        "        if sql[\"where\"]:\n",
        "            conds = []\n",
        "            for cond in sql[\"where\"]:\n",
        "                if isinstance(cond, list):\n",
        "                    col_id = cond[2][1]\n",
        "                    op = [\"=\", \">\", \"<\", \"!=\", \">=\", \"<=\", \"LIKE\", \"IN\", \"BETWEEN\"][cond[1]]\n",
        "                    val = str(cond[3])\n",
        "                    t = schema[\"table_names_original\"][\n",
        "                        schema[\"column_names_original\"][col_id][0]\n",
        "                    ]\n",
        "                    c = schema[\"column_names_original\"][col_id][1]\n",
        "                    conds.append(f\"{t}.{c} {op} {val}\")\n",
        "            where_sql = \" WHERE \" + \" AND \".join(conds)\n",
        "\n",
        "        return select_sql + from_sql + where_sql\n",
        "\n",
        "    except:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "oq1DNvWHGLZS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocab\n",
        "for ex in wikisql_train:\n",
        "    for t in ex[\"question\"].lower().split():\n",
        "        add_src(t)\n",
        "\n",
        "    sql = wikisql_to_sql(ex)\n",
        "    for t in sql_tokenize(sql):\n",
        "        add_tgt(t)\n",
        "\n",
        "for ex in spider_train:\n",
        "    for t in ex[\"query\"].lower().split():\n",
        "        add_src(t)\n",
        "\n",
        "    for t in sql_tokenize(ex[\"query\"]):\n",
        "        add_tgt(t)\n",
        "\n",
        "print(\"SRC vocab:\", len(SRC_VOCAB))\n",
        "print(\"TGT vocab:\", len(TGT_VOCAB))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-r7Quj7AqrI",
        "outputId": "ceaa4eab-d5a0-4dbe-c9d3-e9703ad06dfd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC vocab: 57658\n",
            "TGT vocab: 52432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Special tokens\n",
        "PAD = \"<PAD>\"\n",
        "BOS = \"<BOS>\"\n",
        "EOS = \"<EOS>\"\n",
        "UNK = \"<UNK>\"\n",
        "\n",
        "# Add to target vocab\n",
        "for t in [PAD, BOS, EOS, UNK]:\n",
        "    if t not in TGT_VOCAB:\n",
        "        TGT_VOCAB[t] = len(TGT_VOCAB)\n",
        "\n",
        "INV_TGT_VOCAB = {v:k for k,v in TGT_VOCAB.items()}\n",
        "\n",
        "PAD_ID = TGT_VOCAB[PAD]\n",
        "BOS_ID = TGT_VOCAB[BOS]\n",
        "EOS_ID = TGT_VOCAB[EOS]\n",
        "UNK_ID = TGT_VOCAB[UNK]\n",
        "\n",
        "# Encode source sentence\n",
        "def encode_src(text, max_len=64):\n",
        "    ids = [SRC_VOCAB.get(t, SRC_VOCAB[UNK]) for t in text.lower().split()]\n",
        "    ids = ids[:max_len]\n",
        "    return ids + [SRC_VOCAB[PAD]] * (max_len - len(ids))\n",
        "\n",
        "# Encode SQL string\n",
        "def encode_tgt(sql, max_len=128):\n",
        "    tokens = sql_tokenize(sql)\n",
        "    ids = [TGT_VOCAB.get(t, UNK_ID) for t in tokens]\n",
        "    ids = [BOS_ID] + ids[:max_len-2] + [EOS_ID]\n",
        "    return ids + [PAD_ID] * (max_len - len(ids))\n",
        "\n",
        "\n",
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, spider_data, wiki_data):\n",
        "        self.samples = []\n",
        "\n",
        "        # WikiSQL\n",
        "        for ex in wiki_data:\n",
        "            nl = ex[\"question\"]\n",
        "            sql = wikisql_to_sql(ex)\n",
        "            self.samples.append((nl, sql))\n",
        "\n",
        "        # Spider\n",
        "        # Spider\n",
        "        for ex in spider_data:\n",
        "            schema = next(db for db in spider_tables if db[\"db_id\"] == ex[\"db_id\"])\n",
        "            sql = spider_sql_to_string(ex[\"sql\"], schema)\n",
        "            if sql:\n",
        "                self.samples.append((ex[\"query\"], sql))\n",
        "\n",
        "        print(\"Total training samples:\", len(self.samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        nl, sql = self.samples[idx]\n",
        "\n",
        "        src = torch.tensor(encode_src(nl))\n",
        "        tgt = torch.tensor(encode_tgt(sql))\n",
        "\n",
        "        return src, tgt\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    Seq2SeqDataset(spider_train, wikisql_train),\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b56cFFZAqt-",
        "outputId": "ddcfa939-9215-4f27-aa45-84bdd9f84132"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 59937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=512):\n",
        "        super().__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
        "\n",
        "        div = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(pos * div)\n",
        "        pe[:, 1::2] = torch.cos(pos * div)\n",
        "\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "\n",
        "class TransformerSeq2Seq(nn.Module):\n",
        "    def __init__(self, src_vocab, tgt_vocab, hidden=512, layers=6, heads=8, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.src_emb = nn.Embedding(src_vocab, hidden)\n",
        "        self.tgt_emb = nn.Embedding(tgt_vocab, hidden)\n",
        "\n",
        "        self.pos_enc = PositionalEncoding(hidden)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=hidden,\n",
        "            nhead=heads,\n",
        "            num_encoder_layers=layers,\n",
        "            num_decoder_layers=layers,\n",
        "            dim_feedforward=hidden * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden, tgt_vocab)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.pos_enc(self.src_emb(src))\n",
        "        tgt = self.pos_enc(self.tgt_emb(tgt))\n",
        "\n",
        "        tgt_mask = self.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
        "\n",
        "        out = self.transformer(src, tgt, tgt_mask=tgt_mask)\n",
        "        return self.fc_out(out)\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        return torch.triu(torch.ones(sz, sz) * float(\"-inf\"), diagonal=1)\n"
      ],
      "metadata": {
        "id": "CZ7le4etAqxZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = TransformerSeq2Seq(\n",
        "    src_vocab=len(SRC_VOCAB),\n",
        "    tgt_vocab=len(TGT_VOCAB),\n",
        "    hidden=512,\n",
        "    layers=6,\n",
        "    heads=8,\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
        "\n",
        "print(\"Model parameters:\", sum(p.numel() for p in model.parameters()) // 1e6, \"M\")\n",
        "\n",
        "\n",
        "def train_epoch():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for src, tgt in tqdm(train_loader):\n",
        "        src = src.to(device)\n",
        "        tgt = tgt.to(device)\n",
        "\n",
        "        out = model(src, tgt[:, :-1])\n",
        "        loss = criterion(out.reshape(-1, out.size(-1)), tgt[:, 1:].reshape(-1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "print(\"\\n🔥 Training started\\n\")\n",
        "\n",
        "best_loss = float(\"inf\")\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "    loss = train_epoch()\n",
        "    print(f\"Epoch {epoch:02d} | Train Loss: {loss:.4f}\")\n",
        "\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        torch.save(model.state_dict(), \"nl2sql_seq2seq_best.pt\")\n",
        "        print(\"✅ Saved BEST model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSu2wzArAq2f",
        "outputId": "8ff7c2e8-eaa6-4550-8f25-b86f31e9b068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: 127.0 M\n",
            "\n",
            "🔥 Training started\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1874 [00:39<20:22:32, 39.16s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3vaifOCRAq5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mIPpql5vAq8m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}