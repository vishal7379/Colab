{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal7379/Colab/blob/main/NL_2_SQL_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, json, re, torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "id": "Kqx2G3lHzftu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72f18642-c69c-4ee4-ea33-75806d526964"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SCHEMAS = [\n",
        "\n",
        "    {\n",
        "        \"tables\":{\n",
        "            \"employees\":[\"id\",\"name\",\"salary\",\"dept_id\"],\n",
        "            \"departments\":[\"id\",\"name\"]\n",
        "        },\n",
        "        \"join\":(\"employees\",\"departments\",\"dept_id\",\"id\")\n",
        "    },\n",
        "\n",
        "    {\n",
        "        \"tables\":{\n",
        "            \"students\":[\"id\",\"name\",\"marks\",\"class_id\"],\n",
        "            \"classes\":[\"id\",\"name\"]\n",
        "        },\n",
        "        \"join\":(\"students\",\"classes\",\"class_id\",\"id\")\n",
        "    }\n",
        "]\n",
        "\n",
        "AGGS = [\"SUM\",\"AVG\",\"COUNT\",\"MAX\",\"MIN\"]\n",
        "\n",
        "PREFIX = [\n",
        "    \"show\",\"list\",\"display\",\"fetch\",\"give\",\"find\",\"retrieve\"\n",
        "]\n",
        "\n",
        "COMPARE = [\n",
        "    (\">\",\"greater than\"),\n",
        "    (\"<\",\"less than\")\n",
        "]\n",
        "\n",
        "\n",
        "def generate_example():\n",
        "\n",
        "    db = random.choice(SCHEMAS)\n",
        "    schema = db[\"tables\"]\n",
        "\n",
        "    main = list(schema.keys())[0]\n",
        "    cols = schema[main]\n",
        "\n",
        "    intent = random.choice([\n",
        "        \"SELECT\",\"MULTI\",\"WHERE\",\"OR\",\n",
        "        \"AGG\",\"GROUP\",\"HAVING\",\n",
        "        \"ORDER\",\"LIMIT\",\n",
        "        \"JOIN\",\"JOIN_WHERE\",\n",
        "        \"NESTED\",\"DOUBLE_NESTED\"\n",
        "    ])\n",
        "\n",
        "    prefix = random.choice(PREFIX)\n",
        "\n",
        "    col = random.choice(cols)\n",
        "\n",
        "    # ---------------- SELECT ----------------\n",
        "    if intent==\"SELECT\":\n",
        "\n",
        "        q = f\"{prefix} {col} from {main}\"\n",
        "        sql = f\"SELECT {col} FROM {main}\"\n",
        "\n",
        "\n",
        "    # ---------------- MULTI ----------------\n",
        "    elif intent==\"MULTI\":\n",
        "\n",
        "        c1,c2 = random.sample(cols,2)\n",
        "\n",
        "        q = f\"{prefix} {c1} and {c2} from {main}\"\n",
        "        sql = f\"SELECT {c1}, {c2} FROM {main}\"\n",
        "\n",
        "\n",
        "    # ---------------- WHERE ----------------\n",
        "    elif intent==\"WHERE\":\n",
        "\n",
        "        op,text = random.choice(COMPARE)\n",
        "        val = random.choice([10,50,100,500])\n",
        "\n",
        "        q = f\"{prefix} employees where {col} is {text} {val}\"\n",
        "        sql = f\"SELECT name FROM {main} WHERE {col} {op} {val}\"\n",
        "\n",
        "\n",
        "    # ---------------- OR ----------------\n",
        "    elif intent==\"OR\":\n",
        "\n",
        "        c1,c2 = random.sample(cols,2)\n",
        "        v1,v2 = random.choice([10,50]), random.choice([100,200])\n",
        "\n",
        "        q = f\"{prefix} employees where {c1} > {v1} or {c2} > {v2}\"\n",
        "        sql = f\"SELECT name FROM {main} WHERE {c1} > {v1} OR {c2} > {v2}\"\n",
        "\n",
        "\n",
        "    # ---------------- AGG ----------------\n",
        "    elif intent==\"AGG\":\n",
        "\n",
        "        agg = random.choice(AGGS)\n",
        "\n",
        "        q = f\"what is the {agg.lower()} of {col} in {main}\"\n",
        "        sql = f\"SELECT {agg}({col}) FROM {main}\"\n",
        "\n",
        "\n",
        "    # ---------------- GROUP ----------------\n",
        "    elif intent==\"GROUP\":\n",
        "\n",
        "        group = random.choice(cols)\n",
        "        agg = random.choice(AGGS)\n",
        "\n",
        "        q = f\"{prefix} {agg.lower()} salary grouped by {group}\"\n",
        "        sql = f\"SELECT {group}, {agg}(salary) FROM {main} GROUP BY {group}\"\n",
        "\n",
        "\n",
        "    # ---------------- HAVING ----------------\n",
        "    elif intent==\"HAVING\":\n",
        "\n",
        "        group = random.choice(cols)\n",
        "\n",
        "        q = f\"{prefix} departments having more than 5 employees\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT dept_id, COUNT(*)\n",
        "        FROM employees\n",
        "        GROUP BY dept_id\n",
        "        HAVING COUNT(*) > 5\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    # ---------------- ORDER ----------------\n",
        "    elif intent==\"ORDER\":\n",
        "\n",
        "        q = f\"{prefix} employees ordered by {col}\"\n",
        "        sql = f\"SELECT name FROM {main} ORDER BY {col} DESC\"\n",
        "\n",
        "\n",
        "    # ---------------- LIMIT ----------------\n",
        "    elif intent==\"LIMIT\":\n",
        "\n",
        "        q = f\"{prefix} top 5 employees by {col}\"\n",
        "        sql = f\"SELECT name FROM {main} ORDER BY {col} DESC LIMIT 5\"\n",
        "\n",
        "\n",
        "    # ---------------- JOIN ----------------\n",
        "    elif intent==\"JOIN\":\n",
        "\n",
        "        t1,t2,c1,c2 = db[\"join\"]\n",
        "\n",
        "        q = f\"{prefix} {t1} with their {t2}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT {t1}.name, {t2}.name\n",
        "        FROM {t1}\n",
        "        JOIN {t2}\n",
        "        ON {t1}.{c1} = {t2}.{c2}\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    # ---------------- JOIN WHERE ----------------\n",
        "    elif intent==\"JOIN_WHERE\":\n",
        "\n",
        "        t1,t2,c1,c2 = db[\"join\"]\n",
        "\n",
        "        q = f\"{prefix} employees in departments where id > 3\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT {t1}.name, {t2}.name\n",
        "        FROM {t1}\n",
        "        JOIN {t2}\n",
        "        ON {t1}.{c1} = {t2}.{c2}\n",
        "        WHERE {t2}.id > 3\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    # ---------------- NESTED ----------------\n",
        "    elif intent==\"NESTED\":\n",
        "\n",
        "        q = f\"{prefix} employees earning more than average salary\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT name\n",
        "        FROM {main}\n",
        "        WHERE salary >\n",
        "        (SELECT AVG(salary) FROM {main})\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    # ---------------- DOUBLE NESTED ----------------\n",
        "    else:\n",
        "\n",
        "        q = f\"{prefix} employees earning more than average salary in dept 2\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT name\n",
        "        FROM employees\n",
        "        WHERE salary >\n",
        "        (\n",
        "            SELECT AVG(salary)\n",
        "            FROM employees\n",
        "            WHERE dept_id = 2\n",
        "        )\n",
        "        \"\"\"\n",
        "\n",
        "    return {\n",
        "        \"question\": q.lower(),\n",
        "        \"schema\": schema,\n",
        "        \"sql\": \" \".join(sql.split())\n",
        "    }\n",
        "\n",
        "\n",
        "DATA = [generate_example() for _ in range(150000)]\n",
        "\n",
        "with open(\"nl2sql_data.json\",\"w\") as f:\n",
        "    json.dump(DATA,f,indent=2)\n",
        "\n",
        "print(\"âœ… Massive high-quality dataset generated\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7TJQFl7zfwC",
        "outputId": "8af396d7-1fdf-4b01-b309-eb3f0f3a8da2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Massive high-quality dataset generated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ENC_VOCAB={\"<PAD>\":0,\"<UNK>\":1,\"<SEP>\":2}\n",
        "DEC_VOCAB={\"<PAD>\":0,\"<UNK>\":1,\"<BOS>\":2,\"<EOS>\":3}\n",
        "\n",
        "def add(vocab,t):\n",
        "    if t not in vocab:\n",
        "        vocab[t]=len(vocab)\n",
        "\n",
        "\n",
        "def sql_tokenize(sql):\n",
        "    return re.findall(\n",
        "        r\"[A-Za-z_]+\\.[A-Za-z_]+|\\w+|>=|<=|!=|=|>|<|\\(|\\)|,\",\n",
        "        sql.lower()\n",
        "    )\n",
        "\n",
        "\n",
        "for ex in DATA:\n",
        "\n",
        "    for t in ex[\"question\"].split():\n",
        "        add(ENC_VOCAB,t)\n",
        "\n",
        "    for t,cols in ex[\"schema\"].items():\n",
        "        add(ENC_VOCAB,t)\n",
        "        for c in cols:\n",
        "            add(ENC_VOCAB,f\"{t}.{c}\")\n",
        "\n",
        "    for tok in sql_tokenize(ex[\"sql\"]):\n",
        "        add(DEC_VOCAB,tok)\n",
        "\n",
        "print(len(ENC_VOCAB),len(DEC_VOCAB))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAYyVGbozfyU",
        "outputId": "e1e421e4-7254-4952-fa46-d13c6ad89bf8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69 53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NL2SQLDataset(Dataset):\n",
        "\n",
        "    def __init__(self,data):\n",
        "        self.data=data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "\n",
        "        ex=self.data[i]\n",
        "\n",
        "        src = ex[\"question\"].split()+[\"<SEP>\"]+[\n",
        "            f\"{t}.{c}\"\n",
        "            for t,cs in ex[\"schema\"].items()\n",
        "            for c in cs\n",
        "        ]\n",
        "\n",
        "        src_ids=[ENC_VOCAB.get(t,1) for t in src][:120]\n",
        "        src_ids+=[0]*(120-len(src_ids))\n",
        "\n",
        "        tgt=[DEC_VOCAB[\"<BOS>\"]] + \\\n",
        "            [DEC_VOCAB.get(t,1) for t in sql_tokenize(ex[\"sql\"])] + \\\n",
        "            [DEC_VOCAB[\"<EOS>\"]]\n",
        "\n",
        "        tgt=tgt[:80]\n",
        "        tgt+=[0]*(80-len(tgt))\n",
        "\n",
        "        return torch.tensor(src_ids),torch.tensor(tgt)\n"
      ],
      "metadata": {
        "id": "i3unPFzSOr5r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_MODEL=384\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,d_model,max_len=512):\n",
        "        super().__init__()\n",
        "\n",
        "        pe=torch.zeros(max_len,d_model)\n",
        "\n",
        "        pos=torch.arange(0,max_len).unsqueeze(1)\n",
        "\n",
        "        div=torch.exp(\n",
        "            torch.arange(0,d_model,2) *\n",
        "            (-torch.log(torch.tensor(10000.0))/d_model)\n",
        "        )\n",
        "\n",
        "        pe[:,0::2]=torch.sin(pos*div)\n",
        "        pe[:,1::2]=torch.cos(pos*div)\n",
        "\n",
        "        self.pe=pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return x+self.pe[:,:x.size(1)].to(x.device)\n"
      ],
      "metadata": {
        "id": "JiLHAFAazf1r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self,vocab):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb=nn.Embedding(vocab,D_MODEL,padding_idx=0)\n",
        "        self.pos=PositionalEncoding(D_MODEL)\n",
        "\n",
        "        layer=nn.TransformerEncoderLayer(\n",
        "            D_MODEL,8,1536,\n",
        "            dropout=0.1,\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "\n",
        "        self.enc=nn.TransformerEncoder(layer,4)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        mask=(x==0)\n",
        "\n",
        "        x=self.pos(self.emb(x))\n",
        "\n",
        "        return self.enc(x,src_key_padding_mask=mask)\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self,vocab):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb=nn.Embedding(vocab,D_MODEL)\n",
        "        self.pos=PositionalEncoding(D_MODEL)\n",
        "\n",
        "        layer=nn.TransformerDecoderLayer(\n",
        "            D_MODEL,8,1536,\n",
        "            dropout=0.1,\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "\n",
        "        self.dec=nn.TransformerDecoder(layer,4)\n",
        "\n",
        "        self.fc=nn.Linear(D_MODEL,vocab)\n",
        "\n",
        "        self.fc.weight=self.emb.weight\n",
        "\n",
        "    def forward(self,y,mem,mask):\n",
        "\n",
        "        L=y.size(1)\n",
        "\n",
        "        causal=torch.triu(\n",
        "            torch.ones(L,L,device=y.device),1\n",
        "        ).bool()\n",
        "\n",
        "        y=self.pos(self.emb(y))\n",
        "\n",
        "        return self.fc(\n",
        "            self.dec(\n",
        "                y,mem,\n",
        "                tgt_mask=causal,\n",
        "                memory_key_padding_mask=mask\n",
        "            )\n",
        "        )\n"
      ],
      "metadata": {
        "id": "5bz9c27-zmHh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train,val=train_test_split(DATA,test_size=0.1,random_state=42)\n",
        "\n",
        "train_loader=DataLoader(\n",
        "    NL2SQLDataset(train),\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader=DataLoader(\n",
        "    NL2SQLDataset(val),\n",
        "    batch_size=64\n",
        ")\n"
      ],
      "metadata": {
        "id": "dPc-y-VozmJ_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc=Encoder(len(ENC_VOCAB)).to(device)\n",
        "dec=Decoder(len(DEC_VOCAB)).to(device)\n",
        "\n",
        "optimizer=optim.AdamW(\n",
        "    list(enc.parameters())+list(dec.parameters()),\n",
        "    lr=1e-4\n",
        ")\n",
        "\n",
        "scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer,T_max=15\n",
        ")\n",
        "\n",
        "loss_fn=nn.CrossEntropyLoss(\n",
        "    ignore_index=0,\n",
        "    label_smoothing=0.05\n",
        ")\n",
        "\n",
        "print(\"ðŸš€ Training...\\n\")\n",
        "\n",
        "for epoch in range(15):\n",
        "\n",
        "    enc.train(); dec.train()\n",
        "    train_loss=0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "\n",
        "        x,y=x.to(device),y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        mem=enc(x)\n",
        "\n",
        "        out=dec(y[:,:-1],mem,(x==0))\n",
        "\n",
        "        loss=loss_fn(\n",
        "            out.reshape(-1,len(DEC_VOCAB)),\n",
        "            y[:,1:].reshape(-1)\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            list(enc.parameters())+list(dec.parameters()),\n",
        "            1.0\n",
        "        )\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "\n",
        "    enc.eval(); dec.eval()\n",
        "    val_loss=0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x,y in val_loader:\n",
        "\n",
        "            x,y=x.to(device),y.to(device)\n",
        "\n",
        "            mem=enc(x)\n",
        "            out=dec(y[:,:-1],mem,(x==0))\n",
        "\n",
        "            val_loss+=loss_fn(\n",
        "                out.reshape(-1,len(DEC_VOCAB)),\n",
        "                y[:,1:].reshape(-1)\n",
        "            ).item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"\"\"\n",
        "Epoch {epoch+1}\n",
        "\n",
        "Train Loss: {train_loss/len(train_loader):.3f}\n",
        "Val Loss:   {val_loss/len(val_loader):.3f}\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M1Qw4jfzmMk",
        "outputId": "d63abf07-ffe2-4dea-99ac-f25911fe20d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Training...\n",
            "\n",
            "\n",
            "Epoch 1\n",
            "\n",
            "Train Loss: 3.279\n",
            "Val Loss:   0.446\n",
            "\n",
            "\n",
            "Epoch 2\n",
            "\n",
            "Train Loss: 0.449\n",
            "Val Loss:   0.400\n",
            "\n",
            "\n",
            "Epoch 3\n",
            "\n",
            "Train Loss: 0.410\n",
            "Val Loss:   0.395\n",
            "\n",
            "\n",
            "Epoch 4\n",
            "\n",
            "Train Loss: 0.400\n",
            "Val Loss:   0.394\n",
            "\n",
            "\n",
            "Epoch 5\n",
            "\n",
            "Train Loss: 0.396\n",
            "Val Loss:   0.392\n",
            "\n",
            "\n",
            "Epoch 6\n",
            "\n",
            "Train Loss: 0.394\n",
            "Val Loss:   0.391\n",
            "\n",
            "\n",
            "Epoch 7\n",
            "\n",
            "Train Loss: 0.393\n",
            "Val Loss:   0.391\n",
            "\n",
            "\n",
            "Epoch 8\n",
            "\n",
            "Train Loss: 0.392\n",
            "Val Loss:   0.391\n",
            "\n",
            "\n",
            "Epoch 9\n",
            "\n",
            "Train Loss: 0.391\n",
            "Val Loss:   0.390\n",
            "\n",
            "\n",
            "Epoch 10\n",
            "\n",
            "Train Loss: 0.391\n",
            "Val Loss:   0.390\n",
            "\n",
            "\n",
            "Epoch 11\n",
            "\n",
            "Train Loss: 0.391\n",
            "Val Loss:   0.390\n",
            "\n",
            "\n",
            "Epoch 12\n",
            "\n",
            "Train Loss: 0.391\n",
            "Val Loss:   0.390\n",
            "\n",
            "\n",
            "Epoch 13\n",
            "\n",
            "Train Loss: 0.390\n",
            "Val Loss:   0.390\n",
            "\n",
            "\n",
            "Epoch 14\n",
            "\n",
            "Train Loss: 0.390\n",
            "Val Loss:   0.390\n",
            "\n",
            "\n",
            "Epoch 15\n",
            "\n",
            "Train Loss: 0.390\n",
            "Val Loss:   0.390\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    \"encoder\":enc.state_dict(),\n",
        "    \"decoder\":dec.state_dict(),\n",
        "    \"enc_vocab\":ENC_VOCAB,\n",
        "    \"dec_vocab\":DEC_VOCAB\n",
        "},\"nl2sql_model.pt\")\n",
        "\n",
        "print(\"âœ… MODEL SAVED\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5l7rhjbzmOq",
        "outputId": "04c4e89f-6f88-46ef-b0ad-6317c901044f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"nl2sql_model.pt\", map_location=device)\n",
        "\n",
        "ENC_VOCAB = checkpoint[\"enc_vocab\"]\n",
        "DEC_VOCAB = checkpoint[\"dec_vocab\"]\n",
        "\n",
        "inv_dec_vocab = {v:k for k,v in DEC_VOCAB.items()}\n",
        "\n",
        "enc = Encoder(len(ENC_VOCAB)).to(device)\n",
        "dec = Decoder(len(DEC_VOCAB)).to(device)\n",
        "\n",
        "enc.load_state_dict(checkpoint[\"encoder\"])\n",
        "dec.load_state_dict(checkpoint[\"decoder\"])\n",
        "\n",
        "enc.eval()\n",
        "dec.eval()\n",
        "\n",
        "print(\"âœ… Model Loaded\")\n"
      ],
      "metadata": {
        "id": "QUMijMJWzmRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a322af-a19c-4819-a646-197457a5ad1c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_sampling(logits, k=5, temperature=0.7):\n",
        "\n",
        "    logits = logits / temperature\n",
        "\n",
        "    vals, indices = torch.topk(logits, k)\n",
        "\n",
        "    probs = torch.softmax(vals, dim=-1)\n",
        "\n",
        "    sampled = torch.multinomial(probs, 1)\n",
        "\n",
        "    return indices[0, sampled.item()]\n"
      ],
      "metadata": {
        "id": "r1vtkaRuzmTR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_sql(question, schema, max_len=80):\n",
        "\n",
        "    enc.eval()\n",
        "    dec.eval()\n",
        "\n",
        "    tokens = question.lower().split() + [\"<SEP>\"] + [\n",
        "        f\"{t}.{c}\" for t,cs in schema.items() for c in cs\n",
        "    ]\n",
        "\n",
        "    ids = [ENC_VOCAB.get(t,1) for t in tokens][:120]\n",
        "    ids += [0]*(120-len(ids))\n",
        "\n",
        "    x = torch.tensor(ids).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mem = enc(x)\n",
        "\n",
        "    y = torch.tensor([[DEC_VOCAB[\"<BOS>\"]]], device=device)\n",
        "\n",
        "    generated=[]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            out = dec(y, mem, (x==0))\n",
        "\n",
        "            logits = out[:,-1,:]\n",
        "\n",
        "        idx = top_k_sampling(logits, k=5)\n",
        "\n",
        "        token = inv_dec_vocab[idx.item()]\n",
        "\n",
        "        if token == \"<EOS>\":\n",
        "            break\n",
        "\n",
        "        if token not in [\"<PAD>\",\"<BOS>\"]:\n",
        "            generated.append(token)\n",
        "\n",
        "        y = torch.cat([y, idx.view(1,1)], dim=1)\n",
        "\n",
        "    return \" \".join(generated)\n"
      ],
      "metadata": {
        "id": "-z46WNE9zmV6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema1 = {\n",
        "    \"employees\":[\"id\",\"name\",\"salary\",\"dept_id\"],\n",
        "    \"departments\":[\"id\",\"name\"]\n",
        "}\n",
        "\n",
        "print(infer_sql(\n",
        "    \"show salary of employees earning more than average salary\",\n",
        "    schema1\n",
        "))\n",
        "\n",
        "print(infer_sql(\n",
        "    \"list name and salary of employees\",\n",
        "    schema1\n",
        "))\n",
        "\n",
        "print(infer_sql(\n",
        "    \"show employees and their departments\",\n",
        "    schema1\n",
        "))\n"
      ],
      "metadata": {
        "id": "TbQjO_eVzmYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f423a8a-82bc-4fca-8e95-0ebcca7c1cdf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "select name from employees where salary > ( select avg ( salary ) from employees )\n",
            "select name , salary from employees\n",
            "select employees.name , departments.name from employees\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kDcGyh8WzmbD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2adpLS7czmdk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LY0L9-rozmf2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oYODFX_czmir"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pe0S1B5KzmlS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-segFiZuzmnn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DioIS7vzmqU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3VTaws_azms2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AXdliymTzmwS"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}