{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal7379/Colab/blob/main/NL_2_SQL_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYxlhmF5Uz8S",
        "outputId": "967e7c0c-4763-44af-eabe-b6bd386426a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Spider_dataset.zip\n",
            "  inflating: spider/README.txt       \n",
            "  inflating: spider/database/academic/academic.sqlite  \n",
            "  inflating: spider/database/academic/schema.sql  \n",
            "  inflating: spider/database/activity_1/activity_1.sqlite  \n",
            "  inflating: spider/database/activity_1/schema.sql  \n",
            "  inflating: spider/database/aircraft/aircraft.sqlite  \n",
            "  inflating: spider/database/aircraft/schema.sql  \n",
            "  inflating: spider/database/allergy_1/allergy_1.sqlite  \n",
            "  inflating: spider/database/allergy_1/schema.sql  \n",
            "  inflating: spider/database/apartment_rentals/apartment_rentals.sqlite  \n",
            "  inflating: spider/database/apartment_rentals/schema.sql  \n",
            "  inflating: spider/database/architecture/architecture.sqlite  \n",
            "  inflating: spider/database/architecture/schema.sql  \n",
            "  inflating: spider/database/assets_maintenance/assets_maintenance.sqlite  \n",
            "  inflating: spider/database/assets_maintenance/schema.sql  \n",
            "  inflating: spider/database/baseball_1/baseball_1.sqlite  \n",
            "  inflating: spider/database/baseball_1/schema.sql  \n",
            "  inflating: spider/database/battle_death/battle_death.sqlite  \n",
            "  inflating: spider/database/battle_death/schema.sql  \n",
            "  inflating: spider/database/behavior_monitoring/behavior_monitoring.sqlite  \n",
            "  inflating: spider/database/behavior_monitoring/schema.sql  \n",
            "  inflating: spider/database/bike_1/bike_1.sqlite  \n",
            "  inflating: spider/database/bike_1/schema.sql  \n",
            "  inflating: spider/database/body_builder/body_builder.sqlite  \n",
            "  inflating: spider/database/body_builder/schema.sql  \n",
            "  inflating: spider/database/book_2/book_2.sqlite  \n",
            "  inflating: spider/database/book_2/schema.sql  \n",
            "  inflating: spider/database/browser_web/browser_web.sqlite  \n",
            "  inflating: spider/database/browser_web/schema.sql  \n",
            "  inflating: spider/database/candidate_poll/candidate_poll.sqlite  \n",
            "  inflating: spider/database/candidate_poll/schema.sql  \n",
            "  inflating: spider/database/car_1/annotation.json  \n",
            "  inflating: spider/database/car_1/car_1.json  \n",
            "  inflating: spider/database/car_1/car_1.sql  \n",
            "  inflating: spider/database/car_1/car_1.sqlite  \n",
            "  inflating: spider/database/car_1/data_csv/README.CARS.TXT  \n",
            "  inflating: spider/database/car_1/data_csv/car-makers.csv  \n",
            "  inflating: spider/database/car_1/data_csv/car-names.csv  \n",
            "  inflating: spider/database/car_1/data_csv/cars-data.csv  \n",
            "  inflating: spider/database/car_1/data_csv/cars.desc  \n",
            "  inflating: spider/database/car_1/data_csv/continents.csv  \n",
            "  inflating: spider/database/car_1/data_csv/countries.csv  \n",
            "  inflating: spider/database/car_1/data_csv/model-list.csv  \n",
            "  inflating: spider/database/car_1/link.txt  \n",
            "  inflating: spider/database/car_1/q.txt  \n",
            "  inflating: spider/database/chinook_1/annotation.json  \n",
            "  inflating: spider/database/chinook_1/chinook_1.sqlite  \n",
            "  inflating: spider/database/cinema/cinema.sqlite  \n",
            "  inflating: spider/database/cinema/schema.sql  \n",
            "  inflating: spider/database/city_record/city_record.sqlite  \n",
            "  inflating: spider/database/city_record/schema.sql  \n",
            "  inflating: spider/database/climbing/climbing.sqlite  \n",
            "  inflating: spider/database/climbing/schema.sql  \n",
            "  inflating: spider/database/club_1/club_1.sqlite  \n",
            "  inflating: spider/database/club_1/schema.sql  \n",
            "  inflating: spider/database/coffee_shop/coffee_shop.sqlite  \n",
            "  inflating: spider/database/coffee_shop/schema.sql  \n",
            "  inflating: spider/database/college_1/TinyCollege.sql  \n",
            "  inflating: spider/database/college_1/college_1.sqlite  \n",
            "  inflating: spider/database/college_1/link.txt  \n",
            "  inflating: spider/database/college_2/TextBookExampleSchema.sql  \n",
            "  inflating: spider/database/college_2/college_2.sqlite  \n",
            "  inflating: spider/database/college_2/link.txt  \n",
            "  inflating: spider/database/college_3/college_3.sqlite  \n",
            "  inflating: spider/database/college_3/schema.sql  \n",
            "  inflating: spider/database/company_1/company_1.sqlite  \n",
            "  inflating: spider/database/company_1/link.txt  \n",
            "  inflating: spider/database/company_employee/company_employee.sqlite  \n",
            "  inflating: spider/database/company_employee/schema.sql  \n",
            "  inflating: spider/database/company_office/company_office.sqlite  \n",
            "  inflating: spider/database/company_office/schema.sql  \n",
            "  inflating: spider/database/concert_singer/concert_singer.sqlite  \n",
            "  inflating: spider/database/concert_singer/schema.sql  \n",
            "  inflating: spider/database/county_public_safety/county_public_safety.sqlite  \n",
            "  inflating: spider/database/county_public_safety/schema.sql  \n",
            "  inflating: spider/database/course_teach/course_teach.sqlite  \n",
            "  inflating: spider/database/course_teach/schema.sql  \n",
            "  inflating: spider/database/cre_Doc_Control_Systems/cre_Doc_Control_Systems.sqlite  \n",
            "  inflating: spider/database/cre_Doc_Control_Systems/schema.sql  \n",
            "  inflating: spider/database/cre_Doc_Template_Mgt/cre_Doc_Template_Mgt.sqlite  \n",
            "  inflating: spider/database/cre_Doc_Template_Mgt/schema.sql  \n",
            "  inflating: spider/database/cre_Doc_Tracking_DB/cre_Doc_Tracking_DB.sqlite  \n",
            "  inflating: spider/database/cre_Doc_Tracking_DB/schema.sql  \n",
            "  inflating: spider/database/cre_Docs_and_Epenses/cre_Docs_and_Epenses.sqlite  \n",
            "  inflating: spider/database/cre_Docs_and_Epenses/schema.sql  \n",
            "  inflating: spider/database/cre_Drama_Workshop_Groups/cre_Drama_Workshop_Groups.sqlite  \n",
            "  inflating: spider/database/cre_Drama_Workshop_Groups/schema.sql  \n",
            "  inflating: spider/database/cre_Theme_park/cre_Theme_park.sqlite  \n",
            "  inflating: spider/database/cre_Theme_park/schema.sql  \n",
            "  inflating: spider/database/csu_1/csu_1.sqlite  \n",
            "  inflating: spider/database/csu_1/schema.sql  \n",
            "  inflating: spider/database/culture_company/culture_company.sqlite  \n",
            "  inflating: spider/database/culture_company/schema.sql  \n",
            "  inflating: spider/database/customer_complaints/customer_complaints.sqlite  \n",
            "  inflating: spider/database/customer_complaints/schema.sql  \n",
            "  inflating: spider/database/customer_deliveries/customer_deliveries.sqlite  \n",
            "  inflating: spider/database/customer_deliveries/schema.sql  \n",
            "  inflating: spider/database/customers_and_addresses/customers_and_addresses.sqlite  \n",
            "  inflating: spider/database/customers_and_addresses/schema.sql  \n",
            "  inflating: spider/database/customers_and_invoices/customers_and_invoices.sqlite  \n",
            "  inflating: spider/database/customers_and_invoices/schema.sql  \n",
            "  inflating: spider/database/customers_and_products_contacts/customers_and_products_contacts.sqlite  \n",
            "  inflating: spider/database/customers_and_products_contacts/schema.sql  \n",
            "  inflating: spider/database/customers_campaigns_ecommerce/customers_campaigns_ecommerce.sqlite  \n",
            "  inflating: spider/database/customers_campaigns_ecommerce/schema.sql  \n",
            "  inflating: spider/database/customers_card_transactions/customers_card_transactions.sqlite  \n",
            "  inflating: spider/database/customers_card_transactions/schema.sql  \n",
            "  inflating: spider/database/debate/debate.sqlite  \n",
            "  inflating: spider/database/debate/schema.sql  \n",
            "  inflating: spider/database/decoration_competition/decoration_competition.sqlite  \n",
            "  inflating: spider/database/decoration_competition/schema.sql  \n",
            "  inflating: spider/database/department_management/department_management.sqlite  \n",
            "  inflating: spider/database/department_management/schema.sql  \n",
            "  inflating: spider/database/department_store/department_store.sqlite  \n",
            "  inflating: spider/database/department_store/schema.sql  \n",
            "  inflating: spider/database/device/device.sqlite  \n",
            "  inflating: spider/database/device/schema.sql  \n",
            "  inflating: spider/database/document_management/document_management.sqlite  \n",
            "  inflating: spider/database/document_management/schema.sql  \n",
            "  inflating: spider/database/dog_kennels/dog_kennels.sqlite  \n",
            "  inflating: spider/database/dog_kennels/schema.sql  \n",
            "  inflating: spider/database/dorm_1/dorm_1.sqlite  \n",
            "  inflating: spider/database/dorm_1/schema.sql  \n",
            "  inflating: spider/database/driving_school/driving_school.sqlite  \n",
            "  inflating: spider/database/driving_school/schema.sql  \n",
            "  inflating: spider/database/e_government/e_government.sqlite  \n",
            "  inflating: spider/database/e_government/schema.sql  \n",
            "  inflating: spider/database/e_learning/e_learning.sqlite  \n",
            "  inflating: spider/database/e_learning/schema.sql  \n",
            "  inflating: spider/database/election/election.sqlite  \n",
            "  inflating: spider/database/election/schema.sql  \n",
            "  inflating: spider/database/election_representative/election_representative.sqlite  \n",
            "  inflating: spider/database/election_representative/schema.sql  \n",
            "  inflating: spider/database/employee_hire_evaluation/employee_hire_evaluation.sqlite  \n",
            "  inflating: spider/database/employee_hire_evaluation/schema.sql  \n",
            "  inflating: spider/database/entertainment_awards/entertainment_awards.sqlite  \n",
            "  inflating: spider/database/entertainment_awards/schema.sql  \n",
            "  inflating: spider/database/entrepreneur/entrepreneur.sqlite  \n",
            "  inflating: spider/database/entrepreneur/schema.sql  \n",
            "  inflating: spider/database/epinions_1/epinions_1.sqlite  \n",
            "  inflating: spider/database/farm/farm.sqlite  \n",
            "  inflating: spider/database/farm/schema.sql  \n",
            "  inflating: spider/database/film_rank/film_rank.sqlite  \n",
            "  inflating: spider/database/film_rank/schema.sql  \n",
            "  inflating: spider/database/flight_1/flight_1.sqlite  \n",
            "  inflating: spider/database/flight_1/schema.sql  \n",
            "  inflating: spider/database/flight_2/annotation.json  \n",
            "  inflating: spider/database/flight_2/data_csv/README.AIRLINES.txt  \n",
            "  inflating: spider/database/flight_2/data_csv/airlines.csv  \n",
            "  inflating: spider/database/flight_2/data_csv/airports100.csv  \n",
            "  inflating: spider/database/flight_2/data_csv/flights.csv  \n",
            "  inflating: spider/database/flight_2/flight_2.json  \n",
            "  inflating: spider/database/flight_2/flight_2.sql  \n",
            "  inflating: spider/database/flight_2/flight_2.sqlite  \n",
            "  inflating: spider/database/flight_2/link.txt  \n",
            "  inflating: spider/database/flight_2/q.txt  \n",
            "  inflating: spider/database/flight_4/flight_4.sqlite  \n",
            "  inflating: spider/database/flight_4/link.txt  \n",
            "  inflating: spider/database/flight_4/sql.txt  \n",
            "  inflating: spider/database/flight_company/flight_company.sqlite  \n",
            "  inflating: spider/database/flight_company/schema.sql  \n",
            "  inflating: spider/database/formula_1/annotation.json  \n",
            "  inflating: spider/database/formula_1/data_csv/circuits.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/constructorResults.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/constructorStandings.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/constructors.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/driverStandings.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/drivers.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/lapTimes.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/pitStops.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/qualifying.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/races.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/results.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/seasons.csv  \n",
            "  inflating: spider/database/formula_1/data_csv/status.csv  \n",
            "  inflating: spider/database/formula_1/formula_1.splite  \n",
            "  inflating: spider/database/formula_1/formula_1.sql  \n",
            "  inflating: spider/database/formula_1/formula_1.sqlite  \n",
            "  inflating: spider/database/game_1/game_1.sqlite  \n",
            "  inflating: spider/database/game_1/schema.sql  \n",
            "  inflating: spider/database/game_injury/game_injury.sqlite  \n",
            "  inflating: spider/database/game_injury/schema.sql  \n",
            "  inflating: spider/database/gas_company/gas_company.sqlite  \n",
            "  inflating: spider/database/gas_company/schema.sql  \n",
            "  inflating: spider/database/geo/geo.sqlite  \n",
            "  inflating: spider/database/geo/schema.sql  \n",
            "  inflating: spider/database/gymnast/gymnast.sqlite  \n",
            "  inflating: spider/database/gymnast/schema.sql  \n",
            "  inflating: spider/database/hospital_1/hospital_1.sqlite  \n",
            "  inflating: spider/database/hospital_1/schema.sql  \n",
            "  inflating: spider/database/hr_1/hr_1.sqlite  \n",
            "  inflating: spider/database/hr_1/schema.sql  \n",
            "  inflating: spider/database/icfp_1/icfp_1.sqlite  \n",
            "  inflating: spider/database/icfp_1/link.txt  \n",
            "  inflating: spider/database/icfp_1/q.txt  \n",
            "  inflating: spider/database/imdb/imdb.sqlite  \n",
            "  inflating: spider/database/imdb/schema.sql  \n",
            "  inflating: spider/database/inn_1/annotation.json  \n",
            "  inflating: spider/database/inn_1/change_date.py  \n",
            "  inflating: spider/database/inn_1/data_csv/README.INN.TXT  \n",
            "  inflating: spider/database/inn_1/data_csv/Reservations.csv  \n",
            "  inflating: spider/database/inn_1/data_csv/Reservations_t.csv  \n",
            "  inflating: spider/database/inn_1/data_csv/Rooms.csv  \n",
            "  inflating: spider/database/inn_1/inn_1.sql  \n",
            "  inflating: spider/database/inn_1/inn_1.sqlite  \n",
            "  inflating: spider/database/inn_1/link.txt  \n",
            "  inflating: spider/database/inn_1/q.txt  \n",
            "  inflating: spider/database/insurance_and_eClaims/insurance_and_eClaims.sqlite  \n",
            "  inflating: spider/database/insurance_and_eClaims/schema.sql  \n",
            "  inflating: spider/database/insurance_fnol/insurance_fnol.sqlite  \n",
            "  inflating: spider/database/insurance_fnol/schema.sql  \n",
            "  inflating: spider/database/insurance_policies/insurance_policies.sqlite  \n",
            "  inflating: spider/database/insurance_policies/schema.sql  \n",
            "  inflating: spider/database/journal_committee/journal_committee.sqlite  \n",
            "  inflating: spider/database/journal_committee/schema.sql  \n",
            "  inflating: spider/database/loan_1/loan_1.sqlite  \n",
            "  inflating: spider/database/loan_1/schema.sql  \n",
            "  inflating: spider/database/local_govt_and_lot/local_govt_and_lot.sqlite  \n",
            "  inflating: spider/database/local_govt_and_lot/schema.sql  \n",
            "  inflating: spider/database/local_govt_in_alabama/local_govt_in_alabama.sqlite  \n",
            "  inflating: spider/database/local_govt_in_alabama/schema.sql  \n",
            "  inflating: spider/database/local_govt_mdm/local_govt_mdm.sqlite  \n",
            "  inflating: spider/database/local_govt_mdm/schema.sql  \n",
            "  inflating: spider/database/machine_repair/machine_repair.sqlite  \n",
            "  inflating: spider/database/machine_repair/schema.sql  \n",
            "  inflating: spider/database/manufactory_1/manufactory_1.sqlite  \n",
            "  inflating: spider/database/manufactory_1/schema.sql  \n",
            "  inflating: spider/database/manufacturer/manufacturer.sqlite  \n",
            "  inflating: spider/database/manufacturer/schema.sql  \n",
            "  inflating: spider/database/match_season/match_season.sqlite  \n",
            "  inflating: spider/database/match_season/schema.sql  \n",
            "  inflating: spider/database/medicine_enzyme_interaction/medicine_enzyme_interaction.sqlite  \n",
            "  inflating: spider/database/medicine_enzyme_interaction/schema.sql  \n",
            "  inflating: spider/database/mountain_photos/mountain_photos.sqlite  \n",
            "  inflating: spider/database/mountain_photos/schema.sql  \n",
            "  inflating: spider/database/movie_1/movie_1.sqlite  \n",
            "  inflating: spider/database/movie_1/schema.sql  \n",
            "  inflating: spider/database/museum_visit/museum_visit.sqlite  \n",
            "  inflating: spider/database/museum_visit/schema.sql  \n",
            "  inflating: spider/database/music_1/music_1.sqlite  \n",
            "  inflating: spider/database/music_1/schema.sql  \n",
            "  inflating: spider/database/music_2/music_2.sqlite  \n",
            "  inflating: spider/database/music_2/schema.sql  \n",
            "  inflating: spider/database/music_4/music_4.sqlite  \n",
            "  inflating: spider/database/music_4/schema.sql  \n",
            "  inflating: spider/database/musical/musical.sqlite  \n",
            "  inflating: spider/database/musical/schema.sql  \n",
            "  inflating: spider/database/network_1/network_1.sqlite  \n",
            "  inflating: spider/database/network_1/schema.sql  \n",
            "  inflating: spider/database/network_2/network_2.sqlite  \n",
            "  inflating: spider/database/network_2/schema.sql  \n",
            "  inflating: spider/database/news_report/news_report.sqlite  \n",
            "  inflating: spider/database/news_report/schema.sql  \n",
            "  inflating: spider/database/orchestra/orchestra.sqlite  \n",
            "  inflating: spider/database/orchestra/schema.sql  \n",
            "  inflating: spider/database/party_host/party_host.sqlite  \n",
            "  inflating: spider/database/party_host/schema.sql  \n",
            "  inflating: spider/database/party_people/party_people.sqlite  \n",
            "  inflating: spider/database/party_people/schema.sql  \n",
            "  inflating: spider/database/performance_attendance/performance_attendance.sqlite  \n",
            "  inflating: spider/database/performance_attendance/schema.sql  \n",
            "  inflating: spider/database/perpetrator/perpetrator.sqlite  \n",
            "  inflating: spider/database/perpetrator/schema.sql  \n",
            "  inflating: spider/database/pets_1/pets_1.sqlite  \n",
            "  inflating: spider/database/pets_1/schema.sql  \n",
            "  inflating: spider/database/phone_1/phone_1.sqlite  \n",
            "  inflating: spider/database/phone_1/schema.sql  \n",
            "  inflating: spider/database/phone_market/phone_market.sqlite  \n",
            "  inflating: spider/database/phone_market/schema.sql  \n",
            "  inflating: spider/database/pilot_record/pilot_record.sqlite  \n",
            "  inflating: spider/database/pilot_record/schema.sql  \n",
            "  inflating: spider/database/poker_player/poker_player.sqlite  \n",
            "  inflating: spider/database/poker_player/schema.sql  \n",
            "  inflating: spider/database/product_catalog/product_catalog.sqlite  \n",
            "  inflating: spider/database/product_catalog/schema.sql  \n",
            "  inflating: spider/database/products_for_hire/products_for_hire.sqlite  \n",
            "  inflating: spider/database/products_for_hire/schema.sql  \n",
            "  inflating: spider/database/products_gen_characteristics/products_gen_characteristics.sqlite  \n",
            "  inflating: spider/database/products_gen_characteristics/schema.sql  \n",
            "  inflating: spider/database/program_share/program_share.sqlite  \n",
            "  inflating: spider/database/program_share/schema.sql  \n",
            "  inflating: spider/database/protein_institute/protein_institute.sqlite  \n",
            "  inflating: spider/database/protein_institute/schema.sql  \n",
            "  inflating: spider/database/race_track/race_track.sqlite  \n",
            "  inflating: spider/database/race_track/schema.sql  \n",
            "  inflating: spider/database/railway/railway.sqlite  \n",
            "  inflating: spider/database/railway/schema.sql  \n",
            "  inflating: spider/database/real_estate_properties/real_estate_properties.sqlite  \n",
            "  inflating: spider/database/real_estate_properties/schema.sql  \n",
            "  inflating: spider/database/restaurant_1/restaurant_1.sqlite  \n",
            "  inflating: spider/database/restaurant_1/schema.sql  \n",
            "  inflating: spider/database/restaurants/restaurants.sqlite  \n",
            "  inflating: spider/database/restaurants/schema.sql  \n",
            "  inflating: spider/database/riding_club/riding_club.sqlite  \n",
            "  inflating: spider/database/riding_club/schema.sql  \n",
            "  inflating: spider/database/roller_coaster/roller_coaster.sqlite  \n",
            "  inflating: spider/database/roller_coaster/schema.sql  \n",
            "  inflating: spider/database/sakila_1/sakila_1.sqlite  \n",
            "  inflating: spider/database/sakila_1/schema.sql  \n",
            "  inflating: spider/database/scholar/schema.sql  \n",
            "  inflating: spider/database/scholar/scholar.sqlite  \n",
            "  inflating: spider/database/school_bus/schema.sql  \n",
            "  inflating: spider/database/school_bus/school_bus.sqlite  \n",
            "  inflating: spider/database/school_finance/schema.sql  \n",
            "  inflating: spider/database/school_finance/school_finance.sqlite  \n",
            "  inflating: spider/database/school_player/schema.sql  \n",
            "  inflating: spider/database/school_player/school_player.sqlite  \n",
            "  inflating: spider/database/scientist_1/schema.sql  \n",
            "  inflating: spider/database/scientist_1/scientist_1.sqlite  \n",
            "  inflating: spider/database/ship_1/schema.sql  \n",
            "  inflating: spider/database/ship_1/ship_1.sqlite  \n",
            "  inflating: spider/database/ship_mission/schema.sql  \n",
            "  inflating: spider/database/ship_mission/ship_mission.sqlite  \n",
            "  inflating: spider/database/shop_membership/schema.sql  \n",
            "  inflating: spider/database/shop_membership/shop_membership.sqlite  \n",
            "  inflating: spider/database/singer/schema.sql  \n",
            "  inflating: spider/database/singer/singer.sqlite  \n",
            "  inflating: spider/database/small_bank_1/small_bank_1.sqlite  \n",
            "  inflating: spider/database/soccer_1/schema.sql  \n",
            "  inflating: spider/database/soccer_1/soccer_1.sqlite  \n",
            "  inflating: spider/database/soccer_2/schema.sql  \n",
            "  inflating: spider/database/soccer_2/soccer_2.sqlite  \n",
            "  inflating: spider/database/solvency_ii/schema.sql  \n",
            "  inflating: spider/database/solvency_ii/solvency_ii.sqlite  \n",
            "  inflating: spider/database/sports_competition/schema.sql  \n",
            "  inflating: spider/database/sports_competition/sports_competition.sqlite  \n",
            "  inflating: spider/database/station_weather/schema.sql  \n",
            "  inflating: spider/database/station_weather/station_weather.sqlite  \n",
            "  inflating: spider/database/store_1/schema.sql  \n",
            "  inflating: spider/database/store_1/store_1.sqlite  \n",
            "  inflating: spider/database/store_product/schema.sql  \n",
            "  inflating: spider/database/store_product/store_product.sqlite  \n",
            "  inflating: spider/database/storm_record/schema.sql  \n",
            "  inflating: spider/database/storm_record/storm_record.sqlite  \n",
            "  inflating: spider/database/student_1/annotation.json  \n",
            "  inflating: spider/database/student_1/data_csv/README.STUDENTS.TXT  \n",
            "  inflating: spider/database/student_1/data_csv/list.csv  \n",
            "  inflating: spider/database/student_1/data_csv/teachers.csv  \n",
            "  inflating: spider/database/student_1/link.txt  \n",
            "  inflating: spider/database/student_1/q.txt  \n",
            "  inflating: spider/database/student_1/student_1.sql  \n",
            "  inflating: spider/database/student_1/student_1.sqlite  \n",
            "  inflating: spider/database/student_assessment/schema.sql  \n",
            "  inflating: spider/database/student_assessment/student_assessment.sqlite  \n",
            "  inflating: spider/database/student_transcripts_tracking/schema.sql  \n",
            "  inflating: spider/database/student_transcripts_tracking/student_transcripts_tracking.sqlite  \n",
            "  inflating: spider/database/swimming/schema.sql  \n",
            "  inflating: spider/database/swimming/swimming.sqlite  \n",
            "  inflating: spider/database/theme_gallery/schema.sql  \n",
            "  inflating: spider/database/theme_gallery/theme_gallery.sqlite  \n",
            "  inflating: spider/database/tracking_grants_for_research/schema.sql  \n",
            "  inflating: spider/database/tracking_grants_for_research/tracking_grants_for_research.sqlite  \n",
            "  inflating: spider/database/tracking_orders/schema.sql  \n",
            "  inflating: spider/database/tracking_orders/tracking_orders.sqlite  \n",
            "  inflating: spider/database/tracking_share_transactions/schema.sql  \n",
            "  inflating: spider/database/tracking_share_transactions/tracking_share_transactions.sqlite  \n",
            "  inflating: spider/database/tracking_software_problems/schema.sql  \n",
            "  inflating: spider/database/tracking_software_problems/tracking_software_problems.sqlite  \n",
            "  inflating: spider/database/train_station/schema.sql  \n",
            "  inflating: spider/database/train_station/train_station.sqlite  \n",
            "  inflating: spider/database/tvshow/schema.sql  \n",
            "  inflating: spider/database/tvshow/tvshow.sqlite  \n",
            "  inflating: spider/database/twitter_1/queries/oracle-dialects.xml  \n",
            "  inflating: spider/database/twitter_1/queries/postgres-dialects.xml  \n",
            "  inflating: spider/database/twitter_1/queries/sqlserver-dialects.xml  \n",
            "  inflating: spider/database/twitter_1/twitter_1.sqlite  \n",
            "  inflating: spider/database/university_basketball/schema.sql  \n",
            "  inflating: spider/database/university_basketball/university_basketball.sqlite  \n",
            "  inflating: spider/database/voter_1/voter_1.sqlite  \n",
            "  inflating: spider/database/voter_2/schema.sql  \n",
            "  inflating: spider/database/voter_2/voter_2.sqlite  \n",
            "  inflating: spider/database/wedding/schema.sql  \n",
            "  inflating: spider/database/wedding/wedding.sqlite  \n",
            "  inflating: spider/database/wine_1/annotation.json  \n",
            "  inflating: spider/database/wine_1/data_csv/README.WINE.txt  \n",
            "  inflating: spider/database/wine_1/data_csv/appellations.csv  \n",
            "  inflating: spider/database/wine_1/data_csv/grapes.csv  \n",
            "  inflating: spider/database/wine_1/data_csv/wine.csv  \n",
            "  inflating: spider/database/wine_1/link.txt  \n",
            "  inflating: spider/database/wine_1/q.txt  \n",
            "  inflating: spider/database/wine_1/wine_1.sql  \n",
            "  inflating: spider/database/wine_1/wine_1.sqlite  \n",
            "  inflating: spider/database/workshop_paper/schema.sql  \n",
            "  inflating: spider/database/workshop_paper/workshop_paper.sqlite  \n",
            "  inflating: spider/database/world_1/world_1.json  \n",
            "  inflating: spider/database/world_1/world_1.sqlite  \n",
            "  inflating: spider/database/wrestler/schema.sql  \n",
            "  inflating: spider/database/wrestler/wrestler.sqlite  \n",
            "  inflating: spider/database/wta_1/wta_1.sql  \n",
            "  inflating: spider/database/wta_1/wta_1.sqlite  \n",
            "  inflating: spider/database/yelp/schema.sql  \n",
            "  inflating: spider/database/yelp/yelp.sqlite  \n",
            "  inflating: spider/dev.json         \n",
            "  inflating: spider/dev_gold.sql     \n",
            "  inflating: spider/tables.json      \n",
            "  inflating: spider/train_gold.sql   \n",
            "  inflating: spider/train_others.json  \n",
            "  inflating: spider/train_spider.json  \n"
          ]
        }
      ],
      "source": [
        "!unzip Spider_dataset.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data\n",
        "!cd data\n",
        "\n",
        "!wget https://github.com/salesforce/WikiSQL/raw/master/data.tar.bz2\n",
        "\n",
        "!tar -xvf data.tar.bz2\n",
        "\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4MPbBHjWddu",
        "outputId": "ac6b927e-9c62-41ff-ba4c-f1478afc507f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-27 04:25:15--  https://github.com/salesforce/WikiSQL/raw/master/data.tar.bz2\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/salesforce/WikiSQL/master/data.tar.bz2 [following]\n",
            "--2026-01-27 04:25:15--  https://raw.githubusercontent.com/salesforce/WikiSQL/master/data.tar.bz2\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26164664 (25M) [application/octet-stream]\n",
            "Saving to: ‘data.tar.bz2’\n",
            "\n",
            "data.tar.bz2        100%[===================>]  24.95M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2026-01-27 04:25:16 (331 MB/s) - ‘data.tar.bz2’ saved [26164664/26164664]\n",
            "\n",
            "data/\n",
            "data/train.jsonl\n",
            "data/test.tables.jsonl\n",
            "data/test.db\n",
            "data/dev.tables.jsonl\n",
            "data/dev.db\n",
            "data/test.jsonl\n",
            "data/train.tables.jsonl\n",
            "data/train.db\n",
            "data/dev.jsonl\n",
            "data  data.tar.bz2  sample_data  spider  Spider_dataset.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers networkx tqdm sqlparse\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHud665XWdgq",
        "outputId": "b02bc587-3e57-46fc-8b0f-9652117dfc76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.12/dist-packages (0.5.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import json, random, math, os\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "lbzDYQqzWdit"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHLwx0TKAO2R",
        "outputId": "bed27c50-1d9e-42dc-a3db-4dec90acbb0c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spider\n",
        "with open(\"spider/train_spider.json\") as f:\n",
        "    spider_train = json.load(f)\n",
        "\n",
        "with open(\"spider/dev.json\") as f:\n",
        "    spider_dev = json.load(f)\n",
        "\n",
        "with open(\"spider/tables.json\") as f:\n",
        "    spider_tables = json.load(f)\n",
        "\n",
        "print(\"Loaded spider schemas:\", len(spider_tables))\n",
        "\n",
        "# WikiSQL\n",
        "with open(\"data/train.jsonl\") as f:\n",
        "    wikisql_train = [json.loads(x) for x in f]\n",
        "\n",
        "with open(\"data/dev.jsonl\") as f:\n",
        "    wikisql_dev = [json.loads(x) for x in f]\n",
        "\n",
        "print(\"Spider:\", len(spider_train), len(spider_dev))\n",
        "print(\"WikiSQL:\", len(wikisql_train), len(wikisql_dev))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F470oFVaAO4s",
        "outputId": "cfd3a895-0d35-4ad4-b0fb-7e5a134c5170"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded spider schemas: 166\n",
            "Spider: 7000 1034\n",
            "WikiSQL: 56355 8421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlparse\n",
        "def sql_tokenize(sql):\n",
        "    sql = sql.lower()\n",
        "    tokens = [t.value for t in sqlparse.parse(sql)[0].flatten()]\n",
        "    tokens = [t for t in tokens if not t.isspace()]\n",
        "    return tokens\n",
        "print(sql_tokenize(\"SELECT name FROM student WHERE age > 18\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDuONuBiAO7F",
        "outputId": "8eda43e0-24c3-46fd-c673-43e9d11df6e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['select', 'name', 'from', 'student', 'where', 'age', '>', '18']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_VOCAB = {\"<PAD>\":0,\"<UNK>\":1}\n",
        "TGT_VOCAB = {\"<PAD>\":0,\"<BOS>\":1,\"<EOS>\":2,\"<UNK>\":3}\n"
      ],
      "metadata": {
        "id": "_o7m9dGDAO-k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_src(tok):\n",
        "    if tok not in SRC_VOCAB:\n",
        "        SRC_VOCAB[tok] = len(SRC_VOCAB)\n",
        "\n",
        "def add_tgt(tok):\n",
        "    if tok not in TGT_VOCAB:\n",
        "        TGT_VOCAB[tok] = len(TGT_VOCAB)\n"
      ],
      "metadata": {
        "id": "g-08H7IvAqoT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wikisql_to_sql(ex):\n",
        "    \"\"\"\n",
        "    Convert WikiSQL structured SQL into SQL string\n",
        "    \"\"\"\n",
        "    sql = ex[\"sql\"]\n",
        "    table = ex[\"table_id\"]\n",
        "\n",
        "    col = sql[\"sel\"]\n",
        "    agg = sql[\"agg\"]\n",
        "\n",
        "    agg_ops = [\"\", \"MAX\", \"MIN\", \"COUNT\", \"SUM\", \"AVG\"]\n",
        "\n",
        "    select = f\"{agg_ops[agg]}(col{col})\" if agg != 0 else f\"col{col}\"\n",
        "\n",
        "    where = \"\"\n",
        "    if len(sql[\"conds\"]) > 0:\n",
        "        conds = []\n",
        "        for c in sql[\"conds\"]:\n",
        "            conds.append(f\"col{c[0]} {['=','>','<','!='][c[1]]} '{c[2]}'\")\n",
        "        where = \" WHERE \" + \" AND \".join(conds)\n",
        "\n",
        "    return f\"SELECT {select} FROM {table}{where}\"\n"
      ],
      "metadata": {
        "id": "I4gXnySWCjAQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spider_sql_to_full_string(sql, schema):\n",
        "\n",
        "    def col_to_str(cid):\n",
        "        if cid == 0:\n",
        "            return \"*\"\n",
        "        t = schema[\"table_names_original\"][\n",
        "            schema[\"column_names_original\"][cid][0]\n",
        "        ]\n",
        "        c = schema[\"column_names_original\"][cid][1]\n",
        "        return f\"{t}.{c}\"\n",
        "\n",
        "    AGG = [\"\", \"MAX\", \"MIN\", \"COUNT\", \"SUM\", \"AVG\"]\n",
        "    OP  = [\"=\", \">\", \"<\", \"!=\", \">=\", \"<=\", \"LIKE\", \"IN\", \"BETWEEN\"]\n",
        "\n",
        "    def parse_select(sel):\n",
        "        cols = []\n",
        "        for agg, col in sel[1]:\n",
        "            cid = col[1][1]\n",
        "            col_str = col_to_str(cid)\n",
        "            if agg > 0:\n",
        "                cols.append(f\"{AGG[agg]}({col_str})\")\n",
        "            else:\n",
        "                cols.append(col_str)\n",
        "        return \"SELECT \" + \", \".join(cols)\n",
        "\n",
        "    def parse_from(fr):\n",
        "        base = schema[\"table_names_original\"][fr[\"table_units\"][0][1]]\n",
        "        sql = f\" FROM {base}\"\n",
        "\n",
        "        for cond in fr[\"conds\"]:\n",
        "            if cond[1] == 2:  # join\n",
        "                c1 = col_to_str(cond[2][1])\n",
        "                c2 = col_to_str(cond[3][1])\n",
        "                t2 = c2.split(\".\")[0]\n",
        "                sql += f\" JOIN {t2} ON {c1} = {c2}\"\n",
        "\n",
        "        return sql\n",
        "\n",
        "    def parse_where(w):\n",
        "        if not w:\n",
        "            return \"\"\n",
        "        conds = []\n",
        "        for cond in w:\n",
        "            if isinstance(cond, list):\n",
        "                col = col_to_str(cond[2][1])\n",
        "                op  = OP[cond[1]]\n",
        "                val = str(cond[3])\n",
        "                conds.append(f\"{col} {op} {val}\")\n",
        "        return \" WHERE \" + \" AND \".join(conds)\n",
        "\n",
        "    def parse_group(g):\n",
        "        if not g:\n",
        "            return \"\"\n",
        "        cols = [col_to_str(c[1]) for c in g]\n",
        "        return \" GROUP BY \" + \", \".join(cols)\n",
        "\n",
        "    def parse_having(h):\n",
        "        if not h:\n",
        "            return \"\"\n",
        "        conds = []\n",
        "        for cond in h:\n",
        "            col = col_to_str(cond[2][1])\n",
        "            op  = OP[cond[1]]\n",
        "            val = str(cond[3])\n",
        "            conds.append(f\"{col} {op} {val}\")\n",
        "        return \" HAVING \" + \" AND \".join(conds)\n",
        "\n",
        "    def parse_order(o):\n",
        "        if not o:\n",
        "            return \"\"\n",
        "        cols = [col_to_str(c[1]) for c in o[1]]\n",
        "        order = \"DESC\" if o[0] == \"desc\" else \"ASC\"\n",
        "        return \" ORDER BY \" + \", \".join(cols) + \" \" + order\n",
        "\n",
        "    def parse_sql(s):\n",
        "        q = \"\"\n",
        "        q += parse_select(s[\"select\"])\n",
        "        q += parse_from(s[\"from\"])\n",
        "        q += parse_where(s[\"where\"])\n",
        "        q += parse_group(s[\"groupBy\"])\n",
        "        q += parse_having(s[\"having\"])\n",
        "        q += parse_order(s[\"orderBy\"])\n",
        "\n",
        "        if s[\"intersect\"]:\n",
        "            q += \" INTERSECT \" + parse_sql(s[\"intersect\"])\n",
        "        if s[\"union\"]:\n",
        "            q += \" UNION \" + parse_sql(s[\"union\"])\n",
        "        if s[\"except\"]:\n",
        "            q += \" EXCEPT \" + parse_sql(s[\"except\"])\n",
        "\n",
        "        return q\n",
        "\n",
        "    try:\n",
        "        return parse_sql(sql)\n",
        "    except:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "oq1DNvWHGLZS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocab\n",
        "for ex in wikisql_train:\n",
        "    for t in ex[\"question\"].lower().split():\n",
        "        add_src(t)\n",
        "\n",
        "    sql = wikisql_to_sql(ex)\n",
        "    for t in sql_tokenize(sql):\n",
        "        add_tgt(t)\n",
        "\n",
        "for ex in spider_train:\n",
        "    for t in ex[\"query\"].lower().split():\n",
        "        add_src(t)\n",
        "\n",
        "    for t in sql_tokenize(ex[\"query\"]):\n",
        "        add_tgt(t)\n",
        "\n",
        "print(\"SRC vocab:\", len(SRC_VOCAB))\n",
        "print(\"TGT vocab:\", len(TGT_VOCAB))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-r7Quj7AqrI",
        "outputId": "8a6b3c2c-4e1e-4937-ba8a-2e02e1161620"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC vocab: 57658\n",
            "TGT vocab: 52432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Special tokens\n",
        "PAD = \"<PAD>\"\n",
        "BOS = \"<BOS>\"\n",
        "EOS = \"<EOS>\"\n",
        "UNK = \"<UNK>\"\n",
        "\n",
        "# Add to target vocab\n",
        "for t in [PAD, BOS, EOS, UNK]:\n",
        "    if t not in TGT_VOCAB:\n",
        "        TGT_VOCAB[t] = len(TGT_VOCAB)\n",
        "\n",
        "INV_TGT_VOCAB = {v:k for k,v in TGT_VOCAB.items()}\n",
        "\n",
        "PAD_ID = TGT_VOCAB[PAD]\n",
        "BOS_ID = TGT_VOCAB[BOS]\n",
        "EOS_ID = TGT_VOCAB[EOS]\n",
        "UNK_ID = TGT_VOCAB[UNK]\n",
        "\n",
        "# Encode source sentence\n",
        "def encode_src(text, max_len=64):\n",
        "    ids = [SRC_VOCAB.get(t, SRC_VOCAB[UNK]) for t in text.lower().split()]\n",
        "    ids = ids[:max_len]\n",
        "    return ids + [SRC_VOCAB[PAD]] * (max_len - len(ids))\n",
        "\n",
        "# Encode SQL string\n",
        "def encode_tgt(sql, max_len=128):\n",
        "    tokens = sql_tokenize(sql)\n",
        "    ids = [TGT_VOCAB.get(t, UNK_ID) for t in tokens]\n",
        "    ids = [BOS_ID] + ids[:max_len-2] + [EOS_ID]\n",
        "    return ids + [PAD_ID] * (max_len - len(ids))\n",
        "\n",
        "\n",
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, spider_data, wiki_data):\n",
        "        self.samples = []\n",
        "\n",
        "        # WikiSQL\n",
        "        for ex in wiki_data:\n",
        "            nl = ex[\"question\"]\n",
        "            sql = wikisql_to_sql(ex)\n",
        "            self.samples.append((nl, sql))\n",
        "\n",
        "        # Spider\n",
        "        # Spider\n",
        "        for ex in spider_data:\n",
        "            schema = next(db for db in spider_tables if db[\"db_id\"] == ex[\"db_id\"])\n",
        "            sql = spider_sql_to_full_string(ex[\"sql\"], schema)\n",
        "            if sql:\n",
        "                self.samples.append((ex[\"query\"], sql))\n",
        "\n",
        "        print(\"Total training samples:\", len(self.samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        nl, sql = self.samples[idx]\n",
        "\n",
        "        src = torch.tensor(encode_src(nl))\n",
        "        tgt = torch.tensor(encode_tgt(sql))\n",
        "\n",
        "        return src, tgt\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    Seq2SeqDataset(spider_train, wikisql_train),\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    Seq2SeqDataset(spider_dev, wikisql_dev),\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b56cFFZAqt-",
        "outputId": "421e7f70-6e93-4acd-8f45-ebb431aa2e9c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 57658\n",
            "Total training samples: 8619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=512):\n",
        "        super().__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
        "\n",
        "        div = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(pos * div)\n",
        "        pe[:, 1::2] = torch.cos(pos * div)\n",
        "\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "\n",
        "class TransformerSeq2Seq(nn.Module):\n",
        "    def __init__(self, src_vocab, tgt_vocab, hidden=512, layers=6, heads=8, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.src_emb = nn.Embedding(src_vocab, hidden)\n",
        "        self.tgt_emb = nn.Embedding(tgt_vocab, hidden)\n",
        "\n",
        "        self.pos_enc = PositionalEncoding(hidden)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=hidden,\n",
        "            nhead=heads,\n",
        "            num_encoder_layers=layers,\n",
        "            num_decoder_layers=layers,\n",
        "            dim_feedforward=hidden * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden, tgt_vocab)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.pos_enc(self.src_emb(src))\n",
        "        tgt = self.pos_enc(self.tgt_emb(tgt))\n",
        "\n",
        "        tgt_mask = self.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
        "\n",
        "        out = self.transformer(src, tgt, tgt_mask=tgt_mask)\n",
        "        return self.fc_out(out)\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        return torch.triu(torch.ones(sz, sz) * float(\"-inf\"), diagonal=1)\n"
      ],
      "metadata": {
        "id": "CZ7le4etAqxZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = TransformerSeq2Seq(\n",
        "    src_vocab=len(SRC_VOCAB),\n",
        "    tgt_vocab=len(TGT_VOCAB),\n",
        "    hidden=512,\n",
        "    layers=6,\n",
        "    heads=8,\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
        "\n",
        "print(\"Model parameters:\", sum(p.numel() for p in model.parameters()) // 1e6, \"M\")\n",
        "\n",
        "\n",
        "def train_epoch():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for src, tgt in tqdm(train_loader):\n",
        "        src = src.to(device)\n",
        "        tgt = tgt.to(device)\n",
        "\n",
        "        out = model(src, tgt[:, :-1])\n",
        "        loss = criterion(out.reshape(-1, out.size(-1)), tgt[:, 1:].reshape(-1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def eval_epoch():\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in tqdm(val_loader):\n",
        "            src = src.to(device)\n",
        "            tgt = tgt.to(device)\n",
        "\n",
        "            out = model(src, tgt[:, :-1])\n",
        "            loss = criterion(\n",
        "                out.reshape(-1, out.size(-1)),\n",
        "                tgt[:, 1:].reshape(-1)\n",
        "            )\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "print(\"\\n🔥 Training started\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "best_val = float(\"inf\")\n",
        "\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "    train_loss = train_epoch()\n",
        "    val_loss = eval_epoch()\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\")\n",
        "\n",
        "    if val_loss < best_val:\n",
        "        best_val = val_loss\n",
        "        torch.save(model.state_dict(), \"nl2sql_seq2seq_best.pt\")\n",
        "        print(\"✅ Saved BEST model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "cSu2wzArAq2f",
        "outputId": "50f2c118-c36f-4230-f7cf-125184912385"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: 127.0 M\n",
            "\n",
            "🔥 Training started\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1802 [00:00<27:21,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 814.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 242.12 MiB is free. Process 4052 has 14.50 GiB memory in use. Of the allocated memory 13.49 GiB is allocated by PyTorch, and 900.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1619867985.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1619867985.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 814.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 242.12 MiB is free. Process 4052 has 14.50 GiB memory in use. Of the allocated memory 13.49 GiB is allocated by PyTorch, and 900.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3vaifOCRAq5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mIPpql5vAq8m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}