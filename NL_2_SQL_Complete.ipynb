{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal7379/Colab/blob/main/NL_2_SQL_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, json, re, torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "id": "Kqx2G3lHzftu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0474a8-1a93-499e-efef-e5b66a1be782"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, json\n",
        "\n",
        "SCHEMAS = [\n",
        "\n",
        "    {\n",
        "        \"tables\":{\n",
        "            \"employees\":[\"id\",\"name\",\"salary\",\"dept_id\"],\n",
        "            \"departments\":[\"id\",\"name\"]\n",
        "        },\n",
        "        \"join\":(\"employees\",\"departments\",\"dept_id\",\"id\")\n",
        "    },\n",
        "\n",
        "    {\n",
        "        \"tables\":{\n",
        "            \"students\":[\"id\",\"name\",\"marks\",\"class_id\"],\n",
        "            \"classes\":[\"id\",\"name\"]\n",
        "        },\n",
        "        \"join\":(\"students\",\"classes\",\"class_id\",\"id\")\n",
        "    }\n",
        "]\n",
        "\n",
        "AGGS = [\"SUM\",\"AVG\",\"COUNT\",\"MAX\",\"MIN\"]\n",
        "\n",
        "PREFIX = [\n",
        "    \"show\",\"list\",\"display\",\"fetch\",\"give\",\"find\",\"retrieve\",\n",
        "    \"return\",\"provide\",\"get me\",\"can you show\"\n",
        "]\n",
        "\n",
        "COMPARE = [\n",
        "    (\">\",\"greater than\"),\n",
        "    (\"<\",\"less than\"),\n",
        "    (\">=\",\"at least\"),\n",
        "    (\"<=\",\"at most\"),\n",
        "    (\"!=\",\"not equal to\")\n",
        "]\n",
        "\n",
        "\n",
        "############################################\n",
        "# Helper Functions\n",
        "############################################\n",
        "\n",
        "def rand_val():\n",
        "    \"\"\"Generate realistic numeric values\"\"\"\n",
        "    return random.randint(1,10000)\n",
        "\n",
        "\n",
        "def pick_table(schema):\n",
        "    return random.choice(list(schema.keys()))\n",
        "\n",
        "\n",
        "def pick_col(schema, table):\n",
        "    return random.choice(schema[table])\n",
        "\n",
        "\n",
        "############################################\n",
        "# Generator\n",
        "############################################\n",
        "\n",
        "def generate_example():\n",
        "\n",
        "    db = random.choice(SCHEMAS)\n",
        "    schema = db[\"tables\"]\n",
        "\n",
        "    main = pick_table(schema)\n",
        "    cols = schema[main]\n",
        "\n",
        "    intent = random.choice([\n",
        "        \"SELECT\",\"MULTI\",\"WHERE\",\"OR\",\n",
        "        \"AGG\",\"GROUP\",\n",
        "        \"ORDER\",\"LIMIT\",\n",
        "        \"JOIN\",\"JOIN_WHERE\",\n",
        "        \"NESTED\"\n",
        "    ])\n",
        "\n",
        "    prefix = random.choice(PREFIX)\n",
        "\n",
        "    ##################################\n",
        "    # SELECT\n",
        "    ##################################\n",
        "\n",
        "    if intent==\"SELECT\":\n",
        "\n",
        "        col = pick_col(schema, main)\n",
        "\n",
        "        q = f\"{prefix} {col} from {main}\"\n",
        "        sql = f\"SELECT {col} FROM {main}\"\n",
        "\n",
        "\n",
        "    ##################################\n",
        "    # MULTI\n",
        "    ##################################\n",
        "\n",
        "    elif intent==\"MULTI\":\n",
        "\n",
        "        c1, c2 = random.sample(cols,2)\n",
        "\n",
        "        q = f\"{prefix} {c1} and {c2} from {main}\"\n",
        "        sql = f\"SELECT {c1}, {c2} FROM {main}\"\n",
        "\n",
        "\n",
        "    ##################################\n",
        "    # WHERE\n",
        "    ##################################\n",
        "\n",
        "    elif intent==\"WHERE\":\n",
        "\n",
        "        col = pick_col(schema, main)\n",
        "        op, text = random.choice(COMPARE)\n",
        "        val = rand_val()\n",
        "\n",
        "        q = f\"{prefix} {main} where {col} is {text} {val}\"\n",
        "        sql = f\"SELECT * FROM {main} WHERE {col} {op} {val}\"\n",
        "\n",
        "\n",
        "    ##################################\n",
        "    # OR\n",
        "    ##################################\n",
        "\n",
        "    elif intent==\"OR\":\n",
        "\n",
        "        c1, c2 = random.sample(cols,2)\n",
        "        v1, v2 = rand_val(), rand_val()\n",
        "\n",
        "        q = f\"{prefix} {main} where {c1} > {v1} or {c2} > {v2}\"\n",
        "        sql = f\"SELECT * FROM {main} WHERE {c1} > {v1} OR {c2} > {v2}\"\n",
        "\n",
        "\n",
        "    ##################################\n",
        "    # AGG\n",
        "    ##################################\n",
        "\n",
        "    elif intent==\"AGG\":\n",
        "\n",
        "        col = pick_col(schema, main)\n",
        "        agg = random.choice(AGGS)\n",
        "\n",
        "        q = f\"what is the {agg.lower()} of {col} in {main}\"\n",
        "        sql = f\"SELECT {agg}({col}) FROM {main}\"\n",
        "\n",
        "\n",
        "    ##################################\n",
        "    # GROUP BY\n",
        "    ##################################\n",
        "\n",
        "    elif intent==\"GROUP\":\n",
        "\n",
        "        group_col = pick_col(schema, main)\n",
        "        agg_col = pick_col(schema, main)\n",
        "        agg = random.choice(AGGS)\n",
        "\n",
        "        q = f\"{prefix} {agg.lower()} {agg_col} grouped by {group_col}\"\n",
        "        sql = f\"SELECT {group_col}, {agg}({agg_col}) FROM {main} GROUP BY {group_col}\"\n",
        "\n",
        "\n",
        "    ##################################\n",
        "    # ORDER\n",
        "    ##################################\n",
        "\n",
        "    elif intent==\"ORDER\":\n",
        "\n",
        "        col = pick_col(schema, main)\n",
        "\n",
        "        q = f\"{prefix} {main} ordered by {col}\"\n",
        "        sql = f\"SELECT * FROM {main} ORDER BY {col} DESC\"\n",
        "\n",
        "\n",
        "    ##################################\n",
        "    # LIMIT\n",
        "    ##################################\n",
        "\n",
        "    elif intent==\"LIMIT\":\n",
        "\n",
        "        col = pick_col(schema, main)\n",
        "        limit = random.randint(1,20)\n",
        "\n",
        "        q = f\"{prefix} top {limit} rows from {main} by {col}\"\n",
        "        sql = f\"SELECT * FROM {main} ORDER BY {col} DESC LIMIT {limit}\"\n",
        "\n",
        "\n",
        "    ##################################\n",
        "    # JOIN\n",
        "    ##################################\n",
        "\n",
        "    elif intent==\"JOIN\" and \"join\" in db:\n",
        "\n",
        "        t1,t2,c1,c2 = db[\"join\"]\n",
        "\n",
        "        col1 = pick_col(schema, t1)\n",
        "        col2 = pick_col(schema, t2)\n",
        "\n",
        "        q = f\"{prefix} {t1} with their {t2}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT {t1}.{col1}, {t2}.{col2}\n",
        "        FROM {t1}\n",
        "        JOIN {t2}\n",
        "        ON {t1}.{c1} = {t2}.{c2}\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    ##################################\n",
        "    # JOIN WHERE\n",
        "    ##################################\n",
        "\n",
        "    elif intent==\"JOIN_WHERE\" and \"join\" in db:\n",
        "\n",
        "        t1,t2,c1,c2 = db[\"join\"]\n",
        "\n",
        "        col = pick_col(schema, t2)\n",
        "        val = rand_val()\n",
        "\n",
        "        q = f\"{prefix} {t1} where {t2} {col} is greater than {val}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT *\n",
        "        FROM {t1}\n",
        "        JOIN {t2}\n",
        "        ON {t1}.{c1} = {t2}.{c2}\n",
        "        WHERE {t2}.{col} > {val}\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    ##################################\n",
        "    # NESTED\n",
        "    ##################################\n",
        "\n",
        "    else:\n",
        "\n",
        "        col = pick_col(schema, main)\n",
        "\n",
        "        q = f\"{prefix} {main} where {col} is greater than average\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT *\n",
        "        FROM {main}\n",
        "        WHERE {col} >\n",
        "        (SELECT AVG({col}) FROM {main})\n",
        "        \"\"\"\n",
        "\n",
        "    return {\n",
        "        \"question\": q.lower(),\n",
        "        \"schema\": schema,\n",
        "        \"sql\": \" \".join(sql.split())\n",
        "    }\n",
        "\n",
        "\n",
        "############################################\n",
        "# Generate Dataset\n",
        "############################################\n",
        "\n",
        "DATA = [generate_example() for _ in range(150000)]\n",
        "\n",
        "with open(\"nl2sql_data.json\",\"w\") as f:\n",
        "    json.dump(DATA,f)\n",
        "\n",
        "print(\"ðŸ”¥ ULTRA high-quality dataset generated!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7TJQFl7zfwC",
        "outputId": "92006588-e98d-4458-a880-c26dbf13489c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¥ ULTRA high-quality dataset generated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"nl2sql_data.json\") as f:\n",
        "    DATA = json.load(f)\n"
      ],
      "metadata": {
        "id": "1ohQlFN6os-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENC_VOCAB={\"<PAD>\":0,\"<UNK>\":1,\"<SEP>\":2}\n",
        "DEC_VOCAB={\"<PAD>\":0,\"<UNK>\":1,\"<BOS>\":2,\"<EOS>\":3}\n",
        "\n",
        "def add(vocab,t):\n",
        "    if t not in vocab:\n",
        "        vocab[t]=len(vocab)\n",
        "\n",
        "\n",
        "def sql_tokenize(sql):\n",
        "\n",
        "    return re.findall(\n",
        "        r\"[A-Za-z_]+\\.[A-Za-z_]+\"     # table.column\n",
        "        r\"|>=|<=|!=|=|>|<\"\n",
        "        r\"|\\bselect\\b|\\bfrom\\b|\\bwhere\\b|\\bjoin\\b|\\bon\\b\"\n",
        "        r\"|\\bgroup\\b|\\bby\\b|\\bhaving\\b|\\border\\b|\\blimit\\b\"\n",
        "        r\"|\\bavg\\b|\\bsum\\b|\\bcount\\b|\\bmax\\b|\\bmin\\b\"\n",
        "        r\"|\\*\"\n",
        "        r\"|\\(|\\)|,\"\n",
        "        r\"|[A-Za-z_]+\"\n",
        "        r\"|\\d+\",\n",
        "        sql.lower()\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "for ex in DATA:\n",
        "\n",
        "    for t in ex[\"question\"].split():\n",
        "        add(ENC_VOCAB,t)\n",
        "\n",
        "    for t,cols in ex[\"schema\"].items():\n",
        "        add(ENC_VOCAB,t)\n",
        "        for c in cols:\n",
        "            add(ENC_VOCAB,f\"{t}.{c}\")\n",
        "\n",
        "    for tok in sql_tokenize(ex[\"sql\"]):\n",
        "        add(DEC_VOCAB,tok)\n",
        "\n",
        "print(len(ENC_VOCAB),len(DEC_VOCAB))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAYyVGbozfyU",
        "outputId": "8428de22-8941-4aa4-aadb-b4dda58b6990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10028 10010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NL2SQLDataset(Dataset):\n",
        "\n",
        "    def __init__(self,data):\n",
        "        self.data=data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "\n",
        "        ex=self.data[i]\n",
        "\n",
        "        src = ex[\"question\"].split()+[\"<SEP>\"]+[\n",
        "            f\"{t}.{c}\"\n",
        "            for t,cs in ex[\"schema\"].items()\n",
        "            for c in cs\n",
        "        ]\n",
        "\n",
        "        src_ids=[ENC_VOCAB.get(t,1) for t in src][:160]\n",
        "        src_ids+=[0]*(160-len(src_ids))\n",
        "\n",
        "\n",
        "        tgt=[DEC_VOCAB[\"<BOS>\"]] + \\\n",
        "            [DEC_VOCAB.get(t,1) for t in sql_tokenize(ex[\"sql\"])] + \\\n",
        "            [DEC_VOCAB[\"<EOS>\"]]\n",
        "\n",
        "        tgt=tgt[:80]\n",
        "        tgt+=[0]*(80-len(tgt))\n",
        "\n",
        "        return torch.tensor(src_ids),torch.tensor(tgt)\n"
      ],
      "metadata": {
        "id": "i3unPFzSOr5r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_MODEL=384\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,d_model,max_len=512):\n",
        "        super().__init__()\n",
        "\n",
        "        pe=torch.zeros(max_len,d_model)\n",
        "\n",
        "        pos=torch.arange(0,max_len).unsqueeze(1)\n",
        "\n",
        "        div=torch.exp(\n",
        "            torch.arange(0,d_model,2) *\n",
        "            (-torch.log(torch.tensor(10000.0))/d_model)\n",
        "        )\n",
        "\n",
        "        pe[:,0::2]=torch.sin(pos*div)\n",
        "        pe[:,1::2]=torch.cos(pos*div)\n",
        "\n",
        "        self.pe=pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return x+self.pe[:,:x.size(1)].to(x.device)\n"
      ],
      "metadata": {
        "id": "JiLHAFAazf1r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self,vocab):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb=nn.Embedding(vocab,D_MODEL,padding_idx=0)\n",
        "        self.pos=PositionalEncoding(D_MODEL)\n",
        "\n",
        "        layer=nn.TransformerEncoderLayer(\n",
        "            D_MODEL,8,1536,\n",
        "            dropout=0.1,\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "\n",
        "        self.enc=nn.TransformerEncoder(layer,4)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        mask=(x==0)\n",
        "\n",
        "        x=self.pos(self.emb(x))\n",
        "\n",
        "        return self.enc(x,src_key_padding_mask=mask)\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self,vocab):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb=nn.Embedding(vocab,D_MODEL)\n",
        "        self.pos=PositionalEncoding(D_MODEL)\n",
        "\n",
        "        layer=nn.TransformerDecoderLayer(\n",
        "            D_MODEL,8,1536,\n",
        "            dropout=0.1,\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "\n",
        "        self.dec=nn.TransformerDecoder(layer,4)\n",
        "\n",
        "        self.fc=nn.Linear(D_MODEL,vocab)\n",
        "\n",
        "        self.fc.weight=self.emb.weight\n",
        "\n",
        "    def forward(self,y,mem,mask):\n",
        "\n",
        "        L=y.size(1)\n",
        "\n",
        "        causal=torch.triu(\n",
        "            torch.ones(L,L,device=y.device),1\n",
        "        ).bool()\n",
        "\n",
        "        y=self.pos(self.emb(y))\n",
        "\n",
        "        return self.fc(\n",
        "            self.dec(\n",
        "                y,mem,\n",
        "                tgt_mask=causal,\n",
        "                memory_key_padding_mask=mask\n",
        "            )\n",
        "        )\n"
      ],
      "metadata": {
        "id": "5bz9c27-zmHh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train,val=train_test_split(DATA,test_size=0.1,random_state=42)\n",
        "\n",
        "train_loader=DataLoader(\n",
        "    NL2SQLDataset(train),\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader=DataLoader(\n",
        "    NL2SQLDataset(val),\n",
        "    batch_size=64\n",
        ")\n"
      ],
      "metadata": {
        "id": "dPc-y-VozmJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc=Encoder(len(ENC_VOCAB)).to(device)\n",
        "dec=Decoder(len(DEC_VOCAB)).to(device)\n",
        "\n",
        "optimizer=optim.AdamW(\n",
        "    list(enc.parameters())+list(dec.parameters()),\n",
        "    lr=1e-4\n",
        ")\n",
        "\n",
        "scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer,T_max=15\n",
        ")\n",
        "\n",
        "loss_fn=nn.CrossEntropyLoss(\n",
        "    ignore_index=0,\n",
        "    label_smoothing=0.05\n",
        ")\n",
        "\n",
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = \"checkpoint.pt\"\n",
        "\n",
        "start_epoch = 0\n",
        "\n",
        "############################################\n",
        "# âœ… RESUME IF CHECKPOINT EXISTS\n",
        "############################################\n",
        "\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "\n",
        "    print(\"âœ… Resuming from checkpoint...\\n\")\n",
        "\n",
        "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "\n",
        "    enc.load_state_dict(checkpoint[\"encoder\"])\n",
        "    dec.load_state_dict(checkpoint[\"decoder\"])\n",
        "\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "    scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
        "\n",
        "    start_epoch = checkpoint[\"epoch\"] + 1\n",
        "\n",
        "    print(f\"Resuming from Epoch {start_epoch}\\n\")\n",
        "\n",
        "\n",
        "print(\"ðŸš€ Training...\\n\")\n",
        "\n",
        "EPOCHS = 15\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "\n",
        "    #################################\n",
        "    # TRAIN\n",
        "    #################################\n",
        "    enc.train()\n",
        "    dec.train()\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        mem = enc(x)\n",
        "\n",
        "        out = dec(y[:, :-1], mem, (x == 0))\n",
        "\n",
        "        loss = loss_fn(\n",
        "            out.reshape(-1, len(DEC_VOCAB)),\n",
        "            y[:, 1:].reshape(-1)\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            list(enc.parameters()) + list(dec.parameters()),\n",
        "            1.0\n",
        "        )\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    #################################\n",
        "    # VALIDATION\n",
        "    #################################\n",
        "    enc.eval()\n",
        "    dec.eval()\n",
        "\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for x, y in val_loader:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            mem = enc(x)\n",
        "\n",
        "            out = dec(y[:, :-1], mem, (x == 0))\n",
        "\n",
        "            val_loss += loss_fn(\n",
        "                out.reshape(-1, len(DEC_VOCAB)),\n",
        "                y[:, 1:].reshape(-1)\n",
        "            ).item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    #################################\n",
        "    print(f\"\"\"\n",
        "Epoch {epoch+1}\n",
        "\n",
        "Train Loss: {train_loss:.3f}\n",
        "Val Loss:   {val_loss:.3f}\n",
        "\"\"\")\n",
        "    #################################\n",
        "\n",
        "    ################################################\n",
        "    # âœ… SAVE CHECKPOINT AFTER EVERY EPOCH\n",
        "    ################################################\n",
        "\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"encoder\": enc.state_dict(),\n",
        "        \"decoder\": dec.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "        \"scheduler\": scheduler.state_dict(),\n",
        "        \"enc_vocab\": ENC_VOCAB,\n",
        "        \"dec_vocab\": DEC_VOCAB\n",
        "    }, CHECKPOINT_PATH)\n",
        "\n",
        "    print(\"âœ… Checkpoint Saved!\\n\")\n",
        "\n",
        "print(\"ðŸŽ‰ TRAINING COMPLETE\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9M1Qw4jfzmMk",
        "outputId": "77a2a51b-f9ac-4f51-b6ea-be91327359ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Resuming from checkpoint...\n",
            "\n",
            "Resuming from Epoch 8\n",
            "\n",
            "ðŸš€ Training...\n",
            "\n",
            "\n",
            "Epoch 9\n",
            "\n",
            "Train Loss: 0.750\n",
            "Val Loss:   0.733\n",
            "\n",
            "âœ… Checkpoint Saved!\n",
            "\n",
            "\n",
            "Epoch 10\n",
            "\n",
            "Train Loss: 0.739\n",
            "Val Loss:   0.728\n",
            "\n",
            "âœ… Checkpoint Saved!\n",
            "\n",
            "\n",
            "Epoch 11\n",
            "\n",
            "Train Loss: 0.731\n",
            "Val Loss:   0.728\n",
            "\n",
            "âœ… Checkpoint Saved!\n",
            "\n",
            "\n",
            "Epoch 12\n",
            "\n",
            "Train Loss: 0.725\n",
            "Val Loss:   0.722\n",
            "\n",
            "âœ… Checkpoint Saved!\n",
            "\n",
            "\n",
            "Epoch 13\n",
            "\n",
            "Train Loss: 0.721\n",
            "Val Loss:   0.720\n",
            "\n",
            "âœ… Checkpoint Saved!\n",
            "\n",
            "\n",
            "Epoch 14\n",
            "\n",
            "Train Loss: 0.717\n",
            "Val Loss:   0.720\n",
            "\n",
            "âœ… Checkpoint Saved!\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4122130863.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         torch.nn.utils.clip_grad_norm_(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "CHECKPOINT_PATH = \"checkpoint.pt\"\n",
        "\n",
        "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "\n",
        "# Restore vocab\n",
        "ENC_VOCAB = checkpoint[\"enc_vocab\"]\n",
        "DEC_VOCAB = checkpoint[\"dec_vocab\"]\n",
        "\n",
        "inv_dec_vocab = {v:k for k,v in DEC_VOCAB.items()}\n",
        "\n",
        "# Rebuild models\n",
        "enc = Encoder(len(ENC_VOCAB)).to(device)\n",
        "dec = Decoder(len(DEC_VOCAB)).to(device)\n",
        "\n",
        "enc.load_state_dict(checkpoint[\"encoder\"])\n",
        "dec.load_state_dict(checkpoint[\"decoder\"])\n",
        "\n",
        "enc.eval()\n",
        "dec.eval()\n",
        "\n",
        "print(\"âœ… Model restored. Ready for inference.\")\n"
      ],
      "metadata": {
        "id": "QUMijMJWzmRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6db713-cc49-4518-c4a8-ed5947c0535a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model restored. Ready for inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_sql(question, schema, max_len=80):\n",
        "\n",
        "    enc.eval()\n",
        "    dec.eval()\n",
        "\n",
        "    tokens = question.lower().split() + [\"<SEP>\"] + [\n",
        "        f\"{t}.{c}\" for t,cs in schema.items() for c in cs\n",
        "    ]\n",
        "\n",
        "    ids = [ENC_VOCAB.get(t,1) for t in tokens][:120]\n",
        "    ids += [0]*(120-len(ids))\n",
        "\n",
        "    x = torch.tensor(ids).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        memory = enc(x)\n",
        "\n",
        "        y = torch.tensor([[DEC_VOCAB[\"<BOS>\"]]], device=device)\n",
        "\n",
        "        generated = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "\n",
        "            out = dec(y, memory, (x==0))\n",
        "\n",
        "            logits = out[:,-1,:]\n",
        "\n",
        "            idx = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            token = inv_dec_vocab[idx.item()]\n",
        "\n",
        "            if token == \"<EOS>\":\n",
        "                break\n",
        "\n",
        "            if token not in [\"<PAD>\", \"<BOS>\"]:\n",
        "                generated.append(token)\n",
        "\n",
        "            y = torch.cat([y, idx.view(1,1)], dim=1)\n",
        "\n",
        "    return \" \".join(generated)\n"
      ],
      "metadata": {
        "id": "-z46WNE9zmV6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema1 = {\n",
        "    \"employees\":[\"id\",\"name\",\"salary\",\"dept_id\"],\n",
        "    \"departments\":[\"id\",\"name\"]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "print(infer_sql(\n",
        "    \"list name and salary of employees\",\n",
        "    schema1\n",
        "))\n",
        "print(infer_sql(\n",
        "    \"show employees earning more than average salary\",\n",
        "    schema1\n",
        "))\n",
        "print(infer_sql(\n",
        "    \"what is count of dept_id of employees grouped by dept_id\",\n",
        "    schema1\n",
        "))\n",
        "print(infer_sql(\n",
        "    \"what is max of salary in employees\",\n",
        "    schema1\n",
        "))\n",
        "print(infer_sql(\n",
        "    \"show employees in departments where id > 8\",\n",
        "    schema1\n",
        "))\n",
        "print(infer_sql(\"show employees where salary is greater than 5000\", schema1))\n",
        "\n",
        "print(infer_sql(\"list employees where id is less than 30\", schema1))\n",
        "\n",
        "print(infer_sql(\"get employees ordered by salary\", schema1))\n",
        "\n",
        "print(infer_sql(\"show top 3 employees by salary\", schema1))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TbQjO_eVzmYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b812cb9e-250e-4d23-8dd7-2e8d75dfecbe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "select name , salary from employees\n",
            "select * from employees where salary > ( select avg ( salary ) from employees )\n",
            "select dept_id , count ( dept_id ) from employees group by dept_id\n",
            "select max ( salary ) from employees\n",
            "select * from employees join departments on employees.dept_id = departments.id where departments.id > 8\n",
            "select * from employees where salary > 5000\n",
            "select * from employees where id < 30\n",
            "select * from employees order by salary desc\n",
            "select * from employees order by salary desc limit 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kDcGyh8WzmbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2adpLS7czmdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LY0L9-rozmf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oYODFX_czmir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pe0S1B5KzmlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-segFiZuzmnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DioIS7vzmqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3VTaws_azms2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AXdliymTzmwS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}