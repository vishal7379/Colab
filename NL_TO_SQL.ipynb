{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal7379/Colab/blob/main/NL_TO_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, json\n",
        "\n",
        "# =====================================================\n",
        "# SCHEMAS\n",
        "# =====================================================\n",
        "\n",
        "SCHEMAS = [\n",
        "\n",
        "    {\n",
        "        \"tables\":{\n",
        "            \"employees\":[\"id\",\"name\",\"salary\",\"dept_id\",\"age\",\"experience\"],\n",
        "            \"departments\":[\"id\",\"name\",\"location\"]\n",
        "        },\n",
        "        \"join\":(\"employees\",\"departments\",\"dept_id\",\"id\")\n",
        "    },\n",
        "\n",
        "    {\n",
        "        \"tables\":{\n",
        "            \"students\":[\"id\",\"name\",\"marks\",\"class_id\",\"age\"],\n",
        "            \"classes\":[\"id\",\"name\",\"teacher\"]\n",
        "        },\n",
        "        \"join\":(\"students\",\"classes\",\"class_id\",\"id\")\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# LANGUAGE POOLS (VOCAB BOOSTERS üöÄ)\n",
        "# =====================================================\n",
        "\n",
        "PREFIX = [\n",
        "    \"show\",\"list\",\"display\",\"fetch\",\"give\",\"retrieve\",\n",
        "    \"provide\",\"return\",\"output\",\"present\",\"find\",\n",
        "    \"identify\",\"tell me\",\"can you show\",\"i want\",\n",
        "    \"help me find\",\"get me\",\"let me know\"\n",
        "]\n",
        "\n",
        "QUESTION_STYLE = [\n",
        "    \"{} {} from {}\",\n",
        "    \"{} all {} from {}\",\n",
        "    \"{} the {} available in {}\",\n",
        "    \"what are the {} in {}\",\n",
        "    \"which {} exist in {}\"\n",
        "]\n",
        "\n",
        "COLUMN_SYNONYMS = {\n",
        "    \"salary\":[\"salary\",\"income\",\"pay\",\"earnings\",\"compensation\"],\n",
        "    \"name\":[\"name\",\"full name\",\"employee name\",\"student name\"],\n",
        "    \"age\":[\"age\",\"years\",\"age value\"],\n",
        "    \"marks\":[\"marks\",\"score\",\"grades\",\"result\"],\n",
        "    \"experience\":[\"experience\",\"years of experience\"]\n",
        "}\n",
        "\n",
        "COMPARE = [\n",
        "    (\">\",\"greater than\"),\n",
        "    (\"<\",\"less than\"),\n",
        "    (\">=\",\"at least\"),\n",
        "    (\"<=\",\"at most\"),\n",
        "    (\"!=\",\"not equal to\")\n",
        "]\n",
        "\n",
        "AGGS = [\"SUM\",\"AVG\",\"COUNT\",\"MAX\",\"MIN\"]\n",
        "\n",
        "ORDER_WORDS = [\n",
        "    \"ordered by\",\"sorted by\",\"arranged by\",\n",
        "    \"ranked by\",\"organized by\"\n",
        "]\n",
        "\n",
        "# ‚≠ê Names for nested / equality queries\n",
        "EMP_NAMES = [\n",
        "    \"ravi\",\"rahul\",\"amit\",\"neha\",\n",
        "    \"arjun\",\"vikram\",\"john\",\"sara\"\n",
        "]\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# HELPER FUNCTIONS\n",
        "# =====================================================\n",
        "\n",
        "def col_word(col):\n",
        "    if col in COLUMN_SYNONYMS:\n",
        "        return random.choice(COLUMN_SYNONYMS[col])\n",
        "    return col\n",
        "\n",
        "\n",
        "def question(template, prefix, col, table):\n",
        "    return template.format(prefix, col_word(col), table)\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# GENERATOR\n",
        "# =====================================================\n",
        "\n",
        "def generate_example():\n",
        "\n",
        "    db=random.choice(SCHEMAS)\n",
        "\n",
        "    schema=db[\"tables\"]\n",
        "    t1,t2,c1,c2=db[\"join\"]\n",
        "\n",
        "    main=t1\n",
        "    cols=schema[main]\n",
        "\n",
        "    prefix=random.choice(PREFIX)\n",
        "\n",
        "    intent=random.choice([\n",
        "        \"SELECT\",\"MULTI\",\"WHERE\",\"BETWEEN\",\n",
        "\n",
        "        # ‚≠ê NEW\n",
        "        \"EQUALITY_VALUE\",\n",
        "        \"EQUALITY_NAME\",\n",
        "\n",
        "        \"AGG\",\"GROUP\",\"ORDER\",\"LIMIT\",\n",
        "\n",
        "        \"JOIN\",\"LEFT_JOIN\",\"JOIN_WHERE\",\n",
        "        \"JOIN_GROUP\",\n",
        "\n",
        "        \"NESTED\",\n",
        "\n",
        "        # ‚≠ê VERY IMPORTANT\n",
        "        \"NESTED_PERSON_COMPARE\",\n",
        "\n",
        "        \"CORRELATED\",\n",
        "        \"EXISTS\"\n",
        "    ])\n",
        "\n",
        "    col=random.choice(cols)\n",
        "\n",
        "    # =====================================================\n",
        "    # SIMPLE SELECT\n",
        "    # =====================================================\n",
        "\n",
        "    if intent==\"SELECT\":\n",
        "\n",
        "        q=question(\n",
        "            random.choice(QUESTION_STYLE),\n",
        "            prefix,col,main\n",
        "        )\n",
        "\n",
        "        sql=f\"SELECT {col} FROM {main}\"\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # MULTI COLUMN\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"MULTI\":\n",
        "\n",
        "        c1_,c2_=random.sample(cols,2)\n",
        "\n",
        "        q=f\"{prefix} {col_word(c1_)} and {col_word(c2_)} from {main}\"\n",
        "\n",
        "        sql=f\"SELECT {c1_}, {c2_} FROM {main}\"\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # WHERE\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"WHERE\":\n",
        "\n",
        "        op,text=random.choice(COMPARE)\n",
        "        val=random.randint(10,100)\n",
        "\n",
        "        q=f\"{prefix} {main} where {col_word(col)} is {text} {val}\"\n",
        "\n",
        "        sql=f\"SELECT name FROM {main} WHERE {col} {op} {val}\"\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # BETWEEN\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"BETWEEN\":\n",
        "\n",
        "        low=random.randint(10,40)\n",
        "        high=random.randint(50,100)\n",
        "\n",
        "        q=f\"{prefix} {main} with {col_word(col)} between {low} and {high}\"\n",
        "\n",
        "        sql=f\"SELECT name FROM {main} WHERE {col} BETWEEN {low} AND {high}\"\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # ‚≠ê EQUALITY VALUE\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"EQUALITY_VALUE\":\n",
        "\n",
        "        val=random.randint(10,100)\n",
        "\n",
        "        q=f\"{prefix} {main} where {col_word(col)} equals {val}\"\n",
        "\n",
        "        sql=f\"SELECT name FROM {main} WHERE {col} = {val}\"\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # ‚≠ê EQUALITY NAME\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"EQUALITY_NAME\":\n",
        "\n",
        "        person=random.choice(EMP_NAMES)\n",
        "\n",
        "        q=f\"{prefix} {main} named {person}\"\n",
        "\n",
        "        sql=f\"SELECT * FROM {main} WHERE name = '{person.capitalize()}'\"\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # AGG\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"AGG\":\n",
        "\n",
        "        agg=random.choice(AGGS)\n",
        "\n",
        "        q=f\"what is the {agg.lower()} of {col_word(col)} in {main}\"\n",
        "\n",
        "        sql=f\"SELECT {agg}({col}) FROM {main}\"\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # GROUP\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"GROUP\":\n",
        "\n",
        "        agg=random.choice(AGGS)\n",
        "\n",
        "        q=f\"{prefix} {agg.lower()} salary grouped by dept\"\n",
        "\n",
        "        sql=f\"SELECT dept_id, {agg}(salary) FROM {main} GROUP BY dept_id\"\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # ORDER\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"ORDER\":\n",
        "\n",
        "        q=f\"{prefix} {main} {random.choice(ORDER_WORDS)} {col_word(col)}\"\n",
        "\n",
        "        sql=f\"SELECT name FROM {main} ORDER BY {col} DESC\"\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # LIMIT\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"LIMIT\":\n",
        "\n",
        "        n=random.randint(3,10)\n",
        "\n",
        "        q=f\"{prefix} top {n} {main} by {col_word(col)}\"\n",
        "\n",
        "        sql=f\"SELECT name FROM {main} ORDER BY {col} DESC LIMIT {n}\"\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # JOIN\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"JOIN\":\n",
        "\n",
        "        pattern=random.randint(1,4)\n",
        "\n",
        "        if pattern==1:\n",
        "            q=f\"{prefix} {t1} with their {t2}\"\n",
        "            sql=f\"SELECT {t1}.name, {t2}.name FROM {t1} JOIN {t2} ON {t1}.{c1} = {t2}.{c2}\"\n",
        "\n",
        "        elif pattern==2:\n",
        "            q=f\"{prefix} {t2} along with related {t1}\"\n",
        "            sql=f\"SELECT {t2}.name, {t1}.name FROM {t2} JOIN {t1} ON {t2}.{c2} = {t1}.{c1}\"\n",
        "\n",
        "        elif pattern==3:\n",
        "            q=f\"{prefix} records combining {t1} and {t2}\"\n",
        "            sql=f\"SELECT * FROM {t1} INNER JOIN {t2} ON {t1}.{c1} = {t2}.{c2}\"\n",
        "\n",
        "        else:\n",
        "            q=f\"{prefix} {t1} mapped to their departments\"\n",
        "            sql=f\"SELECT {t1}.name, {t2}.location FROM {t1} JOIN {t2} ON {t1}.{c1} = {t2}.{c2}\"\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # LEFT JOIN\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"LEFT_JOIN\":\n",
        "\n",
        "        q=f\"{prefix} all {t1} even if department missing\"\n",
        "\n",
        "        sql=f\"SELECT {t1}.name FROM {t1} LEFT JOIN {t2} ON {t1}.{c1} = {t2}.{c2}\"\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # JOIN WHERE\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"JOIN_WHERE\":\n",
        "\n",
        "        val=random.randint(1,5)\n",
        "\n",
        "        q=f\"{prefix} {t1} working in departments where id > {val}\"\n",
        "\n",
        "        sql=f\"\"\"\n",
        "        SELECT {t1}.name, {t2}.name\n",
        "        FROM {t1}\n",
        "        JOIN {t2}\n",
        "        ON {t1}.{c1} = {t2}.{c2}\n",
        "        WHERE {t2}.id > {val}\n",
        "        \"\"\".replace(\"\\n\",\" \")\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # JOIN GROUP\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"JOIN_GROUP\":\n",
        "\n",
        "        q=f\"{prefix} number of {t1} per {t2}\"\n",
        "\n",
        "        sql=f\"\"\"\n",
        "        SELECT {t2}.name, COUNT(*)\n",
        "        FROM {t1}\n",
        "        JOIN {t2}\n",
        "        ON {t1}.{c1} = {t2}.{c2}\n",
        "        GROUP BY {t2}.name\n",
        "        \"\"\".replace(\"\\n\",\" \")\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # NESTED AVG/MAX/MIN\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"NESTED\":\n",
        "\n",
        "        agg=random.choice([\"AVG\",\"MAX\",\"MIN\"])\n",
        "\n",
        "        q=f\"{prefix} {main} earning above {agg.lower()} salary\"\n",
        "\n",
        "        sql=f\"\"\"\n",
        "        SELECT name\n",
        "        FROM {main}\n",
        "        WHERE salary >\n",
        "        (SELECT {agg}(salary) FROM {main})\n",
        "        \"\"\".replace(\"\\n\",\" \")\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # ‚≠ê NESTED PERSON COMPARISON\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"NESTED_PERSON_COMPARE\":\n",
        "\n",
        "        person=random.choice(EMP_NAMES)\n",
        "\n",
        "        q=f\"{prefix} employees earning more than {person}\"\n",
        "\n",
        "        sql=f\"\"\"\n",
        "        SELECT name\n",
        "        FROM employees\n",
        "        WHERE salary >\n",
        "        (\n",
        "            SELECT salary\n",
        "            FROM employees\n",
        "            WHERE name = '{person.capitalize()}'\n",
        "        )\n",
        "        \"\"\".replace(\"\\n\",\" \")\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # CORRELATED\n",
        "    # =====================================================\n",
        "\n",
        "    elif intent==\"CORRELATED\":\n",
        "\n",
        "        q=f\"{prefix} employees earning above their department average\"\n",
        "\n",
        "        sql=f\"\"\"\n",
        "        SELECT name\n",
        "        FROM employees e\n",
        "        WHERE salary >\n",
        "        (\n",
        "            SELECT AVG(salary)\n",
        "            FROM employees\n",
        "            WHERE dept_id = e.dept_id\n",
        "        )\n",
        "        \"\"\".replace(\"\\n\",\" \")\n",
        "\n",
        "\n",
        "    # =====================================================\n",
        "    # EXISTS\n",
        "    # =====================================================\n",
        "\n",
        "    else:\n",
        "\n",
        "        q=f\"{prefix} employees that belong to a department\"\n",
        "\n",
        "        sql=f\"\"\"\n",
        "        SELECT name\n",
        "        FROM employees e\n",
        "        WHERE EXISTS\n",
        "        (\n",
        "            SELECT 1\n",
        "            FROM departments d\n",
        "            WHERE e.dept_id = d.id\n",
        "        )\n",
        "        \"\"\".replace(\"\\n\",\" \")\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"question\":q.lower(),\n",
        "        \"schema\":schema,\n",
        "        \"sql\":\" \".join(sql.split())\n",
        "    }\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# GENERATE DATASET\n",
        "# =====================================================\n",
        "\n",
        "DATA=[generate_example() for _ in range(150000)]\n",
        "\n",
        "with open(\"nl2sql_data.json\",\"w\") as f:\n",
        "    json.dump(DATA,f)\n",
        "\n",
        "print(\"üî• ULTRA dataset generated successfully!\")\n"
      ],
      "metadata": {
        "id": "koOJGCLd1Ezw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a4ddb20-ba93-42a2-9169-5146ae79f0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî• ULTRA dataset generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "id": "Sz8p9Kkn1E2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeeee5ed-40f8-4f24-bc6b-3d2e4580c794"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"nl2sql_data.json\") as f:\n",
        "    DATA = json.load(f)\n",
        "\n",
        "print(\"Dataset loaded:\", len(DATA))\n"
      ],
      "metadata": {
        "id": "asU6VQevG_qt",
        "outputId": "eeded9f3-0f1d-49bf-8615-218575e5f27f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded: 150000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "id": "Dedq5DZB1E6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b85942-5c07-4281-fafd-9af1893abcbc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ENC_VOCAB = {\"<PAD>\":0,\"<UNK>\":1,\"<SEP>\":2}\n",
        "DEC_VOCAB = {\"<PAD>\":0,\"<UNK>\":1,\"<BOS>\":2,\"<EOS>\":3}\n",
        "\n",
        "def add(vocab,token):\n",
        "    if token not in vocab:\n",
        "        vocab[token]=len(vocab)\n",
        "\n",
        "\n",
        "\n",
        "# ‚≠ê VERY IMPORTANT TOKENIZER\n",
        "def sql_tokenize(sql):\n",
        "\n",
        "    return re.findall(\n",
        "        r\"[A-Za-z_]+\\.[A-Za-z_]+\"      # table.column\n",
        "        r\"|>=|<=|!=|=|>|<\"\n",
        "        r\"|\\bselect\\b|\\bfrom\\b|\\bjoin\\b|\\bon\\b|\\bwhere\\b\"\n",
        "        r\"|\\bgroup\\b|\\bby\\b|\\border\\b|\\blimit\\b\"\n",
        "        r\"|\\binner\\b|\\bleft\\b|\\bright\\b|\\bhaving\\b\"\n",
        "        r\"|\\bavg\\b|\\bsum\\b|\\bcount\\b|\\bmax\\b|\\bmin\\b\"\n",
        "        r\"|\\*\"\n",
        "        r\"|\\(|\\)|,\"\n",
        "        r\"|[A-Za-z_]+\"\n",
        "        r\"|\\d+\",\n",
        "        sql.lower()\n",
        "    )\n",
        "\n",
        "for ex in DATA:\n",
        "\n",
        "    for t in ex[\"question\"].split():\n",
        "        add(ENC_VOCAB,t)\n",
        "\n",
        "    for t,cols in ex[\"schema\"].items():\n",
        "        add(ENC_VOCAB,t)\n",
        "        for c in cols:\n",
        "            add(ENC_VOCAB,f\"{t}.{c}\")\n",
        "\n",
        "    for tok in sql_tokenize(ex[\"sql\"]):\n",
        "        add(DEC_VOCAB,tok)\n",
        "\n",
        "print(\"Encoder vocab:\",len(ENC_VOCAB))\n",
        "print(\"Decoder vocab:\",len(DEC_VOCAB))\n"
      ],
      "metadata": {
        "id": "7Tk3FM2_1E4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95af44af-df81-431a-e6d3-254b53116a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder vocab: 235\n",
            "Decoder vocab: 168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def add(vocab,token):\n",
        "    if token not in vocab:\n",
        "        vocab[token]=len(vocab)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for ex in DATA:\n",
        "\n",
        "    for t in ex[\"question\"].split():\n",
        "        add(ENC_VOCAB,t)\n",
        "\n",
        "    for t,cols in ex[\"schema\"].items():\n",
        "        add(ENC_VOCAB,t)\n",
        "        for c in cols:\n",
        "            add(ENC_VOCAB,f\"{t}.{c}\")\n",
        "\n",
        "    for tok in sql_tokenize(ex[\"sql\"]):\n",
        "        add(DEC_VOCAB,tok)\n",
        "\n",
        "print(\"Encoder vocab:\",len(ENC_VOCAB))\n",
        "print(\"Decoder vocab:\",len(DEC_VOCAB))\n"
      ],
      "metadata": {
        "id": "Nyf0KweX1E9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0663b25-d6a5-41dc-ead2-e0937aa22008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder vocab: 235\n",
            "Decoder vocab: 168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NL2SQLDataset(Dataset):\n",
        "\n",
        "    def __init__(self,data):\n",
        "        self.data=data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "\n",
        "        ex=self.data[i]\n",
        "\n",
        "        src = ex[\"question\"].split()+[\"<SEP>\"]+[\n",
        "            f\"{t}.{c}\"\n",
        "            for t,cs in ex[\"schema\"].items()\n",
        "            for c in cs\n",
        "        ]\n",
        "\n",
        "        src_ids=[ENC_VOCAB.get(t,1) for t in src][:140]\n",
        "        src_ids+=[0]*(140-len(src_ids))\n",
        "\n",
        "        tgt=[DEC_VOCAB[\"<BOS>\"]] + \\\n",
        "            [DEC_VOCAB.get(t,1) for t in sql_tokenize(ex[\"sql\"])] + \\\n",
        "            [DEC_VOCAB[\"<EOS>\"]]\n",
        "\n",
        "        tgt=tgt[:100]\n",
        "        tgt+=[0]*(100-len(tgt))\n",
        "\n",
        "        return torch.tensor(src_ids),torch.tensor(tgt)\n"
      ],
      "metadata": {
        "id": "AftBb-g41E_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_MODEL = 512   # üî• bigger = better joins + nested\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self,d_model,max_len=600):\n",
        "        super().__init__()\n",
        "\n",
        "        pe=torch.zeros(max_len,d_model)\n",
        "\n",
        "        pos=torch.arange(0,max_len).unsqueeze(1)\n",
        "\n",
        "        div=torch.exp(\n",
        "            torch.arange(0,d_model,2) *\n",
        "            (-torch.log(torch.tensor(10000.0))/d_model)\n",
        "        )\n",
        "\n",
        "        pe[:,0::2]=torch.sin(pos*div)\n",
        "        pe[:,1::2]=torch.cos(pos*div)\n",
        "\n",
        "        self.pe=pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return x+self.pe[:,:x.size(1)].to(x.device)\n"
      ],
      "metadata": {
        "id": "JC89QYON1FCs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self,vocab):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb=nn.Embedding(vocab,D_MODEL,padding_idx=0)\n",
        "        self.pos=PositionalEncoding(D_MODEL)\n",
        "\n",
        "        layer=nn.TransformerEncoderLayer(\n",
        "            D_MODEL,\n",
        "            nhead=8,\n",
        "            dim_feedforward=2048,\n",
        "            dropout=0.1,\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "\n",
        "        self.enc=nn.TransformerEncoder(layer,4)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        mask=(x==0)\n",
        "\n",
        "        x=self.pos(self.emb(x))\n",
        "\n",
        "        return self.enc(x,src_key_padding_mask=mask)\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self,vocab):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb=nn.Embedding(vocab,D_MODEL)\n",
        "        self.pos=PositionalEncoding(D_MODEL)\n",
        "\n",
        "        layer=nn.TransformerDecoderLayer(\n",
        "            D_MODEL,\n",
        "            nhead=8,\n",
        "            dim_feedforward=2048,\n",
        "            dropout=0.1,\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "\n",
        "        self.dec=nn.TransformerDecoder(layer,4)\n",
        "\n",
        "        self.fc=nn.Linear(D_MODEL,vocab)\n",
        "\n",
        "        # ‚≠ê improves generation quality massively\n",
        "        self.fc.weight=self.emb.weight\n",
        "\n",
        "    def forward(self,y,mem,mask):\n",
        "\n",
        "        L=y.size(1)\n",
        "\n",
        "        causal=torch.triu(\n",
        "            torch.ones(L,L,device=y.device),1\n",
        "        ).bool()\n",
        "\n",
        "        y=self.pos(self.emb(y))\n",
        "\n",
        "        return self.fc(\n",
        "            self.dec(\n",
        "                y,mem,\n",
        "                tgt_mask=causal,\n",
        "                memory_key_padding_mask=mask\n",
        "            )\n",
        "        )\n"
      ],
      "metadata": {
        "id": "IZUk2U-z1FE8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train,val=train_test_split(DATA,test_size=0.1,random_state=42)\n",
        "\n",
        "train_loader=DataLoader(\n",
        "    NL2SQLDataset(train),\n",
        "    batch_size=48,   # ‚ö†Ô∏è 512 model needs smaller batch\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader=DataLoader(\n",
        "    NL2SQLDataset(val),\n",
        "    batch_size=48\n",
        ")\n"
      ],
      "metadata": {
        "id": "8x_LF_ZE1FHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc=Encoder(len(ENC_VOCAB)).to(device)\n",
        "dec=Decoder(len(DEC_VOCAB)).to(device)\n",
        "\n",
        "optimizer=optim.AdamW(\n",
        "    list(enc.parameters())+list(dec.parameters()),\n",
        "    lr=8e-5,           # ‚≠ê SWEET SPOT\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=12\n",
        ")\n",
        "\n",
        "loss_fn=nn.CrossEntropyLoss(\n",
        "    ignore_index=0,\n",
        "    label_smoothing=0.07\n",
        ")\n"
      ],
      "metadata": {
        "id": "aSwaq4l61FKC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "6a951545-d09f-457b-e12e-b1c001e474b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ENC_VOCAB' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3662302618.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mENC_VOCAB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEC_VOCAB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer=optim.AdamW(\n\u001b[1;32m      5\u001b[0m     \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ENC_VOCAB' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = \"checkpoint.pt\"\n",
        "BEST_MODEL_PATH = \"best_model.pt\"\n",
        "\n",
        "start_epoch = 0\n",
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "# ‚≠ê Resume automatically if checkpoint exists\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "\n",
        "    print(\"‚úÖ Resuming from checkpoint...\\n\")\n",
        "\n",
        "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "\n",
        "    enc.load_state_dict(checkpoint[\"encoder\"])\n",
        "    dec.load_state_dict(checkpoint[\"decoder\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "    scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
        "\n",
        "    start_epoch = checkpoint[\"epoch\"] + 1\n",
        "    best_val_loss = checkpoint[\"best_val_loss\"]\n",
        "\n",
        "    print(f\"Resuming from Epoch {start_epoch}\\n\")\n",
        "\n",
        "\n",
        "print(\"üöÄ Training...\\n\")\n",
        "\n",
        "for epoch in range(start_epoch, 14):\n",
        "\n",
        "    # ================= TRAIN =================\n",
        "    enc.train(); dec.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "\n",
        "        x,y = x.to(device),y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        mem = enc(x)\n",
        "\n",
        "        out = dec(y[:,:-1],mem,(x==0))\n",
        "\n",
        "        loss = loss_fn(\n",
        "            out.reshape(-1,len(DEC_VOCAB)),\n",
        "            y[:,1:].reshape(-1)\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            list(enc.parameters())+list(dec.parameters()),\n",
        "            1.0\n",
        "        )\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "\n",
        "    # ================= VALIDATION =================\n",
        "    enc.eval(); dec.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for x,y in val_loader:\n",
        "\n",
        "            x,y = x.to(device),y.to(device)\n",
        "\n",
        "            mem = enc(x)\n",
        "\n",
        "            out = dec(y[:,:-1],mem,(x==0))\n",
        "\n",
        "            val_loss += loss_fn(\n",
        "                out.reshape(-1,len(DEC_VOCAB)),\n",
        "                y[:,1:].reshape(-1)\n",
        "            ).item()\n",
        "\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    print(f\"\"\"\n",
        "Epoch {epoch+1}\n",
        "\n",
        "Train Loss: {train_loss:.3f}\n",
        "Val Loss:   {val_loss:.3f}\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "    # ================= SAVE CHECKPOINT =================\n",
        "\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"encoder\": enc.state_dict(),\n",
        "        \"decoder\": dec.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "        \"scheduler\": scheduler.state_dict(),\n",
        "        \"best_val_loss\": best_val_loss\n",
        "    }, CHECKPOINT_PATH)\n",
        "\n",
        "\n",
        "    # ================= SAVE BEST MODEL =================\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "\n",
        "        best_val_loss = val_loss\n",
        "\n",
        "        torch.save({\n",
        "            \"encoder\": enc.state_dict(),\n",
        "            \"decoder\": dec.state_dict(),\n",
        "            \"enc_vocab\": ENC_VOCAB,\n",
        "            \"dec_vocab\": DEC_VOCAB\n",
        "        }, BEST_MODEL_PATH)\n",
        "\n",
        "        print(\"üî• BEST MODEL SAVED!\\n\")\n"
      ],
      "metadata": {
        "id": "yxx_VdTR1FMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "027f6783-e989-43e0-8b3e-704a91240b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Resuming from checkpoint...\n",
            "\n",
            "Resuming from Epoch 8\n",
            "\n",
            "üöÄ Training...\n",
            "\n",
            "\n",
            "Epoch 9\n",
            "\n",
            "Train Loss: 0.614\n",
            "Val Loss:   0.611\n",
            "\n",
            "üî• BEST MODEL SAVED!\n",
            "\n",
            "\n",
            "Epoch 10\n",
            "\n",
            "Train Loss: 0.613\n",
            "Val Loss:   0.610\n",
            "\n",
            "üî• BEST MODEL SAVED!\n",
            "\n",
            "\n",
            "Epoch 11\n",
            "\n",
            "Train Loss: 0.612\n",
            "Val Loss:   0.610\n",
            "\n",
            "üî• BEST MODEL SAVED!\n",
            "\n",
            "\n",
            "Epoch 12\n",
            "\n",
            "Train Loss: 0.612\n",
            "Val Loss:   0.610\n",
            "\n",
            "üî• BEST MODEL SAVED!\n",
            "\n",
            "\n",
            "Epoch 13\n",
            "\n",
            "Train Loss: 0.612\n",
            "Val Loss:   0.610\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BEST_MODEL_PATH = \"best_model.pt\"\n",
        "\n",
        "checkpoint = torch.load(BEST_MODEL_PATH, map_location=device)\n",
        "\n",
        "ENC_VOCAB = checkpoint[\"enc_vocab\"]\n",
        "DEC_VOCAB = checkpoint[\"dec_vocab\"]\n",
        "\n",
        "inv_dec_vocab = {v:k for k,v in DEC_VOCAB.items()}\n",
        "\n",
        "enc = Encoder(len(ENC_VOCAB)).to(device)\n",
        "dec = Decoder(len(DEC_VOCAB)).to(device)\n",
        "\n",
        "enc.load_state_dict(checkpoint[\"encoder\"])\n",
        "dec.load_state_dict(checkpoint[\"decoder\"])\n",
        "\n",
        "enc.eval()\n",
        "dec.eval()\n",
        "\n",
        "print(\"‚úÖ Model + vocab restored successfully!\")\n"
      ],
      "metadata": {
        "id": "GtYwRYNf1FPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f032ba-1618-47ac-94cb-e5a40e2ab698"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model + vocab restored successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inv_dec_vocab = {v:k for k,v in DEC_VOCAB.items()}\n"
      ],
      "metadata": {
        "id": "9J5JdbqD1FRk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def top_k_sampling(logits, k=5):\n",
        "\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "    top_probs, top_idx = torch.topk(probs, k)\n",
        "\n",
        "    choice = torch.multinomial(top_probs, 1)\n",
        "\n",
        "    return top_idx.gather(-1, choice)\n"
      ],
      "metadata": {
        "id": "ANtXsLje1FUR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_sql(question, schema, max_len=100):\n",
        "\n",
        "    # encode question + schema\n",
        "    src = question.lower().split() + [\"<SEP>\"] + [\n",
        "        f\"{t}.{c}\"\n",
        "        for t,cs in schema.items()\n",
        "        for c in cs\n",
        "    ]\n",
        "\n",
        "    src_ids = [ENC_VOCAB.get(t,1) for t in src][:140]\n",
        "    src_ids += [0]*(140-len(src_ids))\n",
        "\n",
        "    x = torch.tensor(src_ids).unsqueeze(0).to(device)\n",
        "\n",
        "    memory = enc(x)\n",
        "    mask = (x==0)\n",
        "\n",
        "    ys = torch.tensor([[DEC_VOCAB[\"<BOS>\"]]], device=device)\n",
        "\n",
        "    generated = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "\n",
        "        out = dec(ys, memory, mask)\n",
        "\n",
        "        logits = out[:,-1,:]\n",
        "\n",
        "        logits = logits / 0.7   # optional but VERY good\n",
        "\n",
        "        token_id = torch.argmax(logits, dim=-1).item()\n",
        "        token = inv_dec_vocab[token_id]\n",
        "\n",
        "        token = inv_dec_vocab[token_id]\n",
        "\n",
        "        if token == \"<EOS>\":\n",
        "            break\n",
        "\n",
        "        generated.append(token)\n",
        "\n",
        "        ys = torch.cat(\n",
        "            [ys, torch.tensor([[token_id]], device=device)],\n",
        "            dim=1\n",
        "        )\n",
        "\n",
        "    return \" \".join(generated)\n"
      ],
      "metadata": {
        "id": "Yy_GQr_m1FWe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema1 = {\n",
        "    \"employees\":[\"id\",\"name\",\"salary\",\"dept_id\",\"age\",\"experience\"],\n",
        "    \"departments\":[\"id\",\"name\",\"location\"]\n",
        "}\n",
        "\n",
        "print(infer_sql(\n",
        "    \"show max salary of employees\",\n",
        "    schema1\n",
        "))\n"
      ],
      "metadata": {
        "id": "7jY7qyV71FZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c7d0311-607f-4bcc-cab4-497d6596b2b1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "select name from employees where salary > ( select max ( salary ) from employees )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xo6NrB_q1Fbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NH1gRfeO1Fd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iF41Wspj1Fia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UkNgE09y1Fkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F665OWLt1FoO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}