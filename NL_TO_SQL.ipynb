{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7CI2AWpJskNFCdQ0aiz2Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal7379/Colab/blob/main/NL_TO_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# NL â†’ SQL Transformer (FINAL TOKEN-BASED SYSTEM)\n",
        "# Perfect SELECT + AGG + WHERE + JOIN + PICARD\n",
        "# ============================================================\n",
        "\n",
        "import random, torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ============================================================\n",
        "# SCHEMAS\n",
        "# ============================================================\n",
        "\n",
        "SCHEMAS = [\n",
        "    {\n",
        "        \"tables\": {\n",
        "            \"employees\": [\"id\",\"name\",\"salary\",\"dept_id\"],\n",
        "            \"departments\": [\"id\",\"name\"]\n",
        "        },\n",
        "        \"join\": (\"employees\",\"departments\",\"dept_id\",\"id\")\n",
        "    },\n",
        "    {\n",
        "        \"tables\": {\n",
        "            \"students\": [\"id\",\"name\",\"marks\",\"class_id\"],\n",
        "            \"classes\": [\"id\",\"name\"]\n",
        "        },\n",
        "        \"join\": (\"students\",\"classes\",\"class_id\",\"id\")\n",
        "    }\n",
        "]\n",
        "\n",
        "AGGS = [\"sum\",\"avg\",\"count\",\"max\",\"min\"]"
      ],
      "metadata": {
        "id": "LhmHN6eG5d8D"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# DATA GENERATION\n",
        "# ============================================================\n",
        "\n",
        "def generate_example():\n",
        "    db = random.choice(SCHEMAS)\n",
        "    schema = db[\"tables\"]\n",
        "    main = list(schema.keys())[0]\n",
        "    cols = schema[main]\n",
        "\n",
        "    intent = random.choices(\n",
        "        [\"SELECT\",\"AGG\",\"WHERE\",\"JOIN\",\"AGG_WHERE\",\"JOIN_WHERE\"],\n",
        "        weights=[0.25,0.2,0.2,0.15,0.1,0.1]\n",
        "    )[0]\n",
        "\n",
        "    if intent==\"SELECT\":\n",
        "        col=random.choice(cols)\n",
        "        q=f\"show {col} of {main}\"\n",
        "        sql=f\"SELECT {col} FROM {main}\"\n",
        "\n",
        "    elif intent==\"AGG\":\n",
        "        agg=random.choice(AGGS)\n",
        "        col=random.choice(cols)\n",
        "        q=f\"show {agg} of {col} from {main}\"\n",
        "        sql=f\"SELECT {agg.upper()}({col}) FROM {main}\"\n",
        "\n",
        "    elif intent==\"WHERE\":\n",
        "        col=random.choice(cols)\n",
        "        val=random.choice([10,20,50,100])\n",
        "        q=f\"get {col} from {main} where {col} > {val}\"\n",
        "        sql=f\"SELECT {col} FROM {main} WHERE {col} > {val}\"\n",
        "\n",
        "    elif intent==\"JOIN\":\n",
        "        t1,t2,c1,c2=db[\"join\"]\n",
        "        q=f\"show {t1} and {t2} names\"\n",
        "        sql=f\"SELECT {t1}.name, {t2}.name FROM {t1} JOIN {t2} ON {t1}.{c1} = {t2}.{c2}\"\n",
        "\n",
        "    elif intent==\"AGG_WHERE\":\n",
        "        agg=random.choice(AGGS)\n",
        "        col=random.choice(cols)\n",
        "        val=random.choice([10,20,50])\n",
        "        q=f\"show {agg} of {col} from {main} where {col} > {val}\"\n",
        "        sql=f\"SELECT {agg.upper()}({col}) FROM {main} WHERE {col} > {val}\"\n",
        "\n",
        "    else:\n",
        "        t1,t2,c1,c2=db[\"join\"]\n",
        "        val=random.choice([10,20,50])\n",
        "        q=f\"show {t1} and {t2} names where {t1}.{c1} > {val}\"\n",
        "        sql=f\"SELECT {t1}.name, {t2}.name FROM {t1} JOIN {t2} ON {t1}.{c1} = {t2}.{c2} WHERE {t1}.{c1} > {val}\"\n",
        "\n",
        "    return {\"question\":q,\"schema\":schema,\"sql\":sql}\n",
        "\n",
        "DATA=[generate_example() for _ in range(60000)]"
      ],
      "metadata": {
        "id": "sAT7OYEl5d-B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# VOCAB\n",
        "# ============================================================\n",
        "\n",
        "ENC_VOCAB={\"<PAD>\":0,\"<UNK>\":1,\"<SEP>\":2}\n",
        "DEC_VOCAB={\"<PAD>\":0,\"<UNK>\":1,\"<BOS>\":2,\"<EOS>\":3}\n",
        "\n",
        "def add(v,t):\n",
        "    if t not in v: v[t]=len(v)\n",
        "\n",
        "for ex in DATA:\n",
        "    for t in ex[\"question\"].lower().split(): add(ENC_VOCAB,t)\n",
        "    for tb,cs in ex[\"schema\"].items():\n",
        "        add(ENC_VOCAB,tb)\n",
        "        for c in cs: add(ENC_VOCAB,f\"{tb}.{c}\")\n",
        "    for t in ex[\"sql\"].lower().split(): add(DEC_VOCAB,t)\n",
        "\n",
        "# ============================================================\n",
        "# DATASET\n",
        "# ============================================================\n",
        "\n",
        "class NL2SQLDataset(Dataset):\n",
        "    def __init__(self,data): self.data=data\n",
        "    def __len__(self): return len(self.data)\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "        ex=self.data[i]\n",
        "        q=ex[\"question\"].lower().split()\n",
        "        schema_tokens=[f\"{t}.{c}\" for t,cs in ex[\"schema\"].items() for c in cs]\n",
        "        random.shuffle(schema_tokens)\n",
        "\n",
        "        src=q+[\"<SEP>\"]+schema_tokens\n",
        "        src_ids=[ENC_VOCAB.get(t,1) for t in src][:80]\n",
        "        src_ids+=[0]*(80-len(src_ids))\n",
        "\n",
        "        tgt=[DEC_VOCAB[\"<BOS>\"]]+[DEC_VOCAB.get(t,1) for t in ex[\"sql\"].lower().split()]+[DEC_VOCAB[\"<EOS>\"]]\n",
        "        tgt=tgt[:70]\n",
        "        tgt+=[0]*(70-len(tgt))\n",
        "\n",
        "        return torch.tensor(src_ids),torch.tensor(tgt)\n",
        "\n",
        "train,val=train_test_split(DATA,test_size=0.1)\n",
        "train_loader=DataLoader(NL2SQLDataset(train),batch_size=128,shuffle=True)\n",
        "val_loader=DataLoader(NL2SQLDataset(val),batch_size=128)"
      ],
      "metadata": {
        "id": "Rf55enHp5eAw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# MODEL\n",
        "# ============================================================\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,v):\n",
        "        super().__init__()\n",
        "        self.emb=nn.Embedding(v,256,padding_idx=0)\n",
        "        layer=nn.TransformerEncoderLayer(256,8,1024,batch_first=True)\n",
        "        self.enc=nn.TransformerEncoder(layer,4)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.enc(self.emb(x),src_key_padding_mask=(x==0))\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,v):\n",
        "        super().__init__()\n",
        "        self.emb=nn.Embedding(v,256)\n",
        "        layer=nn.TransformerDecoderLayer(256,8,1024,batch_first=True)\n",
        "        self.dec=nn.TransformerDecoder(layer,4)\n",
        "        self.fc=nn.Linear(256,v)\n",
        "\n",
        "    def forward(self,y,mem,mask):\n",
        "        L=y.size(1)\n",
        "        causal=torch.triu(torch.ones(L,L,device=y.device),1).bool()\n",
        "        out=self.dec(self.emb(y),mem,tgt_mask=causal,memory_key_padding_mask=mask)\n",
        "        return self.fc(out)\n",
        "\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "enc,dec=Encoder(len(ENC_VOCAB)).to(device),Decoder(len(DEC_VOCAB)).to(device)\n",
        "\n",
        "opt=optim.AdamW(list(enc.parameters())+list(dec.parameters()),lr=3e-4)\n",
        "loss_fn=nn.CrossEntropyLoss(ignore_index=0,label_smoothing=0.1)\n",
        ""
      ],
      "metadata": {
        "id": "ndlS5jkS5eD_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TRAIN\n",
        "# ============================================================\n",
        "\n",
        "print(\"ðŸš€ Training\")\n",
        "\n",
        "for epoch in range(5):\n",
        "    enc.train(); dec.train(); tot=0\n",
        "    for x,y in train_loader:\n",
        "        x,y=x.to(device),y.to(device)\n",
        "        opt.zero_grad()\n",
        "        mem=enc(x)\n",
        "        out=dec(y[:,:-1],mem,(x==0))\n",
        "        loss=loss_fn(out.reshape(-1,len(DEC_VOCAB)),y[:,1:].reshape(-1))\n",
        "        loss.backward(); opt.step()\n",
        "        tot+=loss.item()\n",
        "    print(f\"Epoch {epoch+1} | Loss {tot/len(train_loader):.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# SAVE MODEL\n",
        "# ============================================================\n",
        "\n",
        "torch.save({\n",
        "    \"enc\":enc.state_dict(),\n",
        "    \"dec\":dec.state_dict(),\n",
        "    \"ENC_VOCAB\":ENC_VOCAB,\n",
        "    \"DEC_VOCAB\":DEC_VOCAB\n",
        "},\"nl2sql_token_final.pt\")\n",
        "\n",
        "print(\"âœ… Model saved: nl2sql_token_final.pt\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QrrAM9T5eGr",
        "outputId": "59bd4853-1938-4643-c7ac-f689db438517"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Training\n",
            "Epoch 1 | Loss 0.8214\n",
            "Epoch 2 | Loss 0.7302\n",
            "Epoch 3 | Loss 0.7293\n",
            "Epoch 4 | Loss 0.7289\n",
            "Epoch 5 | Loss 0.7287\n",
            "âœ… Model saved: nl2sql_token_final.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# INFERENCE WITH PICARD\n",
        "# ============================================================\n",
        "\n",
        "inv_dec_vocab={v:k for k,v in DEC_VOCAB.items()}\n",
        "\n",
        "def valid_sql_step(prev, tok):\n",
        "    p=[t.lower() for t in prev]\n",
        "    t=tok.lower()\n",
        "\n",
        "    if len(p)==0: return t==\"select\"\n",
        "    if t==\"from\" and \"select\" not in p: return False\n",
        "    if t==\"join\" and \"from\" not in p: return False\n",
        "    if t==\"where\" and \"from\" not in p: return False\n",
        "    if t==\"on\" and \"join\" not in p: return False\n",
        "    return True\n",
        "\n",
        "def infer_sql(question,schema,max_len=70):\n",
        "    tokens=question.lower().split()+[\"<SEP>\"]+[f\"{t}.{c}\" for t,cs in schema.items() for c in cs]\n",
        "    ids=[ENC_VOCAB.get(t,1) for t in tokens][:80]\n",
        "    ids+=[0]*(80-len(ids))\n",
        "\n",
        "    x=torch.tensor(ids).unsqueeze(0).to(device)\n",
        "    mem=enc(x)\n",
        "\n",
        "    y=torch.tensor([[DEC_VOCAB[\"<BOS>\"]]],device=device)\n",
        "    gen=[]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        out=dec(y,mem,(x==0))\n",
        "        probs=out[:,-1].softmax(-1)\n",
        "        for idx in torch.argsort(probs,descending=True)[0]:\n",
        "            tok=inv_dec_vocab[idx.item()]\n",
        "            if tok in {\"<PAD>\",\"<BOS>\"}: continue\n",
        "            if valid_sql_step(gen,tok):\n",
        "                break\n",
        "        if tok==\"<EOS>\": break\n",
        "        gen.append(tok)\n",
        "        y=torch.cat([y,idx.view(1,1)],dim=1)\n",
        "\n",
        "    return \" \".join(gen)\n",
        "\n",
        "# ============================================================\n",
        "# TEST\n",
        "# ============================================================\n",
        "\n",
        "schema1={\n",
        "    \"employees\":[\"id\",\"name\",\"salary\",\"dept_id\"],\n",
        "    \"departments\":[\"id\",\"name\"]\n",
        "}\n",
        "\n",
        "print(infer_sql(\"min salary from employees\",schema1))\n",
        "print(infer_sql(\"get salary from employees where salary > 20\",schema1))\n",
        "print(infer_sql(\"show employees and departments names\",schema1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4erSNUkV5eJT",
        "outputId": "f1fd02ca-dd9c-4a46-871f-6deaa9f0c525"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "select min(salary) from employees\n",
            "select salary from employees where salary > 20\n",
            "select employees.name, departments.name from employees join departments on employees.dept_id = departments.id\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bdmNS5p5eLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gz-0AuZ5eO9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}