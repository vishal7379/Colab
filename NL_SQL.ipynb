{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal7379/Colab/blob/main/NL_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker\n",
        "\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from faker import Faker\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "fake = Faker()\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wacCB09hFijs",
        "outputId": "468eabe0-77cd-4a62-b573-9d6468b7a6ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-40.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Downloading faker-40.4.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-40.4.0\n",
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SQL_PATTERNS = (\n",
        "    [\"join\"] * 5 +\n",
        "    [\"join_where\"] * 4 +\n",
        "    [\"group_by\"] * 3 +\n",
        "    [\"having\"] * 2 +\n",
        "    [\"where\"] * 2 +\n",
        "    [\"aggregation\"] * 2 +\n",
        "    [\"order_by\"] * 3 +\n",
        "    [\"limit\"] * 2 +\n",
        "    [\"order_by_limit\"] * 3 +\n",
        "    [\"multi_select\"] +\n",
        "    [\"simple_select\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "SMYdGF_-FimD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_COLUMNS = [\n",
        "    \"name\",\"email\",\"age\",\"salary\",\n",
        "    \"department\",\"city\",\"country\",\n",
        "    \"price\",\"amount\",\"quantity\",\n",
        "    \"created_at\",\"updated_at\"\n",
        "]\n",
        "\n",
        "FK_COLUMNS = [\n",
        "    \"user_id\",\n",
        "    \"order_id\",\n",
        "    \"product_id\",\n",
        "    \"customer_id\"\n",
        "]"
      ],
      "metadata": {
        "id": "pZOjhLZ6Fioa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLUMN_TYPES = {\n",
        "    \"numeric\":[\"age\",\"salary\",\"price\",\"amount\",\"quantity\"],\n",
        "    \"text\":[\"name\",\"email\",\"department\",\"city\",\"country\"],\n",
        "    \"date\":[\"created_at\",\"updated_at\"]\n",
        "}\n"
      ],
      "metadata": {
        "id": "0dqcpa4NMvJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_relational_schema():\n",
        "\n",
        "    num_tables = random.randint(2,5)\n",
        "    fake.unique.clear()\n",
        "\n",
        "    tables = {}\n",
        "    table_names = [fake.unique.word() for _ in range(num_tables)]\n",
        "\n",
        "    for t in table_names:\n",
        "\n",
        "        cols = {\n",
        "            \"numeric\": random.sample(COLUMN_TYPES[\"numeric\"], random.randint(1,3)),\n",
        "            \"text\": random.sample(COLUMN_TYPES[\"text\"], random.randint(1,3)),\n",
        "            \"date\": random.sample(COLUMN_TYPES[\"date\"], random.randint(0,1))\n",
        "        }\n",
        "\n",
        "        flat_cols = [\"id\"]\n",
        "        for v in cols.values():\n",
        "            flat_cols.extend(v)\n",
        "\n",
        "        tables[t] = {\n",
        "            \"all\": flat_cols,\n",
        "            \"numeric\": cols[\"numeric\"],\n",
        "            \"text\": cols[\"text\"],\n",
        "            \"date\": cols[\"date\"]\n",
        "        }\n",
        "\n",
        "    relationships = []\n",
        "\n",
        "    for i in range(1, num_tables):\n",
        "        parent = table_names[i-1]\n",
        "        child = table_names[i]\n",
        "        fk = f\"{parent}_id\"\n",
        "        tables[child][\"all\"].append(fk)\n",
        "        relationships.append((child, fk, parent, \"id\"))\n",
        "\n",
        "    return {\"tables\": tables, \"relationships\": relationships}\n"
      ],
      "metadata": {
        "id": "FP1HPZB5Fiqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def schema_to_text(schema):\n",
        "\n",
        "    parts = []\n",
        "\n",
        "    for table, col_dict in schema[\"tables\"].items():\n",
        "        col_tokens = \" \".join([f\"[COL] {c}\" for c in col_dict[\"all\"]])\n",
        "        parts.append(f\"[TABLE] {table} {col_tokens}\")\n",
        "\n",
        "    for child, fk, parent, pk in schema[\"relationships\"]:\n",
        "        parts.append(f\"[REL] {child}.{fk} -> {parent}.{pk}\")\n",
        "\n",
        "    return \" \".join(parts)\n"
      ],
      "metadata": {
        "id": "2J47wv3MFis7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT_TEMPLATES = [\n",
        "    \"show {col} from {table}\",\n",
        "    \"list {col} in {table}\",\n",
        "    \"display {col} from {table}\",\n",
        "    \"what are the {col} in {table}\",\n",
        "]"
      ],
      "metadata": {
        "id": "cdSBBALCFiv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sql(schema):\n",
        "\n",
        "    pattern = random.choice(SQL_PATTERNS)\n",
        "    tables = schema[\"tables\"]\n",
        "    rels = schema[\"relationships\"]\n",
        "\n",
        "    table = random.choice(list(tables.keys()))\n",
        "    columns = tables[table][\"all\"]\n",
        "    numeric_cols = tables[table][\"numeric\"]\n",
        "    text_cols = tables[table][\"text\"]\n",
        "\n",
        "    # SIMPLE SELECT\n",
        "    if pattern == \"simple_select\":\n",
        "\n",
        "        selected = random.sample(columns, random.randint(1, min(3,len(columns))))\n",
        "        question = f\"show {', '.join(selected)} from {table}\"\n",
        "        sql = f\"SELECT {', '.join(selected)} FROM {table}\"\n",
        "\n",
        "    # WHERE\n",
        "    elif pattern == \"where\":\n",
        "\n",
        "        col = random.choice(numeric_cols if numeric_cols else columns)\n",
        "        operator = random.choice([\"=\",\">\",\"<\"])\n",
        "        value = random.randint(1,100)\n",
        "\n",
        "        question = f\"show {col} from {table} where {col} {operator} {value}\"\n",
        "        sql = f\"SELECT {col} FROM {table} WHERE {col} {operator} {value}\"\n",
        "\n",
        "    # ORDER BY\n",
        "    elif pattern == \"order_by\":\n",
        "\n",
        "        col = random.choice(numeric_cols if numeric_cols else columns)\n",
        "        direction = random.choice([\"ASC\",\"DESC\"])\n",
        "\n",
        "        question = f\"show all records from {table} ordered by {col}\"\n",
        "        sql = f\"SELECT * FROM {table} ORDER BY {col} {direction}\"\n",
        "\n",
        "    # LIMIT\n",
        "    elif pattern == \"limit\":\n",
        "\n",
        "        limit_val = random.randint(3,20)\n",
        "        question = f\"show first {limit_val} rows from {table}\"\n",
        "        sql = f\"SELECT * FROM {table} LIMIT {limit_val}\"\n",
        "\n",
        "    # ORDER BY + LIMIT\n",
        "    elif pattern == \"order_by_limit\":\n",
        "\n",
        "        col = random.choice(numeric_cols if numeric_cols else columns)\n",
        "        direction = random.choice([\"ASC\",\"DESC\"])\n",
        "        limit_val = random.randint(3,15)\n",
        "\n",
        "        question = f\"show top {limit_val} records from {table} ordered by {col}\"\n",
        "        sql = f\"SELECT * FROM {table} ORDER BY {col} {direction} LIMIT {limit_val}\"\n",
        "\n",
        "    # JOIN\n",
        "    elif pattern == \"join\" and rels:\n",
        "\n",
        "        child, fk, parent, pk = random.choice(rels)\n",
        "        select_col = random.choice(tables[parent][\"all\"])\n",
        "\n",
        "        question = f\"show {select_col} from {parent} joined with {child}\"\n",
        "        sql = f\"SELECT {parent}.{select_col} FROM {parent} JOIN {child} ON {parent}.{pk} = {child}.{fk}\"\n",
        "\n",
        "    else:\n",
        "        return generate_sql(schema)\n",
        "\n",
        "    return question.strip(), sql.strip()\n"
      ],
      "metadata": {
        "id": "SxOl0INZFizX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(num_schemas=8000, queries_per_schema=8):\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for _ in range(num_schemas):\n",
        "\n",
        "        schema = generate_relational_schema()\n",
        "        schema_text = schema_to_text(schema)\n",
        "\n",
        "        for _ in range(queries_per_schema):\n",
        "\n",
        "            q, sql = generate_sql(schema)\n",
        "\n",
        "            model_input = f\"\"\"\n",
        "Schema:\n",
        "{schema_text}\n",
        "\n",
        "Question:\n",
        "{q}\n",
        "\"\"\"\n",
        "\n",
        "            data.append({\n",
        "                \"input\": model_input.strip(),\n",
        "                \"output\": sql.strip()\n",
        "            })\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "dataset = build_dataset()\n",
        "\n",
        "print(\"Total examples:\", len(dataset))\n",
        "\n",
        "with open(\"dataset.json\", \"w\") as f:\n",
        "    json.dump(dataset, f)\n",
        "\n",
        "print(\"✅ dataset.json saved\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eFqq1tIGfzb",
        "outputId": "57ed15cc-393c-422b-bf04-d3e48c065e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 51200\n",
            "Val: 6400\n",
            "Test: 6400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(data):\n",
        "\n",
        "    counter = Counter()\n",
        "\n",
        "    for row in data:\n",
        "        counter.update(row[\"input\"].split())\n",
        "        counter.update(row[\"output\"].split())\n",
        "\n",
        "    vocab = {w:i+4 for i,(w,_) in enumerate(counter.items())}\n",
        "\n",
        "    vocab[\"<pad>\"] = 0\n",
        "    vocab[\"<unk>\"] = 1\n",
        "    vocab[\"<sos>\"] = 2\n",
        "    vocab[\"<eos>\"] = 3\n",
        "\n",
        "    return vocab\n"
      ],
      "metadata": {
        "id": "ijPR7psAGf16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"dataset.json\") as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "random.shuffle(dataset)\n",
        "\n",
        "split = int(0.9 * len(dataset))\n",
        "\n",
        "train = dataset[:split]\n",
        "val   = dataset[split:]\n",
        "vocab = build_vocab(train)\n",
        "torch.save(vocab, \"vocab.pt\")\n",
        "\n",
        "\n",
        "print(\"Train:\", len(train))\n",
        "print(\"Val:\", len(val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdjAeBQmWaxB",
        "outputId": "e7235674-318f-4a65-fc02-0b47e1eb6850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train/Val/Test datasets saved as JSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 160\n",
        "\n",
        "def encode(text, add_special_tokens=False):\n",
        "\n",
        "    tokens = text.split()\n",
        "\n",
        "    ids = [vocab.get(t,1) for t in tokens]\n",
        "\n",
        "    if add_special_tokens:\n",
        "        ids = [vocab[\"<sos>\"]] + ids + [vocab[\"<eos>\"]]\n",
        "\n",
        "    ids = ids[:MAX_LEN]\n",
        "\n",
        "    ids += [0]*(MAX_LEN-len(ids))\n",
        "\n",
        "    return torch.tensor(ids)\n",
        "\n",
        "\n",
        "class NL2SQLDataset(Dataset):\n",
        "    def __init__(self,data):\n",
        "        self.data = data\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        row = self.data[idx]\n",
        "\n",
        "        src = encode(row[\"input\"], add_special_tokens=False)\n",
        "        tgt = encode(row[\"output\"], add_special_tokens=True)\n",
        "\n",
        "        return src, tgt\n",
        "\n"
      ],
      "metadata": {
        "id": "-ECMgN75Gf4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NL2SQLModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, d_model=256):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.transformer = nn.Transformer(\n",
        "          d_model=d_model,\n",
        "          nhead=4,\n",
        "          num_encoder_layers=2,\n",
        "          num_decoder_layers=2,\n",
        "          batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "\n",
        "        src_mask = (src==0)\n",
        "        tgt_mask = (tgt==0)\n",
        "\n",
        "        seq_len = tgt.size(1)\n",
        "        causal_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(tgt.device)\n",
        "\n",
        "        src = self.embed(src)\n",
        "        tgt = self.embed(tgt)\n",
        "\n",
        "        out = self.transformer(\n",
        "            src,\n",
        "            tgt,\n",
        "            tgt_mask=causal_mask,\n",
        "            src_key_padding_mask=src_mask,\n",
        "            tgt_key_padding_mask=tgt_mask\n",
        "        )\n",
        "\n",
        "        return self.fc(out)\n"
      ],
      "metadata": {
        "id": "yIyTYqmBZYHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(NL2SQLDataset(train), batch_size=16, shuffle=True)\n",
        "val_loader   = DataLoader(NL2SQLDataset(val), batch_size=16)\n",
        "\n",
        "model = NL2SQLModel(len(vocab)).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "CHECKPOINT_PATH = \"nl2sql_checkpoint.pt\"\n",
        "\n",
        "def save_checkpoint(epoch, model, optimizer, val_loss):\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"val_loss\": val_loss\n",
        "    }, CHECKPOINT_PATH)\n",
        "\n",
        "def load_checkpoint(model, optimizer):\n",
        "    if os.path.exists(CHECKPOINT_PATH):\n",
        "        ckpt = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "        model.load_state_dict(ckpt[\"model_state\"])\n",
        "        optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
        "        print(f\"✅ Resuming from epoch {ckpt['epoch']+1}\")\n",
        "        return ckpt[\"epoch\"] + 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "EPOCHS = 15\n",
        "best_loss = float(\"inf\")\n",
        "\n",
        "start_epoch = load_checkpoint(model, optimizer)\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "\n",
        "    ###################\n",
        "    # TRAIN\n",
        "    ###################\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "\n",
        "        x,y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(x, y[:,:-1])\n",
        "\n",
        "        loss = loss_fn(\n",
        "            output.reshape(-1,len(vocab)),\n",
        "            y[:,1:].reshape(-1)\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "\n",
        "    ###################\n",
        "    # VALIDATION\n",
        "    ###################\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x,y in val_loader:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "\n",
        "            output = model(x, y[:,:-1])\n",
        "\n",
        "            loss = loss_fn(\n",
        "                output.reshape(-1,len(vocab)),\n",
        "                y[:,1:].reshape(-1)\n",
        "            )\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch} | Train {train_loss:.4f} | Val {val_loss:.4f}\")\n",
        "\n",
        "    # save every epoch\n",
        "    save_checkpoint(epoch, model, optimizer, val_loss)\n",
        "\n",
        "    # save best model separately\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        print(\"⭐ BEST MODEL SAVED\")\n"
      ],
      "metadata": {
        "id": "C-TVvOjHGf61"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_vocab = {i:w for w,i in vocab.items()}\n",
        "\n",
        "def generate_query(model, text):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    src = encode(text, add_special_tokens=False).unsqueeze(0).to(device)\n",
        "\n",
        "    tgt = torch.tensor([[vocab[\"<sos>\"]]], dtype=torch.long).to(device)\n",
        "\n",
        "    for _ in range(MAX_LEN):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(src, tgt)\n",
        "\n",
        "        next_token = output.argmax(-1)[:,-1]\n",
        "\n",
        "        if next_token.item() == vocab[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "        tgt = torch.cat([tgt, next_token.unsqueeze(0)], dim=1)\n",
        "\n",
        "    tokens = [\n",
        "        inv_vocab.get(i,\"\")\n",
        "        for i in tgt.squeeze().tolist()\n",
        "        if i not in [vocab[\"<sos>\"], vocab[\"<pad>\"]]\n",
        "    ]\n",
        "\n",
        "    return \" \".join(tokens)\n"
      ],
      "metadata": {
        "id": "gHrjTzhwHopk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manual_input = \"\"\"\n",
        "Schema:\n",
        "[TABLE] employees [COL] id [COL] name [COL] salary [COL] department_id\n",
        "[TABLE] departments [COL] id [COL] dept_name\n",
        "[REL] employees.department_id -> departments.id\n",
        "\n",
        "Question:\n",
        "show salary from employees where salary > 100\n",
        "\"\"\"\n",
        "\n",
        "print(generate_query(model, manual_input))\n"
      ],
      "metadata": {
        "id": "nbZc46UCIgbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d1b207c-96a6-4aa7-aa35-381bcc32472a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> FROM salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary salary FROM professor WHERE salary > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 > 58 58 58 58 58 salary > 58 58 58 58 58 salary > 58 58 58 58 58 salary > 58 58 58 58 58 58 salary > 58 58 58 58 58 58 58 salary > 58 58 58 58 58 58 58 salary > 58 58 58 58 58 58 58 58 salary > 58 58 58 58 58 58 58 58 58 salary > 58 58 58 58 58 58 58 58 58 58 58 salary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uJ4cwf1OIges"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}