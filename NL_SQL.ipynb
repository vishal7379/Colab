{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal7379/Colab/blob/main/NL_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch nltk sqlparse\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbyDylnoGaAo",
        "outputId": "fe2cd83a-26f7-4ce6-81a4-47bffc4b242f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.12/dist-packages (0.5.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "2lcZdY2LGc8f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SCHEMAS = [\n",
        "    {\n",
        "        \"tables\": {\n",
        "            \"employees\": [\"id\",\"name\",\"salary\",\"dept_id\"],\n",
        "            \"departments\": [\"id\",\"name\"]\n",
        "        },\n",
        "        \"join\": (\"employees\",\"departments\",\"dept_id\",\"id\")\n",
        "    }\n",
        "]\n",
        "\n",
        "AGGS = [\"sum\",\"avg\",\"count\",\"max\",\"min\"]\n"
      ],
      "metadata": {
        "id": "lHDeGzETGc_K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_example():\n",
        "    db = random.choice(SCHEMAS)\n",
        "    tables = db[\"tables\"]\n",
        "    main = list(tables.keys())[0]\n",
        "    cols = tables[main]\n",
        "\n",
        "    intent = random.choice([\n",
        "        \"SELECT\",\"WHERE\",\"AGG\",\"AGG_WHERE\",\"JOIN\",\"JOIN_WHERE\",\"NESTED\"\n",
        "    ])\n",
        "\n",
        "    if intent==\"SELECT\":\n",
        "        col=random.choice(cols)\n",
        "        q=f\"show {col} of {main}\"\n",
        "        sql=f\"SELECT {main}.{col} FROM {main}\"\n",
        "\n",
        "    elif intent==\"WHERE\":\n",
        "        col=random.choice(cols)\n",
        "        val=random.choice([10,20,50,100])\n",
        "        q=f\"get {col} from {main} where {col} > {val}\"\n",
        "        sql=f\"SELECT {main}.{col} FROM {main} WHERE {main}.{col} > {val}\"\n",
        "\n",
        "    elif intent==\"AGG\":\n",
        "        agg=random.choice(AGGS)\n",
        "        col=random.choice(cols)\n",
        "        q=f\"show {agg} of {col} from {main}\"\n",
        "        sql=f\"SELECT {agg.upper()}({main}.{col}) FROM {main}\"\n",
        "\n",
        "    elif intent==\"AGG_WHERE\":\n",
        "        agg=random.choice(AGGS)\n",
        "        col=random.choice(cols)\n",
        "        val=random.choice([20,50,100])\n",
        "        q=f\"show {agg} of {col} from {main} where {col} > {val}\"\n",
        "        sql=f\"SELECT {agg.upper()}({main}.{col}) FROM {main} WHERE {main}.{col} > {val}\"\n",
        "\n",
        "    elif intent==\"JOIN\":\n",
        "        t1,t2,c1,c2=db[\"join\"]\n",
        "        q=f\"show {t1} and {t2} names\"\n",
        "        sql=f\"SELECT {t1}.name , {t2}.name FROM {t1} JOIN {t2} ON {t1}.{c1} = {t2}.{c2}\"\n",
        "\n",
        "    elif intent==\"JOIN_WHERE\":\n",
        "        t1,t2,c1,c2=db[\"join\"]\n",
        "        val=random.choice([20,50,100])\n",
        "        q=f\"show {t1} and {t2} names where {t1}.{c1} > {val}\"\n",
        "        sql=f\"SELECT {t1}.name , {t2}.name FROM {t1} JOIN {t2} ON {t1}.{c1} = {t2}.{c2} WHERE {t1}.{c1} > {val}\"\n",
        "\n",
        "    else:\n",
        "        q=f\"find employees earning more than average salary\"\n",
        "        sql=\"SELECT name FROM employees WHERE salary > ( SELECT AVG(salary) FROM employees )\"\n",
        "\n",
        "    return {\"question\":q,\"schema\":tables,\"sql\":sql}\n",
        "DATA = [generate_example() for _ in range(60000)]\n"
      ],
      "metadata": {
        "id": "zR0uioiIGdCQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sql_to_ast(sql):\n",
        "    sql=sql.lower()\n",
        "    tokens=[\"<QUERY>\"]\n",
        "\n",
        "    for kw in [\"select\",\"from\",\"join\",\"where\",\"group by\",\"having\",\"order by\",\"intersect\",\"union\",\"except\"]:\n",
        "        if kw in sql:\n",
        "            tokens.append(f\"<{kw.replace(' ','_').upper()}>\")\n",
        "\n",
        "    if sql.count(\"select\") > 1:\n",
        "        tokens.append(\"<SUBQUERY>\")\n",
        "\n",
        "    tokens.append(\"</QUERY>\")\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "Orw18MYjGdE4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AST_VOCAB={\"<PAD>\":0,\"<BOS>\":1,\"<EOS>\":2}\n",
        "idx=3\n",
        "\n",
        "def add(tok):\n",
        "    global idx\n",
        "    if tok not in AST_VOCAB:\n",
        "        AST_VOCAB[tok]=idx\n",
        "        idx+=1\n",
        "\n",
        "for ex in DATA:\n",
        "    for t in sql_to_ast(ex[\"sql\"]):\n",
        "        add(t)\n",
        "\n",
        "INV_AST_VOCAB={v:k for k,v in AST_VOCAB.items()}\n"
      ],
      "metadata": {
        "id": "LushZa9fGdHX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME=\"microsoft/MiniLM-L12-H384-uncased\"\n",
        "tokenizer=AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "class NL2SQLDataset(Dataset):\n",
        "    def __init__(self,data): self.data=data\n",
        "    def __len__(self): return len(self.data)\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "        ex=self.data[i]\n",
        "        schema=\" | \".join([f\"{t}.{c}\" for t,cs in ex[\"schema\"].items() for c in cs])\n",
        "        text=f\"question: {ex['question']} schema: {schema}\"\n",
        "\n",
        "        enc=tokenizer(text,padding=\"max_length\",truncation=True,\n",
        "                      max_length=128,return_tensors=\"pt\")\n",
        "\n",
        "        tgt=[AST_VOCAB[\"<BOS>\"]] + \\\n",
        "            [AST_VOCAB[t] for t in sql_to_ast(ex[\"sql\"])] + \\\n",
        "            [AST_VOCAB[\"<EOS>\"]]\n",
        "\n",
        "        return enc[\"input_ids\"].squeeze(0),enc[\"attention_mask\"].squeeze(0),torch.tensor(tgt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7fzKZZkGdJp",
        "outputId": "0614a0c8-e252-4a51-91e2-504ee6385d1b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    ids, masks, tgts = zip(*batch)\n",
        "\n",
        "    ids = torch.stack(ids)\n",
        "    masks = torch.stack(masks)\n",
        "\n",
        "    max_len = max(len(t) for t in tgts)\n",
        "    tgt_pad = torch.zeros(len(tgts), max_len, dtype=torch.long)\n",
        "\n",
        "    for i, t in enumerate(tgts):\n",
        "        tgt_pad[i, :len(t)] = t\n",
        "\n",
        "    return ids, masks, tgt_pad\n"
      ],
      "metadata": {
        "id": "TxNi1r_pGdMR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train,val=train_test_split(DATA,test_size=0.1)\n",
        "train_loader=DataLoader(NL2SQLDataset(train),batch_size=32,shuffle=True,collate_fn=collate_fn)\n",
        "\n",
        "val_loader=DataLoader(NL2SQLDataset(val),batch_size=32,shuffle=True,collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "_ae90149GdOj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "        out = self.model(ids, attention_mask=mask).last_hidden_state\n",
        "        return self.dropout(out)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden, vocab):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab, hidden)\n",
        "        self.lstm = nn.LSTM(hidden, hidden, batch_first=True, dropout=0.2)\n",
        "        self.attn = nn.MultiheadAttention(hidden, num_heads=8, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(hidden, vocab)\n",
        "\n",
        "    def forward(self, tgt, enc_out):\n",
        "        emb = self.dropout(self.emb(tgt))\n",
        "        out, _ = self.lstm(emb)\n",
        "        out, _ = self.attn(out, enc_out, enc_out)\n",
        "        out = self.dropout(out)\n",
        "        return self.fc(out)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=0, label_smoothing=0.1)\n",
        "\n",
        "\n",
        "class NL2SQL(nn.Module):\n",
        "    def __init__(self, vocab):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder(384, vocab)\n",
        "\n",
        "    def forward(self, ids, mask, tgt):\n",
        "        enc_out = self.encoder(ids, mask)\n",
        "        return self.decoder(tgt, enc_out)\n"
      ],
      "metadata": {
        "id": "q5TPPSsUGdRu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model=NL2SQL(len(AST_VOCAB)).to(device)\n",
        "\n",
        "opt=torch.optim.AdamW(model.parameters(),lr=2e-5)\n",
        "loss_fn=nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "def train_epoch(loader):\n",
        "    model.train(); total=0\n",
        "    for x,m,t in tqdm(loader):\n",
        "        x,m,t=x.to(device),m.to(device),t.to(device)\n",
        "        out=model(x,m,t[:,:-1])\n",
        "        loss=loss_fn(out.reshape(-1,len(AST_VOCAB)),t[:,1:].reshape(-1))\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "        total+=loss.item()\n",
        "    return total/len(loader)\n",
        "\n",
        "for e in range(5):\n",
        "    tr=train_epoch(train_loader)\n",
        "    print(f\"Epoch {e+1} | Loss {tr:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB48vC29GaCl",
        "outputId": "17e4f451-ee21-49a2-94c1-cdb64edac553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1688/1688 [06:11<00:00,  4.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss 0.3283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 901/1688 [03:18<02:51,  4.59it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_structure(question, schema):\n",
        "    model.eval()\n",
        "\n",
        "    text = f\"question: {question} schema: {schema}\"\n",
        "    enc = tokenizer(\n",
        "        text, padding=\"max_length\", truncation=True,\n",
        "        max_length=128, return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    tgt = torch.tensor([[AST_VOCAB[\"<BOS>\"]]], device=device)\n",
        "\n",
        "    for _ in range(20):\n",
        "        logits = model(enc[\"input_ids\"], enc[\"attention_mask\"], tgt)\n",
        "        nxt = logits[:, -1].argmax(-1, keepdim=True)\n",
        "        tgt = torch.cat([tgt, nxt], dim=1)\n",
        "\n",
        "        if nxt.item() == AST_VOCAB[\"<EOS>\"]:\n",
        "            break\n",
        "\n",
        "    tokens = [INV_AST_VOCAB[t.item()] for t in tgt[0]]\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "9RcsdtO2GaE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = \"employees.id | employees.name | employees.salary | employees.dept_id | departments.id | departments.name\"\n",
        "\n",
        "print(infer_structure(\"show employee and department names\", schema))\n",
        "print(infer_structure(\"find employees earning more than average salary\", schema))\n",
        "print(infer_structure(\"show avg salary by department\", schema))\n"
      ],
      "metadata": {
        "id": "bu1Vp98AGaHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0kK7uIo5GaKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y4-WNFTzGaNl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}