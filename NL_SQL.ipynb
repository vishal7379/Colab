{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal7379/Colab/blob/main/NL_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker\n",
        "\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from faker import Faker\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wacCB09hFijs",
        "outputId": "95607bea-b6f8-4192-921a-be498544cea0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-40.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Downloading faker-40.4.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/2.0 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-40.4.0\n",
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SQL_PATTERNS = (\n",
        "    [\"join\"] * 5 +\n",
        "    [\"join_where\"] * 4 +        # ⭐ NEW\n",
        "    [\"group_by\"] * 3 +\n",
        "    [\"having\"] * 2 +\n",
        "    [\"where\"] * 2 +\n",
        "    [\"aggregation\"] * 2 +\n",
        "    [\"order_by\"] * 3 +         # ⭐ NEW\n",
        "    [\"limit\"] * 2 +            # ⭐ NEW\n",
        "    [\"order_by_limit\"] * 3 +   # ⭐ VERY IMPORTANT\n",
        "    [\"multi_select\"] +\n",
        "    [\"simple_select\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "SMYdGF_-FimD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_COLUMNS = [\n",
        "    \"name\",\"email\",\"age\",\"salary\",\n",
        "    \"department\",\"city\",\"country\",\n",
        "    \"price\",\"amount\",\"quantity\",\n",
        "    \"created_at\",\"updated_at\"\n",
        "]\n",
        "\n",
        "FK_COLUMNS = [\n",
        "    \"user_id\",\n",
        "    \"order_id\",\n",
        "    \"product_id\",\n",
        "    \"customer_id\"\n",
        "]"
      ],
      "metadata": {
        "id": "pZOjhLZ6Fioa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLUMN_TYPES = {\n",
        "    \"numeric\":[\n",
        "        \"age\",\"salary\",\"price\",\n",
        "        \"amount\",\"quantity\"\n",
        "    ],\n",
        "    \"text\":[\n",
        "        \"name\",\"email\",\n",
        "        \"department\",\"city\",\"country\"\n",
        "    ],\n",
        "    \"date\":[\n",
        "        \"created_at\",\"updated_at\"\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "0dqcpa4NMvJ0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_relational_schema():\n",
        "\n",
        "    num_tables = random.randint(2,5)\n",
        "\n",
        "    fake.unique.clear()\n",
        "\n",
        "    tables = {}\n",
        "    relationships = {}\n",
        "\n",
        "    table_names = [fake.unique.word() for _ in range(num_tables)]\n",
        "\n",
        "    for t in table_names:\n",
        "\n",
        "        cols = {\n",
        "            \"numeric\": random.sample(COLUMN_TYPES[\"numeric\"],\n",
        "                                     random.randint(1,3)),\n",
        "\n",
        "            \"text\": random.sample(COLUMN_TYPES[\"text\"],\n",
        "                                  random.randint(1,3)),\n",
        "\n",
        "            \"date\": random.sample(COLUMN_TYPES[\"date\"],\n",
        "                                  random.randint(0,1))\n",
        "        }\n",
        "\n",
        "        # flatten\n",
        "        flat_cols = [\"id\"]\n",
        "\n",
        "        for v in cols.values():\n",
        "            flat_cols.extend(v)\n",
        "\n",
        "        tables[t] = {\n",
        "            \"all\": flat_cols,\n",
        "            \"numeric\": cols[\"numeric\"],\n",
        "            \"text\": cols[\"text\"],\n",
        "            \"date\": cols[\"date\"]\n",
        "        }\n",
        "\n",
        "    relationships_list = []\n",
        "\n",
        "    for i in range(1, num_tables):\n",
        "\n",
        "        parent = table_names[i-1]\n",
        "        child = table_names[i]\n",
        "\n",
        "        fk = f\"{parent}_id\"\n",
        "\n",
        "        tables[child][\"all\"].append(fk)\n",
        "\n",
        "        relationships_list.append(\n",
        "            (child, fk, parent, \"id\")\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"tables\": tables,\n",
        "        \"relationships\": relationships_list\n",
        "    }"
      ],
      "metadata": {
        "id": "FP1HPZB5Fiqm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def schema_to_text(schema):\n",
        "\n",
        "    parts = []\n",
        "\n",
        "    for table, col_dict in schema[\"tables\"].items():\n",
        "\n",
        "        cols = col_dict[\"all\"]\n",
        "\n",
        "        col_tokens = \" \".join([f\"[COL] {c}\" for c in cols])\n",
        "        parts.append(f\"[TABLE] {table} {col_tokens}\")\n",
        "\n",
        "    # relationships\n",
        "    for child, fk, parent, pk in schema[\"relationships\"]:\n",
        "        parts.append(\n",
        "            f\"[REL] {child}.{fk} -> {parent}.{pk}\"\n",
        "        )\n",
        "\n",
        "    return \" \".join(parts)"
      ],
      "metadata": {
        "id": "2J47wv3MFis7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT_TEMPLATES = [\n",
        "    \"show {col} from {table}\",\n",
        "    \"list {col} in {table}\",\n",
        "    \"display {col} from {table}\",\n",
        "    \"what are the {col} in {table}\",\n",
        "]"
      ],
      "metadata": {
        "id": "cdSBBALCFiv_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sql(schema):\n",
        "\n",
        "    pattern = random.choice(SQL_PATTERNS)\n",
        "\n",
        "    tables = schema[\"tables\"]\n",
        "    rels = schema[\"relationships\"]\n",
        "\n",
        "    table = random.choice(list(tables.keys()))\n",
        "\n",
        "    columns = tables[table][\"all\"]\n",
        "    numeric_cols = tables[table][\"numeric\"]\n",
        "    text_cols = tables[table][\"text\"]\n",
        "\n",
        "    # ---------- SIMPLE SELECT ----------\n",
        "    if pattern == \"simple_select\":\n",
        "\n",
        "        selected = random.sample(\n",
        "            columns,\n",
        "            random.randint(1, min(3, len(columns)))\n",
        "        )\n",
        "\n",
        "        question = f\"show {', '.join(selected)} from {table}\"\n",
        "        sql = f\"SELECT {', '.join(selected)} FROM {table}\"\n",
        "\n",
        "\n",
        "    # ---------- MULTI SELECT ----------\n",
        "    elif pattern == \"multi_select\":\n",
        "\n",
        "        selected = random.sample(\n",
        "            columns,\n",
        "            random.randint(2, min(4, len(columns)))\n",
        "        )\n",
        "\n",
        "        question = f\"show {', '.join(selected)} from {table}\"\n",
        "        sql = f\"SELECT {', '.join(selected)} FROM {table}\"\n",
        "\n",
        "\n",
        "    # ---------- WHERE ----------\n",
        "    elif pattern == \"where\":\n",
        "\n",
        "        # Prefer numeric filters\n",
        "        if numeric_cols and random.random() < 0.7:\n",
        "\n",
        "            col = random.choice(numeric_cols)\n",
        "            operator = random.choice([\"=\", \">\", \"<\"])\n",
        "            value = random.randint(1, 100)\n",
        "\n",
        "        else:\n",
        "\n",
        "            col = random.choice(text_cols if text_cols else columns)\n",
        "            operator = \"=\"\n",
        "            value = f\"'{fake.word()}'\"\n",
        "\n",
        "        question = f\"show {col} from {table} where {col} {operator} {value}\"\n",
        "        sql = f\"SELECT {col} FROM {table} WHERE {col} {operator} {value}\"\n",
        "\n",
        "\n",
        "    # ---------- AGGREGATION ----------\n",
        "    elif pattern == \"aggregation\":\n",
        "\n",
        "        agg = random.choice([\"COUNT\",\"SUM\",\"AVG\",\"MIN\",\"MAX\"])\n",
        "\n",
        "        if agg in [\"SUM\",\"AVG\"]:\n",
        "\n",
        "            if not numeric_cols:\n",
        "                return generate_sql(schema)\n",
        "\n",
        "            col = random.choice(numeric_cols)\n",
        "\n",
        "        elif agg in [\"MIN\",\"MAX\"]:\n",
        "\n",
        "            candidates = numeric_cols + text_cols\n",
        "            if not candidates:\n",
        "                return generate_sql(schema)\n",
        "\n",
        "            col = random.choice(candidates)\n",
        "\n",
        "        else:  # COUNT\n",
        "            col = random.choice(columns)\n",
        "\n",
        "        question = f\"what is the {agg.lower()} of {col} in {table}\"\n",
        "        sql = f\"SELECT {agg}({col}) FROM {table}\"\n",
        "        # ---------- ORDER BY ----------\n",
        "    elif pattern == \"order_by\":\n",
        "\n",
        "        # prefer numeric columns for sorting\n",
        "        if numeric_cols:\n",
        "            col = random.choice(numeric_cols)\n",
        "        else:\n",
        "            col = random.choice(columns)\n",
        "\n",
        "        direction = random.choice([\"ASC\",\"DESC\"])\n",
        "\n",
        "        question = f\"show all records from {table} ordered by {col} {direction.lower()}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT *\n",
        "        FROM {table}\n",
        "        ORDER BY {col} {direction}\n",
        "        \"\"\"\n",
        "        # ---------- LIMIT ----------\n",
        "    elif pattern == \"limit\":\n",
        "\n",
        "        limit_val = random.randint(3,20)\n",
        "\n",
        "        question = f\"show first {limit_val} rows from {table}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM {table}\n",
        "LIMIT {limit_val}\n",
        "\"\"\"\n",
        "        # ---------- ORDER BY + LIMIT ----------\n",
        "    elif pattern == \"order_by_limit\":\n",
        "\n",
        "        if numeric_cols:\n",
        "            col = random.choice(numeric_cols)\n",
        "        else:\n",
        "            col = random.choice(columns)\n",
        "\n",
        "        direction = random.choice([\"ASC\",\"DESC\"])\n",
        "        limit_val = random.randint(3,15)\n",
        "\n",
        "        question = f\"show top {limit_val} records from {table} ordered by {col}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM {table}\n",
        "ORDER BY {col} {direction}\n",
        "LIMIT {limit_val}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    # ---------- GROUP BY ----------\n",
        "    elif pattern == \"group_by\":\n",
        "\n",
        "        group_candidates = text_cols if text_cols else columns\n",
        "        group_col = random.choice(group_candidates)\n",
        "\n",
        "        if numeric_cols:\n",
        "            agg_col = random.choice(numeric_cols)\n",
        "        else:\n",
        "            return generate_sql(schema)\n",
        "\n",
        "        agg = random.choice([\"COUNT\",\"SUM\",\"AVG\",\"MIN\",\"MAX\"])\n",
        "\n",
        "        question = f\"{agg.lower()} of {agg_col} grouped by {group_col}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "SELECT {group_col}, {agg}({agg_col})\n",
        "FROM {table}\n",
        "GROUP BY {group_col}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    # ---------- HAVING ----------\n",
        "    elif pattern == \"having\":\n",
        "\n",
        "        group_candidates = text_cols if text_cols else columns\n",
        "        group_col = random.choice(group_candidates)\n",
        "\n",
        "        if not numeric_cols:\n",
        "            return generate_sql(schema)\n",
        "\n",
        "        agg_col = random.choice(numeric_cols)\n",
        "        agg = random.choice([\"COUNT\",\"SUM\",\"AVG\",\"MIN\",\"MAX\"])\n",
        "\n",
        "        operator = random.choice([\">\", \"<\", \"=\"])\n",
        "        value = random.randint(1,50)\n",
        "\n",
        "        question = f\"{agg.lower()} of {agg_col} grouped by {group_col} having value {operator} {value}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "SELECT {group_col}, {agg}({agg_col})\n",
        "FROM {table}\n",
        "GROUP BY {group_col}\n",
        "HAVING {agg}({agg_col}) {operator} {value}\n",
        "\"\"\"\n",
        "    # ---------- JOIN + WHERE ----------\n",
        "    elif pattern == \"join_where\" and rels:\n",
        "\n",
        "        child, fk, parent, pk = random.choice(rels)\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            left, right = parent, child\n",
        "            left_key, right_key = pk, fk\n",
        "        else:\n",
        "            left, right = child, parent\n",
        "            left_key, right_key = fk, pk\n",
        "\n",
        "        right_numeric = tables[right][\"numeric\"]\n",
        "        right_text = tables[right][\"text\"]\n",
        "\n",
        "        if right_numeric and random.random() < 0.7:\n",
        "\n",
        "            where_col = random.choice(right_numeric)\n",
        "            operator = random.choice([\">\",\"<\",\"=\"])\n",
        "            value = random.randint(1,100)\n",
        "\n",
        "        else:\n",
        "\n",
        "            candidates = right_text if right_text else right_numeric\n",
        "            if not candidates:\n",
        "                return generate_sql(schema)\n",
        "\n",
        "            where_col = random.choice(candidates)\n",
        "            operator = \"=\"\n",
        "            value = f\"'{fake.word()}'\"\n",
        "\n",
        "        select_col = random.choice(tables[left][\"all\"])\n",
        "\n",
        "        question = f\"show {select_col} from {left} joined with {right} where {where_col} {operator} {value}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "SELECT {left}.{select_col}\n",
        "FROM {left}\n",
        "JOIN {right}\n",
        "ON {left}.{left_key} = {right}.{right_key}\n",
        "WHERE {right}.{where_col} {operator} {value}\n",
        "\"\"\"\n",
        "\n",
        "    # ---------- JOIN ----------\n",
        "    elif pattern == \"join\" and rels:\n",
        "\n",
        "        child, fk, parent, pk = random.choice(rels)\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            left, right = parent, child\n",
        "            left_key, right_key = pk, fk\n",
        "        else:\n",
        "            left, right = child, parent\n",
        "            left_key, right_key = fk, pk\n",
        "\n",
        "        select_col = random.choice(tables[left][\"all\"])\n",
        "\n",
        "        question = f\"show {select_col} from {left} joined with {right}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "SELECT {left}.{select_col}\n",
        "FROM {left}\n",
        "JOIN {right}\n",
        "ON {left}.{left_key} = {right}.{right_key}\n",
        "\"\"\"\n",
        "\n",
        "    else:\n",
        "        return generate_sql(schema)\n",
        "\n",
        "    return question.strip(), sql.strip()"
      ],
      "metadata": {
        "id": "SxOl0INZFizX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset_by_schema(num_schemas=8000,\n",
        "                            queries_per_schema=8):\n",
        "\n",
        "    schemas = [generate_relational_schema()\n",
        "               for _ in range(num_schemas)]\n",
        "\n",
        "    split = int(0.9 * num_schemas)\n",
        "\n",
        "    train_s = schemas[:split]\n",
        "    test_s = schemas[split:]\n",
        "\n",
        "    def build_examples(schema_list):\n",
        "\n",
        "        data = []\n",
        "\n",
        "        for schema in schema_list:\n",
        "\n",
        "            schema_text = schema_to_text(schema)\n",
        "\n",
        "            for _ in range(queries_per_schema):\n",
        "\n",
        "                q, sql = generate_sql(schema)\n",
        "\n",
        "                model_input = f\"\"\"\n",
        "Schema:\n",
        "{schema_text}\n",
        "\n",
        "Question:\n",
        "{q}\n",
        "\"\"\"\n",
        "\n",
        "                data.append({\n",
        "                    \"input\": model_input.strip(),\n",
        "                    \"output\": sql.strip()\n",
        "                })\n",
        "\n",
        "        return data\n",
        "\n",
        "    return build_examples(train_s), build_examples(test_s)\n",
        "\n",
        "\n",
        "train, test = build_dataset_by_schema()\n",
        "\n",
        "print(\"Train:\", len(train))\n",
        "print(\"Test:\", len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eFqq1tIGfzb",
        "outputId": "eada32ff-c4fa-4bdc-cf5b-83e0f4bc08f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 57600\n",
            "Test: 6400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"train.json\", \"w\") as f:\n",
        "    json.dump(train, f)\n",
        "\n",
        "with open(\"test.json\", \"w\") as f:\n",
        "    json.dump(test, f)\n",
        "\n",
        "print(\"✅ Dataset saved as JSON\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdjAeBQmWaxB",
        "outputId": "069b4956-58b9-4838-8b65-92b1d3444f25"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset saved as JSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(data):\n",
        "\n",
        "    counter = Counter()\n",
        "\n",
        "    for row in data:\n",
        "        counter.update(row[\"input\"].split())\n",
        "        counter.update(row[\"output\"].split())\n",
        "\n",
        "    vocab = {w:i+2 for i,(w,_) in enumerate(counter.items())}\n",
        "    vocab[\"<pad>\"] = 0\n",
        "    vocab[\"<unk>\"] = 1\n",
        "\n",
        "    return vocab\n",
        "\n",
        "vocab = build_vocab(train)\n",
        "\n",
        "torch.save(vocab, \"vocab.pt\")"
      ],
      "metadata": {
        "id": "ijPR7psAGf16"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 220\n",
        "\n",
        "def encode(text):\n",
        "\n",
        "    tokens = text.split()\n",
        "\n",
        "    ids = [vocab.get(t,1) for t in tokens][:MAX_LEN]\n",
        "\n",
        "    ids += [0]*(MAX_LEN-len(ids))\n",
        "\n",
        "    return torch.tensor(ids)\n",
        "\n",
        "class NL2SQLDataset(Dataset):\n",
        "\n",
        "    def __init__(self,data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        row = self.data[idx]\n",
        "\n",
        "        return encode(row[\"input\"]), encode(row[\"output\"])"
      ],
      "metadata": {
        "id": "-ECMgN75Gf4i"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"train.json\") as f:\n",
        "    train = json.load(f)\n",
        "\n",
        "with open(\"test.json\") as f:\n",
        "    test = json.load(f)\n",
        "\n",
        "print(\"✅ Dataset loaded!\")\n",
        "print(\"Train size:\", len(train))\n"
      ],
      "metadata": {
        "id": "yIyTYqmBZYHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NL2SQLModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, d_model=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=8,\n",
        "            num_encoder_layers=3,\n",
        "            num_decoder_layers=3,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "\n",
        "        src_mask = (src == 0)\n",
        "        tgt_mask = (tgt == 0)\n",
        "\n",
        "        src = self.embed(src)\n",
        "        tgt = self.embed(tgt)\n",
        "\n",
        "        out = self.transformer(\n",
        "            src,\n",
        "            tgt,\n",
        "            src_key_padding_mask=src_mask,\n",
        "            tgt_key_padding_mask=tgt_mask\n",
        "        )\n",
        "\n",
        "        return self.fc(out)"
      ],
      "metadata": {
        "id": "C-TVvOjHGf61"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(train[i][\"input\"])\n",
        "    print(train[i][\"output\"])\n",
        "    print(\"-----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vv8PWShLVwS",
        "outputId": "f6a0200a-69cd-4ec2-9d78-3043e20425fa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema:\n",
            "[TABLE] new [COL] id [COL] price [COL] email [TABLE] hospital [COL] id [COL] age [COL] quantity [COL] price [COL] name [COL] country [COL] new_id [REL] hospital.new_id -> new.id\n",
            "\n",
            "Question:\n",
            "what is the count of quantity in hospital\n",
            "SELECT COUNT(quantity) FROM hospital\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] new [COL] id [COL] price [COL] email [TABLE] hospital [COL] id [COL] age [COL] quantity [COL] price [COL] name [COL] country [COL] new_id [REL] hospital.new_id -> new.id\n",
            "\n",
            "Question:\n",
            "show price from hospital where price = 12\n",
            "SELECT price FROM hospital WHERE price = 12\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] new [COL] id [COL] price [COL] email [TABLE] hospital [COL] id [COL] age [COL] quantity [COL] price [COL] name [COL] country [COL] new_id [REL] hospital.new_id -> new.id\n",
            "\n",
            "Question:\n",
            "show country from hospital joined with new\n",
            "SELECT hospital.country\n",
            "FROM hospital\n",
            "JOIN new\n",
            "ON hospital.new_id = new.id\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] new [COL] id [COL] price [COL] email [TABLE] hospital [COL] id [COL] age [COL] quantity [COL] price [COL] name [COL] country [COL] new_id [REL] hospital.new_id -> new.id\n",
            "\n",
            "Question:\n",
            "show price from hospital joined with new\n",
            "SELECT hospital.price\n",
            "FROM hospital\n",
            "JOIN new\n",
            "ON hospital.new_id = new.id\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] new [COL] id [COL] price [COL] email [TABLE] hospital [COL] id [COL] age [COL] quantity [COL] price [COL] name [COL] country [COL] new_id [REL] hospital.new_id -> new.id\n",
            "\n",
            "Question:\n",
            "sum of price grouped by email\n",
            "SELECT email, SUM(price)\n",
            "FROM new\n",
            "GROUP BY email\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] new [COL] id [COL] price [COL] email [TABLE] hospital [COL] id [COL] age [COL] quantity [COL] price [COL] name [COL] country [COL] new_id [REL] hospital.new_id -> new.id\n",
            "\n",
            "Question:\n",
            "show id from new joined with hospital\n",
            "SELECT new.id\n",
            "FROM new\n",
            "JOIN hospital\n",
            "ON new.id = hospital.new_id\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] new [COL] id [COL] price [COL] email [TABLE] hospital [COL] id [COL] age [COL] quantity [COL] price [COL] name [COL] country [COL] new_id [REL] hospital.new_id -> new.id\n",
            "\n",
            "Question:\n",
            "show email, id, price from new\n",
            "SELECT email, id, price FROM new\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] new [COL] id [COL] price [COL] email [TABLE] hospital [COL] id [COL] age [COL] quantity [COL] price [COL] name [COL] country [COL] new_id [REL] hospital.new_id -> new.id\n",
            "\n",
            "Question:\n",
            "max of price grouped by email having value = 47\n",
            "SELECT email, MAX(price)\n",
            "FROM new\n",
            "GROUP BY email\n",
            "HAVING MAX(price) = 47\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] move [COL] id [COL] quantity [COL] name [COL] email [COL] department [COL] created_at [TABLE] Mr [COL] id [COL] quantity [COL] price [COL] email [COL] updated_at [COL] move_id [TABLE] listen [COL] id [COL] salary [COL] quantity [COL] name [COL] country [COL] created_at [COL] Mr_id [REL] Mr.move_id -> move.id [REL] listen.Mr_id -> Mr.id\n",
            "\n",
            "Question:\n",
            "avg of quantity grouped by email\n",
            "SELECT email, AVG(quantity)\n",
            "FROM Mr\n",
            "GROUP BY email\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] move [COL] id [COL] quantity [COL] name [COL] email [COL] department [COL] created_at [TABLE] Mr [COL] id [COL] quantity [COL] price [COL] email [COL] updated_at [COL] move_id [TABLE] listen [COL] id [COL] salary [COL] quantity [COL] name [COL] country [COL] created_at [COL] Mr_id [REL] Mr.move_id -> move.id [REL] listen.Mr_id -> Mr.id\n",
            "\n",
            "Question:\n",
            "min of quantity grouped by country\n",
            "SELECT country, MIN(quantity)\n",
            "FROM listen\n",
            "GROUP BY country\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] move [COL] id [COL] quantity [COL] name [COL] email [COL] department [COL] created_at [TABLE] Mr [COL] id [COL] quantity [COL] price [COL] email [COL] updated_at [COL] move_id [TABLE] listen [COL] id [COL] salary [COL] quantity [COL] name [COL] country [COL] created_at [COL] Mr_id [REL] Mr.move_id -> move.id [REL] listen.Mr_id -> Mr.id\n",
            "\n",
            "Question:\n",
            "show salary from listen where salary > 76\n",
            "SELECT salary FROM listen WHERE salary > 76\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] move [COL] id [COL] quantity [COL] name [COL] email [COL] department [COL] created_at [TABLE] Mr [COL] id [COL] quantity [COL] price [COL] email [COL] updated_at [COL] move_id [TABLE] listen [COL] id [COL] salary [COL] quantity [COL] name [COL] country [COL] created_at [COL] Mr_id [REL] Mr.move_id -> move.id [REL] listen.Mr_id -> Mr.id\n",
            "\n",
            "Question:\n",
            "sum of price grouped by email\n",
            "SELECT email, SUM(price)\n",
            "FROM Mr\n",
            "GROUP BY email\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] move [COL] id [COL] quantity [COL] name [COL] email [COL] department [COL] created_at [TABLE] Mr [COL] id [COL] quantity [COL] price [COL] email [COL] updated_at [COL] move_id [TABLE] listen [COL] id [COL] salary [COL] quantity [COL] name [COL] country [COL] created_at [COL] Mr_id [REL] Mr.move_id -> move.id [REL] listen.Mr_id -> Mr.id\n",
            "\n",
            "Question:\n",
            "what is the min of department in move\n",
            "SELECT MIN(department) FROM move\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] move [COL] id [COL] quantity [COL] name [COL] email [COL] department [COL] created_at [TABLE] Mr [COL] id [COL] quantity [COL] price [COL] email [COL] updated_at [COL] move_id [TABLE] listen [COL] id [COL] salary [COL] quantity [COL] name [COL] country [COL] created_at [COL] Mr_id [REL] Mr.move_id -> move.id [REL] listen.Mr_id -> Mr.id\n",
            "\n",
            "Question:\n",
            "show email from move\n",
            "SELECT email FROM move\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] move [COL] id [COL] quantity [COL] name [COL] email [COL] department [COL] created_at [TABLE] Mr [COL] id [COL] quantity [COL] price [COL] email [COL] updated_at [COL] move_id [TABLE] listen [COL] id [COL] salary [COL] quantity [COL] name [COL] country [COL] created_at [COL] Mr_id [REL] Mr.move_id -> move.id [REL] listen.Mr_id -> Mr.id\n",
            "\n",
            "Question:\n",
            "sum of quantity grouped by country\n",
            "SELECT country, SUM(quantity)\n",
            "FROM listen\n",
            "GROUP BY country\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] move [COL] id [COL] quantity [COL] name [COL] email [COL] department [COL] created_at [TABLE] Mr [COL] id [COL] quantity [COL] price [COL] email [COL] updated_at [COL] move_id [TABLE] listen [COL] id [COL] salary [COL] quantity [COL] name [COL] country [COL] created_at [COL] Mr_id [REL] Mr.move_id -> move.id [REL] listen.Mr_id -> Mr.id\n",
            "\n",
            "Question:\n",
            "what is the count of id in move\n",
            "SELECT COUNT(id) FROM move\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] street [COL] id [COL] quantity [COL] price [COL] city [TABLE] structure [COL] id [COL] age [COL] price [COL] country [COL] department [COL] city [COL] street_id [TABLE] win [COL] id [COL] age [COL] quantity [COL] price [COL] department [COL] structure_id [TABLE] computer [COL] id [COL] age [COL] department [COL] city [COL] created_at [COL] win_id [REL] structure.street_id -> street.id [REL] win.structure_id -> structure.id [REL] computer.win_id -> win.id\n",
            "\n",
            "Question:\n",
            "avg of age grouped by city\n",
            "SELECT city, AVG(age)\n",
            "FROM computer\n",
            "GROUP BY city\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] street [COL] id [COL] quantity [COL] price [COL] city [TABLE] structure [COL] id [COL] age [COL] price [COL] country [COL] department [COL] city [COL] street_id [TABLE] win [COL] id [COL] age [COL] quantity [COL] price [COL] department [COL] structure_id [TABLE] computer [COL] id [COL] age [COL] department [COL] city [COL] created_at [COL] win_id [REL] structure.street_id -> street.id [REL] win.structure_id -> structure.id [REL] computer.win_id -> win.id\n",
            "\n",
            "Question:\n",
            "show id, age, city from structure\n",
            "SELECT id, age, city FROM structure\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] street [COL] id [COL] quantity [COL] price [COL] city [TABLE] structure [COL] id [COL] age [COL] price [COL] country [COL] department [COL] city [COL] street_id [TABLE] win [COL] id [COL] age [COL] quantity [COL] price [COL] department [COL] structure_id [TABLE] computer [COL] id [COL] age [COL] department [COL] city [COL] created_at [COL] win_id [REL] structure.street_id -> street.id [REL] win.structure_id -> structure.id [REL] computer.win_id -> win.id\n",
            "\n",
            "Question:\n",
            "show street_id from structure joined with win\n",
            "SELECT structure.street_id\n",
            "FROM structure\n",
            "JOIN win\n",
            "ON structure.id = win.structure_id\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] street [COL] id [COL] quantity [COL] price [COL] city [TABLE] structure [COL] id [COL] age [COL] price [COL] country [COL] department [COL] city [COL] street_id [TABLE] win [COL] id [COL] age [COL] quantity [COL] price [COL] department [COL] structure_id [TABLE] computer [COL] id [COL] age [COL] department [COL] city [COL] created_at [COL] win_id [REL] structure.street_id -> street.id [REL] win.structure_id -> structure.id [REL] computer.win_id -> win.id\n",
            "\n",
            "Question:\n",
            "show created_at from computer joined with win\n",
            "SELECT computer.created_at\n",
            "FROM computer\n",
            "JOIN win\n",
            "ON computer.win_id = win.id\n",
            "-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    NL2SQLDataset(train),\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "model = NL2SQLModel(len(vocab)).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=0)"
      ],
      "metadata": {
        "id": "5PESpD8FGf9I"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_PATH = \"nl2sql_checkpoint.pt\"\n",
        "\n",
        "def save_checkpoint(epoch, model, optimizer, loss):\n",
        "\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"loss\": loss\n",
        "    }, CHECKPOINT_PATH)\n",
        "\n",
        "def load_checkpoint(model, optimizer):\n",
        "\n",
        "    if os.path.exists(CHECKPOINT_PATH):\n",
        "\n",
        "        ckpt = torch.load(CHECKPOINT_PATH,\n",
        "                          map_location=device)\n",
        "\n",
        "        model.load_state_dict(ckpt[\"model_state\"])\n",
        "        optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
        "\n",
        "        print(\"Resuming from epoch:\",\n",
        "              ckpt[\"epoch\"]+1)\n",
        "\n",
        "        return ckpt[\"epoch\"] + 1\n",
        "\n",
        "    return 0"
      ],
      "metadata": {
        "id": "pi6TnwL9Gf_d"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "best_loss = float(\"inf\")\n",
        "\n",
        "start_epoch = load_checkpoint(model, optimizer)\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(x, y[:,:-1])\n",
        "\n",
        "        loss = loss_fn(\n",
        "            output.reshape(-1, len(vocab)),\n",
        "            y[:,1:].reshape(-1)\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch} | Loss {avg_loss}\")\n",
        "\n",
        "    save_checkpoint(epoch, model, optimizer, avg_loss)\n",
        "\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        torch.save(model.state_dict(),\n",
        "                   \"best_model.pt\")\n",
        "        print(\"⭐ BEST MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5d62paSTGgB6",
        "outputId": "a31d31c8-1e2c-4ff0-89cd-f65a16246103"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1006010197.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- LOAD VOCAB ----------\n",
        "vocab = torch.load(\"vocab.pt\")\n",
        "inv_vocab = {i:w for w,i in vocab.items()}\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "# ---------- REBUILD MODEL ----------\n",
        "model = NL2SQLModel(len(vocab)).to(device)\n",
        "\n",
        "model.load_state_dict(\n",
        "    torch.load(\"best_model.pt\", map_location=device)\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print(\"✅ Best model loaded!\")\n"
      ],
      "metadata": {
        "id": "88bvEFs3GgET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 220\n",
        "\n",
        "def encode(text):\n",
        "\n",
        "    tokens = text.split()\n",
        "\n",
        "    ids = [vocab.get(t,1) for t in tokens][:MAX_LEN]\n",
        "\n",
        "    ids += [0]*(MAX_LEN-len(ids))\n",
        "\n",
        "    return torch.tensor(ids)\n"
      ],
      "metadata": {
        "id": "5cnMD7NEGgIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_query(model, text, max_len=220):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    src = encode(text).unsqueeze(0).to(device)\n",
        "\n",
        "    tgt = torch.zeros((1,1), dtype=torch.long).to(device)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "\n",
        "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(\n",
        "            tgt.size(1)\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            output = model.transformer(\n",
        "                model.embed(src),\n",
        "                model.embed(tgt),\n",
        "                tgt_mask=tgt_mask,\n",
        "                src_key_padding_mask=(src==0),\n",
        "                tgt_key_padding_mask=(tgt==0)\n",
        "            )\n",
        "\n",
        "            logits = model.fc(output)\n",
        "\n",
        "        next_token = logits.argmax(-1)[:,-1].unsqueeze(0)\n",
        "\n",
        "        tgt = torch.cat([tgt, next_token], dim=1)\n",
        "\n",
        "        if next_token.item() == 0:\n",
        "            break\n",
        "\n",
        "\n",
        "    tokens = [\n",
        "        inv_vocab.get(i,\"\")\n",
        "        for i in tgt.squeeze().tolist()\n",
        "    ]\n",
        "\n",
        "    return \" \".join(tokens)\n"
      ],
      "metadata": {
        "id": "YeGVvn7RIgUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nbZc46UCIgbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uJ4cwf1OIges"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}