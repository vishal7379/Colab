{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal7379/Colab/blob/main/NL_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker\n",
        "\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from faker import Faker\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wacCB09hFijs",
        "outputId": "df97f59d-5f5a-49af-fa5f-206407ab0dee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-40.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Downloading faker-40.4.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-40.4.0\n",
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SQL_PATTERNS = (\n",
        "    [\"join\"] * 5 +\n",
        "    [\"join_where\"] * 4 +        # ⭐ NEW\n",
        "    [\"group_by\"] * 3 +\n",
        "    [\"having\"] * 2 +\n",
        "    [\"where\"] * 2 +\n",
        "    [\"aggregation\"] * 2 +\n",
        "    [\"order_by\"] * 3 +         # ⭐ NEW\n",
        "    [\"limit\"] * 2 +            # ⭐ NEW\n",
        "    [\"order_by_limit\"] * 3 +   # ⭐ VERY IMPORTANT\n",
        "    [\"multi_select\"] +\n",
        "    [\"simple_select\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "SMYdGF_-FimD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_COLUMNS = [\n",
        "    \"name\",\"email\",\"age\",\"salary\",\n",
        "    \"department\",\"city\",\"country\",\n",
        "    \"price\",\"amount\",\"quantity\",\n",
        "    \"created_at\",\"updated_at\"\n",
        "]\n",
        "\n",
        "FK_COLUMNS = [\n",
        "    \"user_id\",\n",
        "    \"order_id\",\n",
        "    \"product_id\",\n",
        "    \"customer_id\"\n",
        "]"
      ],
      "metadata": {
        "id": "pZOjhLZ6Fioa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLUMN_TYPES = {\n",
        "    \"numeric\":[\n",
        "        \"age\",\"salary\",\"price\",\n",
        "        \"amount\",\"quantity\"\n",
        "    ],\n",
        "    \"text\":[\n",
        "        \"name\",\"email\",\n",
        "        \"department\",\"city\",\"country\"\n",
        "    ],\n",
        "    \"date\":[\n",
        "        \"created_at\",\"updated_at\"\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "0dqcpa4NMvJ0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_relational_schema():\n",
        "\n",
        "    num_tables = random.randint(2,5)\n",
        "\n",
        "    fake.unique.clear()\n",
        "\n",
        "    tables = {}\n",
        "    relationships = {}\n",
        "\n",
        "    table_names = [fake.unique.word() for _ in range(num_tables)]\n",
        "\n",
        "    for t in table_names:\n",
        "\n",
        "        cols = {\n",
        "            \"numeric\": random.sample(COLUMN_TYPES[\"numeric\"],\n",
        "                                     random.randint(1,3)),\n",
        "\n",
        "            \"text\": random.sample(COLUMN_TYPES[\"text\"],\n",
        "                                  random.randint(1,3)),\n",
        "\n",
        "            \"date\": random.sample(COLUMN_TYPES[\"date\"],\n",
        "                                  random.randint(0,1))\n",
        "        }\n",
        "\n",
        "        # flatten\n",
        "        flat_cols = [\"id\"]\n",
        "\n",
        "        for v in cols.values():\n",
        "            flat_cols.extend(v)\n",
        "\n",
        "        tables[t] = {\n",
        "            \"all\": flat_cols,\n",
        "            \"numeric\": cols[\"numeric\"],\n",
        "            \"text\": cols[\"text\"],\n",
        "            \"date\": cols[\"date\"]\n",
        "        }\n",
        "\n",
        "    relationships_list = []\n",
        "\n",
        "    for i in range(1, num_tables):\n",
        "\n",
        "        parent = table_names[i-1]\n",
        "        child = table_names[i]\n",
        "\n",
        "        fk = f\"{parent}_id\"\n",
        "\n",
        "        tables[child][\"all\"].append(fk)\n",
        "\n",
        "        relationships_list.append(\n",
        "            (child, fk, parent, \"id\")\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"tables\": tables,\n",
        "        \"relationships\": relationships_list\n",
        "    }"
      ],
      "metadata": {
        "id": "FP1HPZB5Fiqm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def schema_to_text(schema):\n",
        "\n",
        "    parts = []\n",
        "\n",
        "    for table, col_dict in schema[\"tables\"].items():\n",
        "\n",
        "        cols = col_dict[\"all\"]\n",
        "\n",
        "        col_tokens = \" \".join([f\"[COL] {c}\" for c in cols])\n",
        "        parts.append(f\"[TABLE] {table} {col_tokens}\")\n",
        "\n",
        "    # relationships\n",
        "    for child, fk, parent, pk in schema[\"relationships\"]:\n",
        "        parts.append(\n",
        "            f\"[REL] {child}.{fk} -> {parent}.{pk}\"\n",
        "        )\n",
        "\n",
        "    return \" \".join(parts)"
      ],
      "metadata": {
        "id": "2J47wv3MFis7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT_TEMPLATES = [\n",
        "    \"show {col} from {table}\",\n",
        "    \"list {col} in {table}\",\n",
        "    \"display {col} from {table}\",\n",
        "    \"what are the {col} in {table}\",\n",
        "]"
      ],
      "metadata": {
        "id": "cdSBBALCFiv_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sql(schema):\n",
        "\n",
        "    pattern = random.choice(SQL_PATTERNS)\n",
        "\n",
        "    tables = schema[\"tables\"]\n",
        "    rels = schema[\"relationships\"]\n",
        "\n",
        "    table = random.choice(list(tables.keys()))\n",
        "\n",
        "    columns = tables[table][\"all\"]\n",
        "    numeric_cols = tables[table][\"numeric\"]\n",
        "    text_cols = tables[table][\"text\"]\n",
        "\n",
        "    # ---------- SIMPLE SELECT ----------\n",
        "    if pattern == \"simple_select\":\n",
        "\n",
        "        selected = random.sample(\n",
        "            columns,\n",
        "            random.randint(1, min(3, len(columns)))\n",
        "        )\n",
        "\n",
        "        question = f\"show {', '.join(selected)} from {table}\"\n",
        "        sql = f\"SELECT {', '.join(selected)} FROM {table}\"\n",
        "\n",
        "\n",
        "    # ---------- MULTI SELECT ----------\n",
        "    elif pattern == \"multi_select\":\n",
        "\n",
        "        selected = random.sample(\n",
        "            columns,\n",
        "            random.randint(2, min(4, len(columns)))\n",
        "        )\n",
        "\n",
        "        question = f\"show {', '.join(selected)} from {table}\"\n",
        "        sql = f\"SELECT {', '.join(selected)} FROM {table}\"\n",
        "\n",
        "\n",
        "    # ---------- WHERE ----------\n",
        "    elif pattern == \"where\":\n",
        "\n",
        "        # Prefer numeric filters\n",
        "        if numeric_cols and random.random() < 0.7:\n",
        "\n",
        "            col = random.choice(numeric_cols)\n",
        "            operator = random.choice([\"=\", \">\", \"<\"])\n",
        "            value = random.randint(1, 100)\n",
        "\n",
        "        else:\n",
        "\n",
        "            col = random.choice(text_cols if text_cols else columns)\n",
        "            operator = \"=\"\n",
        "            value = f\"'{fake.word()}'\"\n",
        "\n",
        "        question = f\"show {col} from {table} where {col} {operator} {value}\"\n",
        "        sql = f\"SELECT {col} FROM {table} WHERE {col} {operator} {value}\"\n",
        "\n",
        "\n",
        "    # ---------- AGGREGATION ----------\n",
        "    elif pattern == \"aggregation\":\n",
        "\n",
        "        agg = random.choice([\"COUNT\",\"SUM\",\"AVG\",\"MIN\",\"MAX\"])\n",
        "\n",
        "        if agg in [\"SUM\",\"AVG\"]:\n",
        "\n",
        "            if not numeric_cols:\n",
        "                return generate_sql(schema)\n",
        "\n",
        "            col = random.choice(numeric_cols)\n",
        "\n",
        "        elif agg in [\"MIN\",\"MAX\"]:\n",
        "\n",
        "            candidates = numeric_cols + text_cols\n",
        "            if not candidates:\n",
        "                return generate_sql(schema)\n",
        "\n",
        "            col = random.choice(candidates)\n",
        "\n",
        "        else:  # COUNT\n",
        "            col = random.choice(columns)\n",
        "\n",
        "        question = f\"what is the {agg.lower()} of {col} in {table}\"\n",
        "        sql = f\"SELECT {agg}({col}) FROM {table}\"\n",
        "        # ---------- ORDER BY ----------\n",
        "    elif pattern == \"order_by\":\n",
        "\n",
        "        # prefer numeric columns for sorting\n",
        "        if numeric_cols:\n",
        "            col = random.choice(numeric_cols)\n",
        "        else:\n",
        "            col = random.choice(columns)\n",
        "\n",
        "        direction = random.choice([\"ASC\",\"DESC\"])\n",
        "\n",
        "        question = f\"show all records from {table} ordered by {col} {direction.lower()}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT *\n",
        "        FROM {table}\n",
        "        ORDER BY {col} {direction}\n",
        "        \"\"\"\n",
        "        # ---------- LIMIT ----------\n",
        "    elif pattern == \"limit\":\n",
        "\n",
        "        limit_val = random.randint(3,20)\n",
        "\n",
        "        question = f\"show first {limit_val} rows from {table}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM {table}\n",
        "LIMIT {limit_val}\n",
        "\"\"\"\n",
        "        # ---------- ORDER BY + LIMIT ----------\n",
        "    elif pattern == \"order_by_limit\":\n",
        "\n",
        "        if numeric_cols:\n",
        "            col = random.choice(numeric_cols)\n",
        "        else:\n",
        "            col = random.choice(columns)\n",
        "\n",
        "        direction = random.choice([\"ASC\",\"DESC\"])\n",
        "        limit_val = random.randint(3,15)\n",
        "\n",
        "        question = f\"show top {limit_val} records from {table} ordered by {col}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "SELECT *\n",
        "FROM {table}\n",
        "ORDER BY {col} {direction}\n",
        "LIMIT {limit_val}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    # ---------- GROUP BY ----------\n",
        "    elif pattern == \"group_by\":\n",
        "\n",
        "        group_candidates = text_cols if text_cols else columns\n",
        "        group_col = random.choice(group_candidates)\n",
        "\n",
        "        if numeric_cols:\n",
        "            agg_col = random.choice(numeric_cols)\n",
        "        else:\n",
        "            return generate_sql(schema)\n",
        "\n",
        "        agg = random.choice([\"COUNT\",\"SUM\",\"AVG\",\"MIN\",\"MAX\"])\n",
        "\n",
        "        question = f\"{agg.lower()} of {agg_col} grouped by {group_col}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "SELECT {group_col}, {agg}({agg_col})\n",
        "FROM {table}\n",
        "GROUP BY {group_col}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    # ---------- HAVING ----------\n",
        "    elif pattern == \"having\":\n",
        "\n",
        "        group_candidates = text_cols if text_cols else columns\n",
        "        group_col = random.choice(group_candidates)\n",
        "\n",
        "        if not numeric_cols:\n",
        "            return generate_sql(schema)\n",
        "\n",
        "        agg_col = random.choice(numeric_cols)\n",
        "        agg = random.choice([\"COUNT\",\"SUM\",\"AVG\",\"MIN\",\"MAX\"])\n",
        "\n",
        "        operator = random.choice([\">\", \"<\", \"=\"])\n",
        "        value = random.randint(1,50)\n",
        "\n",
        "        question = f\"{agg.lower()} of {agg_col} grouped by {group_col} having value {operator} {value}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "SELECT {group_col}, {agg}({agg_col})\n",
        "FROM {table}\n",
        "GROUP BY {group_col}\n",
        "HAVING {agg}({agg_col}) {operator} {value}\n",
        "\"\"\"\n",
        "    # ---------- JOIN + WHERE ----------\n",
        "    elif pattern == \"join_where\" and rels:\n",
        "\n",
        "        child, fk, parent, pk = random.choice(rels)\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            left, right = parent, child\n",
        "            left_key, right_key = pk, fk\n",
        "        else:\n",
        "            left, right = child, parent\n",
        "            left_key, right_key = fk, pk\n",
        "\n",
        "        right_numeric = tables[right][\"numeric\"]\n",
        "        right_text = tables[right][\"text\"]\n",
        "\n",
        "        if right_numeric and random.random() < 0.7:\n",
        "\n",
        "            where_col = random.choice(right_numeric)\n",
        "            operator = random.choice([\">\",\"<\",\"=\"])\n",
        "            value = random.randint(1,100)\n",
        "\n",
        "        else:\n",
        "\n",
        "            candidates = right_text if right_text else right_numeric\n",
        "            if not candidates:\n",
        "                return generate_sql(schema)\n",
        "\n",
        "            where_col = random.choice(candidates)\n",
        "            operator = \"=\"\n",
        "            value = f\"'{fake.word()}'\"\n",
        "\n",
        "        select_col = random.choice(tables[left][\"all\"])\n",
        "\n",
        "        question = f\"show {select_col} from {left} joined with {right} where {where_col} {operator} {value}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "SELECT {left}.{select_col}\n",
        "FROM {left}\n",
        "JOIN {right}\n",
        "ON {left}.{left_key} = {right}.{right_key}\n",
        "WHERE {right}.{where_col} {operator} {value}\n",
        "\"\"\"\n",
        "\n",
        "    # ---------- JOIN ----------\n",
        "    elif pattern == \"join\" and rels:\n",
        "\n",
        "        child, fk, parent, pk = random.choice(rels)\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            left, right = parent, child\n",
        "            left_key, right_key = pk, fk\n",
        "        else:\n",
        "            left, right = child, parent\n",
        "            left_key, right_key = fk, pk\n",
        "\n",
        "        select_col = random.choice(tables[left][\"all\"])\n",
        "\n",
        "        question = f\"show {select_col} from {left} joined with {right}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "SELECT {left}.{select_col}\n",
        "FROM {left}\n",
        "JOIN {right}\n",
        "ON {left}.{left_key} = {right}.{right_key}\n",
        "\"\"\"\n",
        "\n",
        "    else:\n",
        "        return generate_sql(schema)\n",
        "\n",
        "    return question.strip(), sql.strip()"
      ],
      "metadata": {
        "id": "SxOl0INZFizX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset_by_schema(num_schemas=8000,\n",
        "                            queries_per_schema=8):\n",
        "\n",
        "    schemas = [generate_relational_schema()\n",
        "               for _ in range(num_schemas)]\n",
        "\n",
        "    train_split = int(0.8 * num_schemas)\n",
        "    val_split   = int(0.9 * num_schemas)\n",
        "\n",
        "    train_s = schemas[:train_split]\n",
        "    val_s   = schemas[train_split:val_split]\n",
        "    test_s  = schemas[val_split:]\n",
        "\n",
        "    def build_examples(schema_list):\n",
        "\n",
        "        data = []\n",
        "\n",
        "        for schema in schema_list:\n",
        "\n",
        "            schema_text = schema_to_text(schema)\n",
        "\n",
        "            for _ in range(queries_per_schema):\n",
        "\n",
        "                q, sql = generate_sql(schema)\n",
        "\n",
        "                model_input = f\"\"\"\n",
        "Schema:\n",
        "{schema_text}\n",
        "\n",
        "Question:\n",
        "{q}\n",
        "\"\"\"\n",
        "\n",
        "                data.append({\n",
        "                    \"input\": model_input.strip(),\n",
        "                    \"output\": sql.strip()\n",
        "                })\n",
        "\n",
        "        return data\n",
        "\n",
        "    return build_examples(train_s), build_examples(val_s), build_examples(test_s)\n",
        "\n",
        "\n",
        "train, val, test = build_dataset_by_schema()\n",
        "\n",
        "\n",
        "print(\"Train:\", len(train))\n",
        "print(\"Val:\", len(val))\n",
        "print(\"Test:\", len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eFqq1tIGfzb",
        "outputId": "57ed15cc-393c-422b-bf04-d3e48c065e2a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 51200\n",
            "Val: 6400\n",
            "Test: 6400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"train.json\", \"w\") as f:\n",
        "    json.dump(train, f)\n",
        "\n",
        "with open(\"val.json\", \"w\") as f:\n",
        "    json.dump(val, f)\n",
        "\n",
        "with open(\"test.json\", \"w\") as f:\n",
        "    json.dump(test, f)\n",
        "\n",
        "print(\"✅ Train/Val/Test datasets saved as JSON\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdjAeBQmWaxB",
        "outputId": "e7235674-318f-4a65-fc02-0b47e1eb6850"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train/Val/Test datasets saved as JSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(data):\n",
        "\n",
        "    counter = Counter()\n",
        "\n",
        "    for row in data:\n",
        "        counter.update(row[\"input\"].split())\n",
        "        counter.update(row[\"output\"].split())\n",
        "\n",
        "    vocab = {w:i+2 for i,(w,_) in enumerate(counter.items())}\n",
        "    vocab[\"<pad>\"] = 0\n",
        "    vocab[\"<unk>\"] = 1\n",
        "\n",
        "    return vocab\n",
        "\n",
        "vocab = build_vocab(train)\n",
        "\n",
        "torch.save(vocab, \"vocab.pt\")"
      ],
      "metadata": {
        "id": "ijPR7psAGf16"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 160\n",
        "\n",
        "def encode(text):\n",
        "\n",
        "    tokens = text.split()\n",
        "\n",
        "    ids = [vocab.get(t,1) for t in tokens][:MAX_LEN]\n",
        "\n",
        "    ids += [0]*(MAX_LEN-len(ids))\n",
        "\n",
        "    return torch.tensor(ids)\n",
        "\n",
        "class NL2SQLDataset(Dataset):\n",
        "\n",
        "    def __init__(self,data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        row = self.data[idx]\n",
        "\n",
        "        return encode(row[\"input\"]), encode(row[\"output\"])"
      ],
      "metadata": {
        "id": "-ECMgN75Gf4i"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"train.json\") as f:\n",
        "    train = json.load(f)\n",
        "\n",
        "with open(\"val.json\") as f:\n",
        "    val = json.load(f)\n",
        "\n",
        "with open(\"test.json\") as f:\n",
        "    test = json.load(f)\n",
        "\n",
        "print(\"✅ Dataset loaded!\")\n",
        "print(\"Train size:\", len(train))\n",
        "print(\"Val size:\", len(val))\n",
        "print(\"Test size:\", len(test))\n"
      ],
      "metadata": {
        "id": "yIyTYqmBZYHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NL2SQLModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, d_model=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=8,\n",
        "            num_encoder_layers=3,\n",
        "            num_decoder_layers=3,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "\n",
        "        src_padding_mask = (src == 0)\n",
        "        tgt_padding_mask = (tgt == 0)\n",
        "\n",
        "        # ⭐⭐⭐ CAUSAL MASK (VERY IMPORTANT)\n",
        "        tgt_seq_len = tgt.size(1)\n",
        "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(\n",
        "            tgt_seq_len\n",
        "        ).to(tgt.device)\n",
        "\n",
        "        src = self.embed(src)\n",
        "        tgt = self.embed(tgt)\n",
        "\n",
        "        out = self.transformer(\n",
        "            src,\n",
        "            tgt,\n",
        "            tgt_mask=tgt_mask,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_padding_mask\n",
        "        )\n",
        "\n",
        "        return self.fc(out)\n"
      ],
      "metadata": {
        "id": "C-TVvOjHGf61"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(train[i][\"input\"])\n",
        "    print(train[i][\"output\"])\n",
        "    print(\"-----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vv8PWShLVwS",
        "outputId": "37d266a3-0406-43a6-8179-8c158cbbc80b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema:\n",
            "[TABLE] environmental [COL] id [COL] quantity [COL] city [COL] department [COL] country [COL] updated_at [TABLE] voice [COL] id [COL] quantity [COL] age [COL] amount [COL] country [COL] updated_at [COL] environmental_id [TABLE] today [COL] id [COL] salary [COL] country [COL] email [COL] name [COL] voice_id [TABLE] not [COL] id [COL] price [COL] age [COL] department [COL] country [COL] updated_at [COL] today_id [TABLE] with [COL] id [COL] salary [COL] age [COL] city [COL] updated_at [COL] not_id [REL] voice.environmental_id -> environmental.id [REL] today.voice_id -> voice.id [REL] not.today_id -> today.id [REL] with.not_id -> not.id\n",
            "\n",
            "Question:\n",
            "show department from not\n",
            "SELECT department FROM not\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] environmental [COL] id [COL] quantity [COL] city [COL] department [COL] country [COL] updated_at [TABLE] voice [COL] id [COL] quantity [COL] age [COL] amount [COL] country [COL] updated_at [COL] environmental_id [TABLE] today [COL] id [COL] salary [COL] country [COL] email [COL] name [COL] voice_id [TABLE] not [COL] id [COL] price [COL] age [COL] department [COL] country [COL] updated_at [COL] today_id [TABLE] with [COL] id [COL] salary [COL] age [COL] city [COL] updated_at [COL] not_id [REL] voice.environmental_id -> environmental.id [REL] today.voice_id -> voice.id [REL] not.today_id -> today.id [REL] with.not_id -> not.id\n",
            "\n",
            "Question:\n",
            "show department, id from environmental\n",
            "SELECT department, id FROM environmental\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] environmental [COL] id [COL] quantity [COL] city [COL] department [COL] country [COL] updated_at [TABLE] voice [COL] id [COL] quantity [COL] age [COL] amount [COL] country [COL] updated_at [COL] environmental_id [TABLE] today [COL] id [COL] salary [COL] country [COL] email [COL] name [COL] voice_id [TABLE] not [COL] id [COL] price [COL] age [COL] department [COL] country [COL] updated_at [COL] today_id [TABLE] with [COL] id [COL] salary [COL] age [COL] city [COL] updated_at [COL] not_id [REL] voice.environmental_id -> environmental.id [REL] today.voice_id -> voice.id [REL] not.today_id -> today.id [REL] with.not_id -> not.id\n",
            "\n",
            "Question:\n",
            "show environmental_id from voice\n",
            "SELECT environmental_id FROM voice\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] environmental [COL] id [COL] quantity [COL] city [COL] department [COL] country [COL] updated_at [TABLE] voice [COL] id [COL] quantity [COL] age [COL] amount [COL] country [COL] updated_at [COL] environmental_id [TABLE] today [COL] id [COL] salary [COL] country [COL] email [COL] name [COL] voice_id [TABLE] not [COL] id [COL] price [COL] age [COL] department [COL] country [COL] updated_at [COL] today_id [TABLE] with [COL] id [COL] salary [COL] age [COL] city [COL] updated_at [COL] not_id [REL] voice.environmental_id -> environmental.id [REL] today.voice_id -> voice.id [REL] not.today_id -> today.id [REL] with.not_id -> not.id\n",
            "\n",
            "Question:\n",
            "show quantity from voice where quantity < 66\n",
            "SELECT quantity FROM voice WHERE quantity < 66\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] environmental [COL] id [COL] quantity [COL] city [COL] department [COL] country [COL] updated_at [TABLE] voice [COL] id [COL] quantity [COL] age [COL] amount [COL] country [COL] updated_at [COL] environmental_id [TABLE] today [COL] id [COL] salary [COL] country [COL] email [COL] name [COL] voice_id [TABLE] not [COL] id [COL] price [COL] age [COL] department [COL] country [COL] updated_at [COL] today_id [TABLE] with [COL] id [COL] salary [COL] age [COL] city [COL] updated_at [COL] not_id [REL] voice.environmental_id -> environmental.id [REL] today.voice_id -> voice.id [REL] not.today_id -> today.id [REL] with.not_id -> not.id\n",
            "\n",
            "Question:\n",
            "show first 6 rows from not\n",
            "SELECT *\n",
            "FROM not\n",
            "LIMIT 6\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] environmental [COL] id [COL] quantity [COL] city [COL] department [COL] country [COL] updated_at [TABLE] voice [COL] id [COL] quantity [COL] age [COL] amount [COL] country [COL] updated_at [COL] environmental_id [TABLE] today [COL] id [COL] salary [COL] country [COL] email [COL] name [COL] voice_id [TABLE] not [COL] id [COL] price [COL] age [COL] department [COL] country [COL] updated_at [COL] today_id [TABLE] with [COL] id [COL] salary [COL] age [COL] city [COL] updated_at [COL] not_id [REL] voice.environmental_id -> environmental.id [REL] today.voice_id -> voice.id [REL] not.today_id -> today.id [REL] with.not_id -> not.id\n",
            "\n",
            "Question:\n",
            "show updated_at from not joined with today\n",
            "SELECT not.updated_at\n",
            "FROM not\n",
            "JOIN today\n",
            "ON not.today_id = today.id\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] environmental [COL] id [COL] quantity [COL] city [COL] department [COL] country [COL] updated_at [TABLE] voice [COL] id [COL] quantity [COL] age [COL] amount [COL] country [COL] updated_at [COL] environmental_id [TABLE] today [COL] id [COL] salary [COL] country [COL] email [COL] name [COL] voice_id [TABLE] not [COL] id [COL] price [COL] age [COL] department [COL] country [COL] updated_at [COL] today_id [TABLE] with [COL] id [COL] salary [COL] age [COL] city [COL] updated_at [COL] not_id [REL] voice.environmental_id -> environmental.id [REL] today.voice_id -> voice.id [REL] not.today_id -> today.id [REL] with.not_id -> not.id\n",
            "\n",
            "Question:\n",
            "show first 4 rows from not\n",
            "SELECT *\n",
            "FROM not\n",
            "LIMIT 4\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] environmental [COL] id [COL] quantity [COL] city [COL] department [COL] country [COL] updated_at [TABLE] voice [COL] id [COL] quantity [COL] age [COL] amount [COL] country [COL] updated_at [COL] environmental_id [TABLE] today [COL] id [COL] salary [COL] country [COL] email [COL] name [COL] voice_id [TABLE] not [COL] id [COL] price [COL] age [COL] department [COL] country [COL] updated_at [COL] today_id [TABLE] with [COL] id [COL] salary [COL] age [COL] city [COL] updated_at [COL] not_id [REL] voice.environmental_id -> environmental.id [REL] today.voice_id -> voice.id [REL] not.today_id -> today.id [REL] with.not_id -> not.id\n",
            "\n",
            "Question:\n",
            "show all records from voice ordered by amount desc\n",
            "SELECT *\n",
            "        FROM voice\n",
            "        ORDER BY amount DESC\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] white [COL] id [COL] salary [COL] amount [COL] quantity [COL] department [COL] email [COL] city [COL] created_at [TABLE] he [COL] id [COL] price [COL] amount [COL] age [COL] name [COL] white_id [REL] he.white_id -> white.id\n",
            "\n",
            "Question:\n",
            "min of amount grouped by name having value < 37\n",
            "SELECT name, MIN(amount)\n",
            "FROM he\n",
            "GROUP BY name\n",
            "HAVING MIN(amount) < 37\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] white [COL] id [COL] salary [COL] amount [COL] quantity [COL] department [COL] email [COL] city [COL] created_at [TABLE] he [COL] id [COL] price [COL] amount [COL] age [COL] name [COL] white_id [REL] he.white_id -> white.id\n",
            "\n",
            "Question:\n",
            "what is the count of quantity in white\n",
            "SELECT COUNT(quantity) FROM white\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] white [COL] id [COL] salary [COL] amount [COL] quantity [COL] department [COL] email [COL] city [COL] created_at [TABLE] he [COL] id [COL] price [COL] amount [COL] age [COL] name [COL] white_id [REL] he.white_id -> white.id\n",
            "\n",
            "Question:\n",
            "what is the sum of age in he\n",
            "SELECT SUM(age) FROM he\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] white [COL] id [COL] salary [COL] amount [COL] quantity [COL] department [COL] email [COL] city [COL] created_at [TABLE] he [COL] id [COL] price [COL] amount [COL] age [COL] name [COL] white_id [REL] he.white_id -> white.id\n",
            "\n",
            "Question:\n",
            "show top 10 records from white ordered by quantity\n",
            "SELECT *\n",
            "FROM white\n",
            "ORDER BY quantity DESC\n",
            "LIMIT 10\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] white [COL] id [COL] salary [COL] amount [COL] quantity [COL] department [COL] email [COL] city [COL] created_at [TABLE] he [COL] id [COL] price [COL] amount [COL] age [COL] name [COL] white_id [REL] he.white_id -> white.id\n",
            "\n",
            "Question:\n",
            "show id from he joined with white\n",
            "SELECT he.id\n",
            "FROM he\n",
            "JOIN white\n",
            "ON he.white_id = white.id\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] white [COL] id [COL] salary [COL] amount [COL] quantity [COL] department [COL] email [COL] city [COL] created_at [TABLE] he [COL] id [COL] price [COL] amount [COL] age [COL] name [COL] white_id [REL] he.white_id -> white.id\n",
            "\n",
            "Question:\n",
            "show email from white joined with he where name = 'successful'\n",
            "SELECT white.email\n",
            "FROM white\n",
            "JOIN he\n",
            "ON white.id = he.white_id\n",
            "WHERE he.name = 'successful'\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] white [COL] id [COL] salary [COL] amount [COL] quantity [COL] department [COL] email [COL] city [COL] created_at [TABLE] he [COL] id [COL] price [COL] amount [COL] age [COL] name [COL] white_id [REL] he.white_id -> white.id\n",
            "\n",
            "Question:\n",
            "count of amount grouped by name having value = 14\n",
            "SELECT name, COUNT(amount)\n",
            "FROM he\n",
            "GROUP BY name\n",
            "HAVING COUNT(amount) = 14\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] white [COL] id [COL] salary [COL] amount [COL] quantity [COL] department [COL] email [COL] city [COL] created_at [TABLE] he [COL] id [COL] price [COL] amount [COL] age [COL] name [COL] white_id [REL] he.white_id -> white.id\n",
            "\n",
            "Question:\n",
            "show amount from he joined with white where salary < 65\n",
            "SELECT he.amount\n",
            "FROM he\n",
            "JOIN white\n",
            "ON he.white_id = white.id\n",
            "WHERE white.salary < 65\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] fund [COL] id [COL] price [COL] age [COL] name [COL] created_at [TABLE] clear [COL] id [COL] price [COL] department [COL] email [COL] fund_id [TABLE] six [COL] id [COL] age [COL] amount [COL] country [COL] clear_id [REL] clear.fund_id -> fund.id [REL] six.clear_id -> clear.id\n",
            "\n",
            "Question:\n",
            "show id, name, created_at from fund\n",
            "SELECT id, name, created_at FROM fund\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] fund [COL] id [COL] price [COL] age [COL] name [COL] created_at [TABLE] clear [COL] id [COL] price [COL] department [COL] email [COL] fund_id [TABLE] six [COL] id [COL] age [COL] amount [COL] country [COL] clear_id [REL] clear.fund_id -> fund.id [REL] six.clear_id -> clear.id\n",
            "\n",
            "Question:\n",
            "show top 10 records from fund ordered by price\n",
            "SELECT *\n",
            "FROM fund\n",
            "ORDER BY price DESC\n",
            "LIMIT 10\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] fund [COL] id [COL] price [COL] age [COL] name [COL] created_at [TABLE] clear [COL] id [COL] price [COL] department [COL] email [COL] fund_id [TABLE] six [COL] id [COL] age [COL] amount [COL] country [COL] clear_id [REL] clear.fund_id -> fund.id [REL] six.clear_id -> clear.id\n",
            "\n",
            "Question:\n",
            "show id from clear joined with six where amount > 35\n",
            "SELECT clear.id\n",
            "FROM clear\n",
            "JOIN six\n",
            "ON clear.id = six.clear_id\n",
            "WHERE six.amount > 35\n",
            "-----\n",
            "Schema:\n",
            "[TABLE] fund [COL] id [COL] price [COL] age [COL] name [COL] created_at [TABLE] clear [COL] id [COL] price [COL] department [COL] email [COL] fund_id [TABLE] six [COL] id [COL] age [COL] amount [COL] country [COL] clear_id [REL] clear.fund_id -> fund.id [REL] six.clear_id -> clear.id\n",
            "\n",
            "Question:\n",
            "show id, price, name, created_at from fund\n",
            "SELECT id, price, name, created_at FROM fund\n",
            "-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    NL2SQLDataset(train),\n",
        "    batch_size=16,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    NL2SQLDataset(val),\n",
        "    batch_size=16,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    NL2SQLDataset(test),\n",
        "    batch_size=16,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "model = NL2SQLModel(len(vocab)).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=0)"
      ],
      "metadata": {
        "id": "5PESpD8FGf9I"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_PATH = \"nl2sql_checkpoint.pt\"\n",
        "\n",
        "def save_checkpoint(epoch, model, optimizer, loss):\n",
        "\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"loss\": loss\n",
        "    }, CHECKPOINT_PATH)\n",
        "\n",
        "def load_checkpoint(model, optimizer):\n",
        "\n",
        "    if os.path.exists(CHECKPOINT_PATH):\n",
        "\n",
        "        ckpt = torch.load(CHECKPOINT_PATH,\n",
        "                          map_location=device)\n",
        "\n",
        "        model.load_state_dict(ckpt[\"model_state\"])\n",
        "        optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
        "\n",
        "        print(\"Resuming from epoch:\",\n",
        "              ckpt[\"epoch\"]+1)\n",
        "\n",
        "        return ckpt[\"epoch\"] + 1\n",
        "\n",
        "    return 0"
      ],
      "metadata": {
        "id": "pi6TnwL9Gf_d"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "best_loss = float(\"inf\")\n",
        "\n",
        "start_epoch = load_checkpoint(model, optimizer)\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "\n",
        "    ###################\n",
        "    # TRAIN\n",
        "    ###################\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(x, y[:,:-1])\n",
        "\n",
        "        loss = loss_fn(\n",
        "            output.reshape(-1, len(vocab)),\n",
        "            y[:,1:].reshape(-1)\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "\n",
        "    ###################\n",
        "    # VALIDATION\n",
        "    ###################\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for x,y in val_loader:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            output = model(x, y[:,:-1])\n",
        "\n",
        "            loss = loss_fn(\n",
        "                output.reshape(-1, len(vocab)),\n",
        "                y[:,1:].reshape(-1)\n",
        "            )\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch} | Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f}\")\n",
        "\n",
        "    save_checkpoint(epoch, model, optimizer, val_loss)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        print(\"⭐ BEST MODEL SAVED\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d62paSTGgB6",
        "outputId": "83f12508-8303-496e-e54a-8a2cacb41fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Train Loss 3.1396 | Val Loss 2.9934\n",
            "⭐ BEST MODEL SAVED\n",
            "Epoch 1 | Train Loss 2.6255 | Val Loss 3.1910\n",
            "Epoch 2 | Train Loss 1.9118 | Val Loss 3.2314\n",
            "Epoch 3 | Train Loss 1.3053 | Val Loss 3.1079\n",
            "Epoch 4 | Train Loss 0.9828 | Val Loss 3.0030\n",
            "Epoch 5 | Train Loss 0.7949 | Val Loss 2.9828\n",
            "⭐ BEST MODEL SAVED\n",
            "Epoch 6 | Train Loss 0.6839 | Val Loss 3.0611\n",
            "Epoch 7 | Train Loss 0.6103 | Val Loss 3.0056\n",
            "Epoch 8 | Train Loss 0.5529 | Val Loss 3.0139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(\n",
        "    NL2SQLDataset(test),\n",
        "    batch_size=64,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for x,y in test_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        output = model(x, y[:,:-1])\n",
        "\n",
        "        loss = loss_fn(\n",
        "            output.reshape(-1, len(vocab)),\n",
        "            y[:,1:].reshape(-1)\n",
        "        )\n",
        "\n",
        "        test_loss += loss.item()\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "\n",
        "print(\"✅ FINAL TEST LOSS:\", test_loss)\n"
      ],
      "metadata": {
        "id": "G10AQ6FzgRFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- LOAD VOCAB ----------\n",
        "vocab = torch.load(\"vocab.pt\")\n",
        "inv_vocab = {i:w for w,i in vocab.items()}\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "# ---------- REBUILD MODEL ----------\n",
        "model = NL2SQLModel(len(vocab)).to(device)\n",
        "\n",
        "model.load_state_dict(\n",
        "    torch.load(\"best_model.pt\", map_location=device)\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print(\"✅ Best model loaded!\")\n"
      ],
      "metadata": {
        "id": "88bvEFs3GgET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 220\n",
        "\n",
        "def encode(text):\n",
        "\n",
        "    tokens = text.split()\n",
        "\n",
        "    ids = [vocab.get(t,1) for t in tokens][:MAX_LEN]\n",
        "\n",
        "    ids += [0]*(MAX_LEN-len(ids))\n",
        "\n",
        "    return torch.tensor(ids)\n"
      ],
      "metadata": {
        "id": "5cnMD7NEGgIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_query(model, text, max_len=220):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    src = encode(text).unsqueeze(0).to(device)\n",
        "\n",
        "    tgt = torch.zeros((1,1), dtype=torch.long).to(device)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            output = model(src, tgt)\n",
        "            logits = output\n",
        "\n",
        "        next_token = logits.argmax(-1)[:,-1].unsqueeze(0)\n",
        "\n",
        "        tgt = torch.cat([tgt, next_token], dim=1)\n",
        "\n",
        "        if next_token.item() == 0:\n",
        "            break\n",
        "\n",
        "    tokens = [\n",
        "        inv_vocab.get(i,\"\")\n",
        "        for i in tgt.squeeze().tolist()\n",
        "    ]\n",
        "\n",
        "    return \" \".join(tokens)\n"
      ],
      "metadata": {
        "id": "YeGVvn7RIgUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nbZc46UCIgbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uJ4cwf1OIges"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}