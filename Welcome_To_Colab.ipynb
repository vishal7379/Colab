{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal7379/Colab/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sympy --upgrade\n",
        "\n",
        "import random\n",
        "import string\n",
        "import json\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "7j2HKx8N3qtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "id": "m2UqGMRa3qvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_token(min_len=4, max_len=10):\n",
        "    length = random.randint(min_len, max_len)\n",
        "    return ''.join(random.choices(string.ascii_lowercase, k=length))\n",
        "\n",
        "\n",
        "def generate_schema():\n",
        "\n",
        "    schema = {}\n",
        "\n",
        "    num_tables = random.randint(1,5)\n",
        "\n",
        "    for _ in range(num_tables):\n",
        "\n",
        "        table = random_token()\n",
        "\n",
        "        num_cols = random.randint(3,7)\n",
        "\n",
        "        cols = [random_token() for _ in range(num_cols)]\n",
        "\n",
        "        cols.append(\"id\")   # anchor column\n",
        "\n",
        "        schema[table] = list(set(cols))\n",
        "\n",
        "    return schema\n"
      ],
      "metadata": {
        "id": "mzCNbsUA3qyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AGGS = [\"SUM\",\"AVG\",\"COUNT\",\"MAX\",\"MIN\"]\n",
        "\n",
        "OPS = [\">\",\"<\",\">=\",\"<=\",\"!=\"]\n",
        "\n",
        "JOIN_TYPES = [\"JOIN\",\"LEFT JOIN\",\"RIGHT JOIN\"]\n",
        "\n",
        "SORT = [\"ASC\",\"DESC\"]\n"
      ],
      "metadata": {
        "id": "CVAZ0sd73q0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def serialize_schema(schema):\n",
        "\n",
        "    parts = []\n",
        "\n",
        "    for t,cols in schema.items():\n",
        "\n",
        "        random.shuffle(cols)  # prevents memorization\n",
        "\n",
        "        parts.append(\n",
        "            f\"{t} : \" + \" , \".join(cols)\n",
        "        )\n",
        "\n",
        "    return \" <SCHEMA> \" + \" | \".join(parts) + \" </SCHEMA> \"\n"
      ],
      "metadata": {
        "id": "SpoM2fAR3q2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_example():\n",
        "\n",
        "    schema = generate_schema()\n",
        "\n",
        "    tables = list(schema.keys())\n",
        "\n",
        "    main = random.choice(tables)\n",
        "\n",
        "    cols = schema[main]\n",
        "\n",
        "    intent = random.choice([\n",
        "        \"SELECT\",\"WHERE\",\"GROUP\",\n",
        "        \"HAVING\",\"ORDER\",\"LIMIT\",\n",
        "        \"JOIN\",\"NESTED\"\n",
        "    ])\n",
        "\n",
        "    ################################\n",
        "    # SELECT\n",
        "    ################################\n",
        "\n",
        "    if intent == \"SELECT\":\n",
        "\n",
        "        chosen = random.sample(cols, random.randint(1,min(3,len(cols))))\n",
        "\n",
        "        question = f\"get {', '.join(chosen)} from {main}\"\n",
        "\n",
        "        sql = f\"SELECT {', '.join(chosen)} FROM {main}\"\n",
        "\n",
        "\n",
        "    ################################\n",
        "    # WHERE\n",
        "    ################################\n",
        "\n",
        "    elif intent == \"WHERE\":\n",
        "\n",
        "        chosen = random.sample(cols,2)\n",
        "\n",
        "        op = random.choice(OPS)\n",
        "\n",
        "        val = random.randint(1,1000)\n",
        "\n",
        "        question = f\"find {chosen[0]} from {main} where {chosen[1]} {op} {val}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT {chosen[0]}\n",
        "        FROM {main}\n",
        "        WHERE {chosen[1]} {op} {val}\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    ################################\n",
        "    # GROUP + HAVING\n",
        "    ################################\n",
        "\n",
        "    elif intent == \"HAVING\":\n",
        "\n",
        "        group = random.choice(cols)\n",
        "        agg_col = random.choice(cols)\n",
        "\n",
        "        agg = random.choice(AGGS)\n",
        "\n",
        "        op = random.choice(OPS)\n",
        "        val = random.randint(1,500)\n",
        "\n",
        "        question = f\"group {main} by {group} having {agg.lower()} {agg_col} {op} {val}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT {group}, {agg}({agg_col})\n",
        "        FROM {main}\n",
        "        GROUP BY {group}\n",
        "        HAVING {agg}({agg_col}) {op} {val}\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    ################################\n",
        "    # ORDER\n",
        "    ################################\n",
        "\n",
        "    elif intent == \"ORDER\":\n",
        "\n",
        "        col = random.choice(cols)\n",
        "\n",
        "        direction = random.choice(SORT)\n",
        "\n",
        "        question = f\"order {main} by {col} {direction.lower()}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT {col}\n",
        "        FROM {main}\n",
        "        ORDER BY {col} {direction}\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    ################################\n",
        "    # LIMIT\n",
        "    ################################\n",
        "\n",
        "    elif intent == \"LIMIT\":\n",
        "\n",
        "        col = random.choice(cols)\n",
        "\n",
        "        limit = random.randint(1,20)\n",
        "\n",
        "        question = f\"top {limit} rows of {col} from {main}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT {col}\n",
        "        FROM {main}\n",
        "        LIMIT {limit}\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    ################################\n",
        "    # JOIN\n",
        "    ################################\n",
        "\n",
        "    elif intent == \"JOIN\" and len(tables) > 1:\n",
        "\n",
        "        t2 = random.choice([t for t in tables if t!=main])\n",
        "\n",
        "        c1 = random.choice(schema[main])\n",
        "        c2 = random.choice(schema[t2])\n",
        "\n",
        "        join = random.choice(JOIN_TYPES)\n",
        "\n",
        "        question = f\"join {main} with {t2}\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT {main}.{c1}, {t2}.{c2}\n",
        "        FROM {main}\n",
        "        {join} {t2}\n",
        "        ON {main}.{c1} = {t2}.{c2}\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    ################################\n",
        "    # NESTED\n",
        "    ################################\n",
        "\n",
        "    else:\n",
        "\n",
        "        col = random.choice(cols)\n",
        "\n",
        "        agg = random.choice(AGGS)\n",
        "\n",
        "        question = f\"find {col} from {main} greater than average\"\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT {col}\n",
        "        FROM {main}\n",
        "        WHERE {col} >\n",
        "        (SELECT {agg}({col}) FROM {main})\n",
        "        \"\"\"\n",
        "\n",
        "    full_question = question + serialize_schema(schema)\n",
        "\n",
        "    return {\n",
        "        \"question\": full_question.lower(),\n",
        "        \"sql\": \" \".join(sql.split())\n",
        "    }\n"
      ],
      "metadata": {
        "id": "jKictraQ3q5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA = [generate_example() for _ in range(80000)]\n",
        "\n",
        "with open(\"nl2sql.json\",\"w\") as f:\n",
        "    json.dump(DATA,f)\n",
        "\n",
        "print(\"Dataset Ready ðŸš€\")\n"
      ],
      "metadata": {
        "id": "b3_oZQdk3q9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sql_tokenize(sql):\n",
        "\n",
        "    return re.findall(\n",
        "        r\"[A-Za-z_]+\\.[A-Za-z_]+\"\n",
        "        r\"|>=|<=|!=|=|>|<\"\n",
        "        r\"|\\bselect\\b|\\bfrom\\b|\\bwhere\\b|\\bjoin\\b|\\bon\\b\"\n",
        "        r\"|\\bgroup\\b|\\bby\\b|\\bhaving\\b|\\border\\b|\\blimit\\b\"\n",
        "        r\"|\\bavg\\b|\\bsum\\b|\\bcount\\b|\\bmax\\b|\\bmin\\b\"\n",
        "        r\"|\\(|\\)|,\"\n",
        "        r\"|[A-Za-z_]+\"\n",
        "        r\"|\\d+\",\n",
        "        sql.lower()\n",
        "    )\n"
      ],
      "metadata": {
        "id": "ELRIU0y04Lub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENC_VOCAB={\"<PAD>\":0,\"<UNK>\":1}\n",
        "DEC_VOCAB={\"<PAD>\":0,\"<UNK>\":1,\"<BOS>\":2,\"<EOS>\":3}\n",
        "\n",
        "def add(vocab,t):\n",
        "    if t not in vocab:\n",
        "        vocab[t]=len(vocab)\n",
        "\n",
        "for ex in DATA:\n",
        "\n",
        "    for t in ex[\"question\"].split():\n",
        "        add(ENC_VOCAB,t)\n",
        "\n",
        "    for t in sql_tokenize(ex[\"sql\"]):\n",
        "        add(DEC_VOCAB,t)\n",
        "\n",
        "print(len(ENC_VOCAB), len(DEC_VOCAB))\n"
      ],
      "metadata": {
        "id": "q9euL1zw4LxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NL2SQLDataset(Dataset):\n",
        "\n",
        "    def __init__(self,data):\n",
        "        self.data=data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "\n",
        "        ex=self.data[i]\n",
        "\n",
        "        src=[ENC_VOCAB.get(t,1) for t in ex[\"question\"].split()][:180]\n",
        "        src+=[0]*(180-len(src))\n",
        "\n",
        "        tgt=[DEC_VOCAB[\"<BOS>\"]] + \\\n",
        "            [DEC_VOCAB.get(t,1) for t in sql_tokenize(ex[\"sql\"])] + \\\n",
        "            [DEC_VOCAB[\"<EOS>\"]]\n",
        "\n",
        "        tgt=tgt[:100]\n",
        "        tgt+=[0]*(100-len(tgt))\n",
        "\n",
        "        return torch.tensor(src),torch.tensor(tgt)\n"
      ],
      "metadata": {
        "id": "XSM9QhEL4Lzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_MODEL = 512\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,d_model,max_len=512):\n",
        "        super().__init__()\n",
        "\n",
        "        pe=torch.zeros(max_len,d_model)\n",
        "\n",
        "        pos=torch.arange(0,max_len).unsqueeze(1)\n",
        "\n",
        "        div=torch.exp(\n",
        "            torch.arange(0,d_model,2) *\n",
        "            (-torch.log(torch.tensor(10000.0))/d_model)\n",
        "        )\n",
        "\n",
        "        pe[:,0::2]=torch.sin(pos*div)\n",
        "        pe[:,1::2]=torch.cos(pos*div)\n",
        "\n",
        "        self.pe=pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return x+self.pe[:,:x.size(1)].to(x.device)\n"
      ],
      "metadata": {
        "id": "JqU8iVTs4L2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self,vocab):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb=nn.Embedding(vocab,D_MODEL,padding_idx=0)\n",
        "        self.pos=PositionalEncoding(D_MODEL)\n",
        "\n",
        "        layer=nn.TransformerEncoderLayer(\n",
        "            D_MODEL,8,1536,\n",
        "            dropout=0.1,\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "\n",
        "        self.enc=nn.TransformerEncoder(layer,4)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        mask=(x==0)\n",
        "\n",
        "        x=self.pos(self.emb(x))\n",
        "\n",
        "        return self.enc(x,src_key_padding_mask=mask)\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self,vocab):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb=nn.Embedding(vocab,D_MODEL)\n",
        "        self.pos=PositionalEncoding(D_MODEL)\n",
        "\n",
        "        layer=nn.TransformerDecoderLayer(\n",
        "            D_MODEL,8,1536,\n",
        "            dropout=0.1,\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "\n",
        "        self.dec=nn.TransformerDecoder(layer,4)\n",
        "\n",
        "        self.fc=nn.Linear(D_MODEL,vocab)\n",
        "\n",
        "        self.fc.weight=self.emb.weight\n",
        "\n",
        "    def forward(self,y,mem,mask):\n",
        "\n",
        "        L=y.size(1)\n",
        "\n",
        "        causal=torch.triu(\n",
        "            torch.ones(L,L,device=y.device),1\n",
        "        ).bool()\n",
        "\n",
        "        y=self.pos(self.emb(y))\n",
        "\n",
        "        return self.fc(\n",
        "            self.dec(\n",
        "                y,mem,\n",
        "                tgt_mask=causal,\n",
        "                memory_key_padding_mask=mask\n",
        "            )\n",
        "        )\n"
      ],
      "metadata": {
        "id": "y9kHlVS04L44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_MODEL = 512\n",
        "N_HEADS = 8\n",
        "NUM_LAYERS = 4\n",
        "FF_DIM = 2048\n",
        "DROPOUT = 0.1\n"
      ],
      "metadata": {
        "id": "e-otQLq44L7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=512):\n",
        "        super().__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) *\n",
        "            (-math.log(10000.0) / d_model)\n",
        "        )\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)].to(x.device)\n"
      ],
      "metadata": {
        "id": "eYdJHsw_4L9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            vocab_size,\n",
        "            D_MODEL,\n",
        "            padding_idx=0\n",
        "        )\n",
        "\n",
        "        self.pos = PositionalEncoding(D_MODEL)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=D_MODEL,\n",
        "            nhead=N_HEADS,\n",
        "            dim_feedforward=FF_DIM,\n",
        "            dropout=DROPOUT,\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=NUM_LAYERS\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        padding_mask = (x == 0)\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos(x)\n",
        "\n",
        "        return self.encoder(\n",
        "            x,\n",
        "            src_key_padding_mask=padding_mask\n",
        "        )\n"
      ],
      "metadata": {
        "id": "jFUSvogh4MAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            vocab_size,\n",
        "            D_MODEL\n",
        "        )\n",
        "\n",
        "        self.pos = PositionalEncoding(D_MODEL)\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=D_MODEL,\n",
        "            nhead=N_HEADS,\n",
        "            dim_feedforward=FF_DIM,\n",
        "            dropout=DROPOUT,\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.TransformerDecoder(\n",
        "            decoder_layer,\n",
        "            num_layers=NUM_LAYERS\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(D_MODEL, vocab_size)\n",
        "\n",
        "        # weight tying (important)\n",
        "        self.fc.weight = self.embedding.weight\n",
        "\n",
        "    def forward(self, y, memory, src_mask):\n",
        "\n",
        "        L = y.size(1)\n",
        "\n",
        "        causal_mask = torch.triu(\n",
        "            torch.ones(L, L, device=y.device),\n",
        "            diagonal=1\n",
        "        ).bool()\n",
        "\n",
        "        y = self.embedding(y)\n",
        "        y = self.pos(y)\n",
        "\n",
        "        output = self.decoder(\n",
        "            y,\n",
        "            memory,\n",
        "            tgt_mask=causal_mask,\n",
        "            memory_key_padding_mask=src_mask\n",
        "        )\n",
        "\n",
        "        return self.fc(output)\n"
      ],
      "metadata": {
        "id": "zkDJK-xw6WLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_data, val_data = train_test_split(\n",
        "    DATA,\n",
        "    test_size=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    NL2SQLDataset(train_data),\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    NL2SQLDataset(val_data),\n",
        "    batch_size=64\n",
        ")\n"
      ],
      "metadata": {
        "id": "iEE-6xfb6WNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "enc = Encoder(len(ENC_VOCAB)).to(device)\n",
        "dec = Decoder(len(DEC_VOCAB)).to(device)\n"
      ],
      "metadata": {
        "id": "O4jxoQB26WP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.AdamW(\n",
        "    list(enc.parameters()) + list(dec.parameters()),\n",
        "    lr=1e-4\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=15\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(\n",
        "    ignore_index=0,\n",
        "    label_smoothing=0.05\n",
        ")\n"
      ],
      "metadata": {
        "id": "KD35DX1i6WSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    #################################\n",
        "    # TRAIN\n",
        "    #################################\n",
        "\n",
        "    enc.train()\n",
        "    dec.train()\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        memory = enc(x)\n",
        "\n",
        "        output = dec(y[:, :-1], memory, (x == 0))\n",
        "\n",
        "        loss = loss_fn(\n",
        "            output.reshape(-1, len(DEC_VOCAB)),\n",
        "            y[:, 1:].reshape(-1)\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            list(enc.parameters()) + list(dec.parameters()),\n",
        "            1.0\n",
        "        )\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    #################################\n",
        "    # VALIDATION\n",
        "    #################################\n",
        "\n",
        "    enc.eval()\n",
        "    dec.eval()\n",
        "\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for x, y in val_loader:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            memory = enc(x)\n",
        "\n",
        "            output = dec(y[:, :-1], memory, (x == 0))\n",
        "\n",
        "            val_loss += loss_fn(\n",
        "                output.reshape(-1, len(DEC_VOCAB)),\n",
        "                y[:, 1:].reshape(-1)\n",
        "            ).item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    #################################\n",
        "\n",
        "    print(f\"\"\"\n",
        "Epoch {epoch+1}\n",
        "\n",
        "Train Loss: {train_loss:.3f}\n",
        "Val Loss:   {val_loss:.3f}\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "v-lQrWvk6WUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lfZraNMK6WX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ofyV4TLZ4MDw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}